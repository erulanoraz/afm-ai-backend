# app/services/facts/fact_filter.py

import logging
from typing import List
from app.services.facts.fact_models import LegalFact

logger = logging.getLogger(__name__)


class FactFilter:
    """
    FactFilter v10.2 ‚Äî Criminal Core Filter –¥–ª—è Qualifier 6.x

    –¶–µ–ª–∏ v10.2:
    ‚Ä¢ –ü–æ–ª–Ω–æ—Å—Ç—å—é —É–¥–∞–ª–∏—Ç—å —à—É–º–æ–≤—ã–µ pseudo-person —Ñ–∞–∫—Ç—ã (¬´–í–æ–µ–Ω–Ω–æ–æ–±—è–∑–∞–Ω–Ω—ã–π –ù–∞–ª–∏—á–∏–µ¬ª, 
      ¬´–ù–µ—Ç –û—Ç–Ω–æ—à–µ–Ω–∏–µ¬ª, ¬´–†–µ—Å–ø—É–±–ª–∏–∫–∞ –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω¬ª –∏ —Ç.–ø.).
    ‚Ä¢ –£—Å–∏–ª–∏—Ç—å —Ñ–∏–ª—å—Ç—Ä –ø—Ä–æ—Ü–µ—Å—Å—É–∞–ª–∫–∏: –≤—Å—ë, —á—Ç–æ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∫—Ä–∏–º–∏–Ω–∞–ª—å–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤,
      —Å—É–º–º—ã, –ø–µ—Ä–µ–≤–æ–¥–æ–≤, —Å—Ö–µ–º, –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞, –ø–ª–∞—Ç—Ñ–æ—Ä–º ‚Üí —É–¥–∞–ª—è–µ—Ç—Å—è.
    ‚Ä¢ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ, —Å—Ö–µ–º–Ω—ã–µ, –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–Ω—ã–µ, –ø—Ä–æ–µ–∫—Ç–Ω—ã–µ –∏ 
      –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è.
    """

    # ================================
    # –®—É–º–æ–≤—ã–µ –ø—Å–µ–≤–¥–æ-—É—á–∞—Å—Ç–Ω–∏–∫–∏ (—Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å FactTokenizer v32.0)
    # ================================
    NOISE_PERSON_PHRASES = {
        "–≤–æ–µ–Ω–Ω–æ–æ–±—è–∑–∞–Ω–Ω—ã–π", "–≤–æ–µ–Ω–Ω–æ–æ–±—è–∑–∞–Ω–Ω–∞—è",
        "–≤–æ–µ–Ω–Ω–æ–æ–±—è–∑–∞–Ω–Ω—ã–π –Ω–∞–ª–∏—á–∏–µ", "–Ω–∞–ª–∏—á–∏–µ", "–æ—Ç–Ω–æ—à–µ–Ω–∏–µ", "–Ω–µ—Ç –æ—Ç–Ω–æ—à–µ–Ω–∏–µ",
        "–Ω–µ—Ç –æ—Ç–Ω–æ—à–µ–Ω–∏—è",
        "—Ä–µ—Å–ø—É–±–ª–∏–∫–∞ –∫–∞–∑–∞—Ö—Å—Ç–∞–Ω", "—Ä–µ—Å–ø—É–±–ª–∏–∫–∏ –∫–∞–∑–∞—Ö—Å—Ç–∞–Ω",
        "—Ä–µ—Å–ø—É–±–ª–∏–∫–∞", "–∫–∞–∑–∞—Ö—Å—Ç–∞–Ω",
        "–∑–∞—è–≤–∏—Ç–µ–ª—å", "–ø–æ—Ç–µ—Ä–ø–µ–≤—à–∏–π", "–ø–æ—Ç–µ—Ä–ø–µ–≤—à–∞—è",
        "–ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º—ã–π", "–ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º–∞—è",
        "–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è", "–∫–æ–º–ø–∞–Ω–∏—è", "–±–∞–Ω–∫",
        "–æ–Ω", "–æ–Ω–∞", "–æ–Ω–∏",
        "–≤ –Ω–∞–ª–∏—á–∏–∏", "–±–µ–∑ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ –º–µ—Å—Ç–∞ –∂–∏—Ç–µ–ª—å—Å—Ç–≤–∞",
        "–±–µ–∑ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ–≥–æ –º–µ—Å—Ç–∞ –∂–∏—Ç–µ–ª—å—Å—Ç–≤–∞",
        "—Å–≤–µ–¥–µ–Ω–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç", "–Ω–µ—Ç —Å–≤–µ–¥–µ–Ω–∏–π",
    }

    # ================================
    # –ü—Ä–æ—Ü–µ—Å—Å—É–∞–ª—å–Ω—ã–µ —Ñ—Ä–∞–∑—ã
    # ================================
    PROCESSUAL_KEYWORDS = [
        # –ø—Ä–∞–≤–∞
        "—Ä–∞–∑—ä—è—Å–Ω–µ–Ω—ã –ø—Ä–∞–≤–∞",
        "–µ–º—É —Ä–∞–∑—ä—è—Å–Ω–µ–Ω—ã –ø—Ä–∞–≤–∞",
        "–µ–π —Ä–∞–∑—ä—è—Å–Ω–µ–Ω—ã –ø—Ä–∞–≤–∞",
        "–ø—Ä–∞–≤–∞ –∏ –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏ –±—ã–ª–∏ —Ä–∞–∑—ä—è—Å–Ω–µ–Ω—ã",
        "—É–≤–µ–¥–æ–º–ª–µ–Ω –æ–± —É–≥–æ–ª–æ–≤–Ω–æ–π –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏",
        "—É–≤–µ–¥–æ–º–ª–µ–Ω–∞ –æ–± —É–≥–æ–ª–æ–≤–Ω–æ–π –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏",
        "–ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω –æ–± —É–≥–æ–ª–æ–≤–Ω–æ–π –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏",
        "–ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∞ –æ–± —É–≥–æ–ª–æ–≤–Ω–æ–π –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏",

        # —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è
        "—Å–æ—Å—Ç–∞–≤–∏–ª —Ä–∞–ø–æ—Ä—Ç",
        "—Å–æ—Å—Ç–∞–≤–ª–µ–Ω —Ä–∞–ø–æ—Ä—Ç",
        "–∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–ª –º–∞—Ç–µ—Ä–∏–∞–ª—ã",
        "–∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω—ã –º–∞—Ç–µ—Ä–∏–∞–ª—ã",
        "–∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–æ –≤ –µ—Ä–¥—Ä",
        "–∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω—ã –≤ –µ—Ä–¥—Ä",
        "–∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–æ –≤ –∫—É–∏",
        "–∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω—ã –≤ –∫—É–∏",

        # –∏–∑—ä—è—Ç–∏–µ / —ç–∫—Å–ø–µ—Ä—Ç–∏–∑–∞
        "–ø—Ä–∏–æ–±—â–∏–ª –∫ –º–∞—Ç–µ—Ä–∏–∞–ª–∞–º –¥–µ–ª–∞",
        "–ø—Ä–∏–æ–±—â–µ–Ω—ã –∫ –º–∞—Ç–µ—Ä–∏–∞–ª–∞–º –¥–µ–ª–∞",
        "–∏–∑—ä—è–ª –¥–æ–∫—É–º–µ–Ω—Ç—ã",
        "–∏–∑—ä—è—Ç—ã –¥–æ–∫—É–º–µ–Ω—Ç—ã",
        "–∏–∑—ä—è—Ç–æ –∏–º—É—â–µ—Å—Ç–≤–æ",
        "–Ω–∞–∑–Ω–∞—á–µ–Ω–∞ —ç–∫—Å–ø–µ—Ä—Ç–∏–∑–∞",
        "–ø—Ä–æ–≤–µ–¥–µ–Ω–∞ —ç–∫—Å–ø–µ—Ä—Ç–∏–∑–∞",

        # –ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
        "–ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –æ –Ω–∞—á–∞–ª–µ –¥–æ—Å—É–¥–µ–±–Ω–æ–≥–æ —Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è",
        "–≤—ã–Ω–µ—Å–µ–Ω–æ –ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ",
        "–Ω–∞—á–∞—Ç–æ –¥–æ—Å—É–¥–µ–±–Ω–æ–µ —Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ",
        "—É–≥–æ–ª–æ–≤–Ω–æ–µ –¥–µ–ª–æ –≤–æ–∑–±—É–∂–¥–µ–Ω–æ",

        # –ø—Ä–æ—Ç–æ–∫–æ–ª—ã
        "—Å–æ—Å—Ç–∞–≤–ª–µ–Ω –ø—Ä–æ—Ç–æ–∫–æ–ª",
        "–ø—Ä–æ—Ç–æ–∫–æ–ª –¥–æ–ø—Ä–æ—Å–∞",
        "–ø—Ä–æ—Ç–æ–∫–æ–ª –æ—Å–º–æ—Ç—Ä–∞",

        # —Å—É–¥
        "–¥–µ–ª–æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–æ –≤ —Å—É–¥",
        "–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–æ –≤ —Å—É–¥",
    ]

    # ================================
    # –ö—Ä–∏–º–∏–Ω–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã (—Å–∏–≥–Ω–∞–ª—ã —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è)
    # ================================
    CRIME_TOKEN_TYPES = {
        "amount",
        "fraud_flag",
        "invest_flag",
        "scheme_flag",
        "economic_flag",
        "admin_flag",
        "crypto_flag",
        "crypto",
        "channel",
        "account",
        "date",

        "entity",
        "project",
        "platform",
        "organization",

        "article_ref",
        "phone",
    }

    # ================================
    # –†–æ–ª–∏, –∫–æ—Ç–æ—Ä—ã–µ –ù–ò–ö–û–ì–î–ê –Ω–µ–ª—å–∑—è —É–¥–∞–ª—è—Ç—å
    # ================================
    ALWAYS_KEEP_ROLES = {
        "suspect_action",
        "fraud_action",
        "fraud_event",
        "investment_event",
        "investment_context",
        "crypto_operation",
        "scheme_marker",
        "economic_action",
        "digital_transfer",
        "victim_loss",
        "money_transfer",
        "admin_action",
        "entity_reference",
    }

    MAX_FACTS = 180

    # =======================================================
    # –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
    # =======================================================
    def filter_for_qualifier(self, facts: List[LegalFact]) -> List[LegalFact]:
        if not facts:
            return []

        before = len(facts)

        # 1. –£–¥–∞–ª—è–µ–º –ø—Ä–æ—Ü–µ—Å—Å—É–∞–ª–∫—É –∏ —à—É–º–æ–≤—ã–µ pseudo-person —Ñ–∞–∫—Ç—ã
        non_proc = []
        for f in facts:
            if self._is_noise_fake_person(f):
                continue
            if self._is_processual_fact(f):
                continue
            non_proc.append(f)

        logger.info(
            f"üßπ FactFilter 10.2: –±—ã–ª–æ={before}, –æ—Å—Ç–∞–ª–æ—Å—å –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏={len(non_proc)}"
        )

        if not non_proc:
            logger.warning(
                "‚ö†Ô∏è FactFilter 10.2: –≤—Å—ë –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ. –í–æ–∑–≤—Ä–∞—â–∞–µ–º top-–∫–æ–Ω—Ç–µ–Ω—Ç –∏–∑ –∏—Å—Ö–æ–¥–Ω—ã—Ö."
            )
            return sorted(facts, key=self._score_fact, reverse=True)[: self.MAX_FACTS]

        # 2. —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É
        sorted_facts = sorted(non_proc, key=self._score_fact, reverse=True)

        # 3. –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ
        return sorted_facts[: self.MAX_FACTS]

    # =======================================================
    # 1. –§–∏–ª—å—Ç—Ä —à—É–º–æ–≤—ã—Ö pseudo-person –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
    # =======================================================
    def _is_noise_fake_person(self, fact: LegalFact) -> bool:
        """
        –£–¥–∞–ª—è–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –≤–∏–¥–∞:
        ¬´–ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º—ã–π –í–æ–µ–Ω–Ω–æ–æ–±—è–∑–∞–Ω–Ω—ã–π –ù–∞–ª–∏—á–∏–µ¬ª
        ¬´–ø–æ—Ç–µ—Ä–ø–µ–≤—à–∏–π –†–µ—Å–ø—É–±–ª–∏–∫–∞ –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω¬ª
        """

        text = (fact.text or "").lower()

        # –µ—Å–ª–∏ —ç—Ç–æ –≤–∞–∂–Ω–∞—è –∫—Ä–∏–º–∏–Ω–∞–ª—å–Ω–∞—è —Ä–æ–ª—å ‚Äî –ù–ï —É–¥–∞–ª—è–µ–º
        if (fact.role or "").lower() in self.ALWAYS_KEEP_ROLES:
            return False

        # –µ—Å–ª–∏ –Ω–µ—Ç person-—Ç–æ–∫–µ–Ω–æ–≤ ‚Äî –Ω–µ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ–º –∫–∞–∫ fake-person
        if not any(t.type == "person" for t in (fact.tokens or [])):
            return False

        # –µ—Å–ª–∏ –µ—Å—Ç—å –∫—Ä–∏–º–∏–Ω–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã ‚Üí —ç—Ç–æ –ù–ï –º—É—Å–æ—Ä
        types = {t.type for t in (fact.tokens or [])}
        if types.intersection(self.CRIME_TOKEN_TYPES):
            return False

        # –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç —à—É–º–æ–≤—ã–µ —à–∞–±–ª–æ–Ω—ã ‚Üí —É–¥–∞–ª—è–µ–º
        for noise in self.NOISE_PERSON_PHRASES:
            if noise in text:
                return True

        return False

    # =======================================================
    # 2. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–æ—Ü–µ—Å—Å—É–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–∫—Ç–∞
    # =======================================================
    def _is_processual_fact(self, fact: LegalFact) -> bool:
        role = (fact.role or "").lower()

        # 0) –≤–∞–∂–Ω—ã–µ —Ä–æ–ª–∏ –ù–ï —É–¥–∞–ª—è–µ–º
        if role in self.ALWAYS_KEEP_ROLES:
            return False

        text = (fact.text or fact.span_text or "").lower()
        tokens = fact.tokens or []
        token_types = {t.type for t in tokens}

        # 1) –ø—Ä–æ—Ü–µ—Å—Å—É–∞–ª—å–Ω—ã–π —Ñ–ª–∞–≥ –±–µ–∑ –∫—Ä–∏–º–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è
        if "processual_flag" in token_types:
            if not token_types.intersection(self.CRIME_TOKEN_TYPES):
                return True
            return False

        # 2) —Ç–µ–∫—Å—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –ø—Ä–æ—Ü–µ—Å—Å—É–∞–ª—å–Ω—ã–µ —Ñ—Ä–∞–∑—ã
        if any(kw in text for kw in self.PROCESSUAL_KEYWORDS):
            # –Ω–æ –≤ —Ç–µ–∫—Å—Ç–µ –Ω–µ—Ç –∫—Ä–∏–º–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è ‚Üí –ø—Ä–æ—Ü–µ—Å—Å—É–∞–ª–∫–∞
            if not token_types.intersection(self.CRIME_TOKEN_TYPES):
                return True
            return False

        return False

    # =======================================================
    # 3. –ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏—è —Ñ–∞–∫—Ç–æ–≤
    # =======================================================
    def _score_fact(self, fact: LegalFact) -> int:
        role = (fact.role or "").lower()
        tokens = fact.tokens or []
        token_types = {t.type for t in tokens}

        score = 0

        # –†–û–õ–ï–í–ê–Ø –ò–ï–†–ê–†–•–ò–Ø
        ROLE_SCORES = {
            "suspect_action": 130,
            "fraud_action": 125,
            "fraud_event": 120,
            "investment_event": 110,
            "investment_context": 105,
            "scheme_marker": 105,
            "crypto_operation": 100,
            "economic_action": 95,
            "digital_transfer": 90,
            "victim_loss": 90,
            "money_transfer": 90,

            "entity_reference": 60,
            "admin_action": 60,
            "victim_statement": 35,
            "role_statement": 25,
            "generic_fact": 15,
        }

        score += ROLE_SCORES.get(role, 10)

        # —Ç–æ–∫–µ–Ω—ã
        TOKEN_SCORES = {
            "amount": 20,
            "fraud_flag": 22,
            "invest_flag": 20,
            "scheme_flag": 18,
            "economic_flag": 16,
            "crypto_flag": 18,
            "crypto": 20,
            "channel": 14,
            "account": 14,

            "project": 16,
            "platform": 16,
            "organization": 14,
            "entity": 14,

            "date": 5,
            "phone": 4,
            "article_ref": 6,
            "person": 2,
            "address": 1,
        }

        for t in token_types:
            score += TOKEN_SCORES.get(t, 1)

        # confidence
        conf = getattr(fact, "confidence", 0.0) or 0.0
        if conf > 0.85:
            score += 18
        elif conf > 0.6:
            score += 12
        elif conf > 0.35:
            score += 6

        # —É—Å–∏–ª–µ–Ω–∏–µ —Å—Ö–µ–º / –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–π / –ø–µ—Ä–µ–≤–æ–¥–æ–≤
        if "invest_flag" in token_types and (
            "amount" in token_types or
            "economic_flag" in token_types or
            "channel" in token_types or
            "account" in token_types
        ):
            score += 22

        if "scheme_flag" in token_types and ("project" in token_types or "platform" in token_types):
            score += 18

        if "amount" in token_types:
            if role == "suspect_action":
                score += 35
            elif role == "fraud_action":
                score += 25
            elif role == "investment_event":
                score += 22

        return score
