from __future__ import annotations
from typing import List, Tuple, Dict, Set
from app.services.facts.fact_models import LegalFact, FactToken, SourceRef


class FactGraph:

    # =====================================================================
    # ğŸ“˜ ĞÑĞ½Ğ¾Ğ²Ğ½Ğ°Ñ Ñ‚Ğ¾Ñ‡ĞºĞ° Ğ²Ñ…Ğ¾Ğ´Ğ°
    # =====================================================================
    def build(self, facts: List[LegalFact]) -> List[LegalFact]:
        """
        Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ¸Ñ€Ğ¾Ğ²ĞºĞ° Ğ¿Ğ¾ Ñ€Ğ¾Ğ»Ğ¸, Ğ·Ğ°Ñ‚ĞµĞ¼ Ğ°ĞºĞºÑƒÑ€Ğ°Ñ‚Ğ½Ğ¾Ğµ ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ¾Ğ±ÑŠĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğµ.
        """
        if not facts:
            return []

        merged: List[LegalFact] = []
        bucket: Dict[str, List[LegalFact]] = {}

        # 1. Ğ³Ñ€ÑƒĞ¿Ğ¿Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¿Ğ¾ Ñ€Ğ¾Ğ»Ğ¸
        for f in facts:
            bucket.setdefault(f.role, []).append(f)

        # 2. Ğ¾Ğ±ÑŠĞµĞ´Ğ¸Ğ½ÑĞµĞ¼ Ğ² Ğ¿Ñ€ĞµĞ´ĞµĞ»Ğ°Ñ… Ñ€Ğ¾Ğ»Ğ¸
        for role, items in bucket.items():
            merged.extend(self._merge_role_facts(items))

        return merged

    # =====================================================================
    # ğŸ“˜ Ğ¡ĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ¾Ğ±ÑŠĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğµ Ñ„Ğ°ĞºÑ‚Ğ¾Ğ² Ğ¾Ğ´Ğ¸Ğ½Ğ°ĞºĞ¾Ğ²Ğ¾Ğ¹ Ñ€Ğ¾Ğ»Ğ¸
    # =====================================================================
    def _merge_role_facts(self, facts: List[LegalFact]) -> List[LegalFact]:
        """
        ĞĞ¾Ğ²Ñ‹Ğ¹ ĞºĞ»ÑÑ‡ Ğ¾Ğ±ÑŠĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ñ:
            â€¢ Ğ½Ğ°Ğ±Ğ¾Ñ€ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ² (type, value)
            â€¢ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ span_text (Ğ±ĞµĞ· Ğ¿Ñ€Ğ¾Ğ±ĞµĞ»Ğ¾Ğ²)
            â€¢ sentence_index (Ğ´Ğ»Ñ Ğ·Ğ°Ñ‰Ğ¸Ñ‚Ñ‹ Ğ¾Ñ‚ Ğ»Ğ¾Ğ¶Ğ½Ğ¾Ğ³Ğ¾ merge)
        """
        if not facts:
            return []

        unique_map: Dict[Tuple, LegalFact] = {}

        for f in facts:
            tokens_key = tuple(sorted((t.type, t.value) for t in f.tokens))
            span_key = self._normalize_span(f.span_text)
            sent_key = f.sentence_index

            merge_key = (tokens_key, span_key, sent_key)

            if merge_key not in unique_map:
                unique_map[merge_key] = f
                continue

            existing = unique_map[merge_key]

            # ------------------------------------------------------
            # 1) Ğ¾Ğ±ÑŠĞµĞ´Ğ¸Ğ½ÑĞµĞ¼ source_refs
            # ------------------------------------------------------
            old_src = {(s.file_id, s.page) for s in existing.source_refs}
            new_src = {(s.file_id, s.page) for s in f.source_refs}
            combined = old_src | new_src

            existing.source_refs = [
                SourceRef(file_id=fid, page=pg) for fid, pg in combined
            ]

            # ------------------------------------------------------
            # 2) Ğ¾Ğ±ÑŠĞµĞ´Ğ¸Ğ½ÑĞµĞ¼ Ñ‚Ğ¾ĞºĞµĞ½Ñ‹ (Ğ½Ğµ Ğ´Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Ğ´ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ‚Ğ¾Ğ²)
            # ------------------------------------------------------
            seen = {(t.type, t.value) for t in existing.tokens}
            for t in f.tokens:
                if (t.type, t.value) not in seen:
                    existing.tokens.append(t)
                    seen.add((t.type, t.value))

            # ------------------------------------------------------
            # 3) Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ÑĞµĞ¼ span_text ĞºĞ°Ğº Ñƒ existing (Ğ³Ğ»Ğ°Ğ²Ğ½Ğ¾Ğ³Ğ¾)
            #    context_before / after Ñ‚Ğ¾Ğ¶Ğµ Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ÑĞµĞ¼
            # ------------------------------------------------------

            # ------------------------------------------------------
            # 4) Ğ¾Ğ±ÑŠĞµĞ´Ğ¸Ğ½ÑĞµĞ¼ article_hints
            # ------------------------------------------------------
            hints = set(existing.article_hints or []) | set(f.article_hints or [])
            existing.article_hints = list(sorted(hints))

        return list(unique_map.values())

    # =====================================================================
    # ğŸ“˜ ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ span_text â€” Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ merge Ğ±Ñ‹Ğ» Ñ‚Ğ¾Ñ‡Ğ½Ñ‹Ğ¼
    # =====================================================================
    def _normalize_span(self, span: str) -> str:
        if not span:
            return ""
        s = span.lower().strip()
        s = " ".join(s.split())
        return s
