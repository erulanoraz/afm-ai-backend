# app/services/agents/ai_extractor.py
"""
AI Extractor 3.0 (—Å SUPER PRE-FILTER)

–¶–µ–ª—å:
‚Ä¢ –ù–ï —É–¥–∞–ª—è—Ç—å —Ñ–∞–±—É–ª—É, –Ω–æ —É–¥–∞–ª—è—Ç—å:
    ‚Äî –¥–∏–∞–ª–æ–≥–∏ (–í–æ–ø—Ä–æ—Å / –û—Ç–≤–µ—Ç)
    ‚Äî –∞–Ω–∫–µ—Ç–Ω—ã–µ –±–ª–æ–∫–∏ (–§–ò–û, –≥—Ä–∞–∂–¥–∞–Ω—Å—Ç–≤–æ‚Ä¶)
    ‚Äî —Å–ª—É–∂–µ–±–Ω—ã–π –º—É—Å–æ—Ä ("–¥–æ–ø—Ä–æ—Å –æ–∫–æ–Ω—á–µ–Ω", –ø–æ–¥–ø–∏—Å–∏)
    ‚Äî —Å—Ç—Ä–æ–∫–∏ –ø–æ—Ç–µ—Ä–ø–µ–≤—à–∏—Ö, –∫–æ—Ç–æ—Ä—ã–µ –±–µ—Å–ø–æ–ª–µ–∑–Ω—ã
‚Ä¢ –¥–∞–≤–∞—Ç—å ai_qualifier'—É –ß–ò–°–¢–´–ï –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
‚Ä¢ –Ω–µ –ª–æ–º–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –ª–æ–≥–∏–∫—É
"""

import re
import logging
from collections import defaultdict
from datetime import datetime

logger = logging.getLogger(__name__)

# ============================================================
# üî• SUPER PRE-FILTER 2.0 ‚Äî –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞
# ============================================================

DIALOG_QUESTIONS = [
    r"–≤–æ–ø—Ä–æ—Å —Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª[—è–π]:?",
    r"–≤–æ–ø—Ä–æ—Å:?",
    r"—Å–ø—Ä–æ—Å–∏–ª–∏:?",
]

DIALOG_ANSWERS = [
    r"–æ—Ç–≤–µ—Ç –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º[–∞-—è—ë]:?",
    r"–æ—Ç–≤–µ—Ç –ø–æ—Ç–µ—Ä–ø–µ–≤—à[–∞-—è—ë]:?",
    r"–æ—Ç–≤–µ—Ç —Å–≤–∏–¥–µ—Ç–µ–ª[—è–π]:?",
    r"–æ—Ç–≤–µ—Ç:?",
]

SERVICE_GARBAGE = [
    r"–Ω–∞ —ç—Ç–æ–º –¥–æ–ø—Ä–æ—Å .*? –æ–∫–æ–Ω—á[–µ—ë]–Ω",
    r"–¥–æ–∫—É–º–µ–Ω—Ç –ø–æ–¥–≥–æ—Ç–æ–≤–∏–ª.*",
    r"–¥–æ–∫—É–º–µ–Ω—Ç –ø–æ–¥–ø–∏—Å–∞–Ω.*",
    r"–æ—Ä–¥–µ—Ä ‚Ññ.*",
    r"–ø—Ä–∏–ª–æ–∂–µ–Ω–∏[–µ—è].*",
    r"–ø—Ä–æ—Ç–æ–∫–æ–ª –¥–æ–ø—Ä–æ—Å–∞.*",
    r"—É–≤–µ–¥–æ–º–ª–µ–Ω.*?",
]

PERSON_TECH_LINES = [
    r"—Ñ–∞–º–∏–ª–∏—è[,:\s]",
    r"–∏–º—è[,:\s]",
    r"–æ—Ç—á–µ—Å—Ç–≤–æ[,:\s]",
    r"–≥—Ä–∞–∂–¥–∞–Ω—Å—Ç–≤–æ[,:\s]",
    r"–Ω–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å[,:\s]",
    r"—Å–µ–º–µ–π–Ω–æ–µ –ø–æ–ª–æ–∂–µ–Ω–∏–µ[,:\s]",
    r"–º–µ—Å—Ç–æ —Ä–∞–±–æ—Ç—ã.*?:",
    r"–º–µ—Å—Ç–æ –∂–∏—Ç–µ–ª—å—Å—Ç–≤–∞.*?:",
    r"–º–µ—Å—Ç–æ —Ä–æ–∂–¥–µ–Ω–∏—è.*?:",
    r"–¥–∞—Ç–∞ —Ä–æ–∂–¥–µ–Ω–∏—è.*?:",
]

VICTIM_NOISE = [
    r"–ø–æ—Ç–µ—Ä–ø–µ–≤—à[–∞-—è—ë]*:?$",
    r"–Ω–∞ —ç—Ç–æ–º –¥–æ–ø—Ä–æ—Å –ø–æ—Ç–µ—Ä–ø–µ–≤—à–µ–≥–æ –æ–∫–æ–Ω—á[–µ—ë]–Ω",
]

def super_pre_filter(text: str) -> list[str]:
    """
    –ü—Ä–∏–Ω–∏–º–∞–µ—Ç —Å—ã—Ä–æ–π —Ç–µ–∫—Å—Ç —á–∞–Ω–∫–∞.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –æ—á–∏—â–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π.
    """
    if not text or len(text.strip()) < 3:
        return []

    t = text.strip()

    # 1) –£–¥–∞–ª—è–µ–º —Å–ª—É–∂–µ–±–Ω—ã–π –º—É—Å–æ—Ä
    for pattern in SERVICE_GARBAGE + VICTIM_NOISE:
        t = re.sub(pattern, "", t, flags=re.IGNORECASE)

    # 2) –£–¥–∞–ª—è–µ–º –¥–∏–∞–ª–æ–≥–æ–≤—ã–µ –º–∞—Ä–∫–µ—Ä—ã
    for pattern in DIALOG_QUESTIONS + DIALOG_ANSWERS:
        t = re.sub(pattern, "", t, flags=re.IGNORECASE)

    # 3) –£–¥–∞–ª—è–µ–º –∞–Ω–∫–µ—Ç–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
    for pattern in PERSON_TECH_LINES:
        t = re.sub(pattern, "", t, flags=re.IGNORECASE)

    # 4) –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
    sentences = re.split(r"(?<=[\.\?\!])\s+", t)

    cleaned = []
    for s in sentences:
        s = s.strip()

        if not s or len(s) < 5:
            continue

        # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Ç–∏–ø–∞ "–ò–≤–∞–Ω–æ–≤ –ò.–ò."
        if re.fullmatch(r"[–ê-–ØA-Z–Å”ò”®“ö“Æ“∞“¢][–∞-—èa-z—ë”ô”©“õ“Ø“±“£]+ [–ê-–ØA-Z]\.[–ê-–ØA-Z]\.", s):
            continue

        cleaned.append(s)

    return cleaned


# ============================================================
# üß† –ë–ê–ó–û–í–´–ï –†–ï–ì–£–õ–Ø–†–ö–ò
# ============================================================

DATE_REGEX = r"\b(\d{1,2}\.\d{1,2}\.\d{4})\b"
AMOUNT_REGEX = r"\b(\d[\d\s]{0,15}\s?(?:—Ç–µ–Ω–≥–µ|—Ç–≥|‚Ç∏|kzt|usd|usdt|eur|—Ä—É–±(?:\.|–ª–µ–π)?))\b"

# ‚Ä¢ –§–∞–º–∏–ª–∏—è –ò–º—è –û—Ç—á–µ—Å—Ç–≤–æ
# ‚Ä¢ –§–∞–º–∏–ª–∏—è –ò–º—è
# ‚Ä¢ –§–∞–º–∏–ª–∏—è –ò.–û.
# ‚Ä¢ –§–∞–º–∏–ª–∏—è–ò.–û. (—Å –∏–Ω–∏—Ü–∏–∞–ª–∞–º–∏ —Å–ª–∏—Ç–Ω–æ)
PERSON_REGEX = r"""
(
    [A-Z–ê-–Ø”ò–Ü“¢“í“Æ“∞“ö”®“∫][a-z–∞-—è”ô—ñ“£“ì“Ø“±“õ”©“ª—ë]+          # –§–∞–º–∏–ª–∏—è
    \s+
    [A-Z–ê-–Ø”ò–Ü“¢“í“Æ“∞“ö”®“∫][a-z–∞-—è”ô—ñ“£“ì“Ø“±“õ”©“ª—ë]*          # –ò–º—è
    (?:\s+[A-Z–ê-–Ø”ò–Ü“¢“í“Æ“∞“ö”®“∫][a-z–∞-—è”ô—ñ“£“ì“Ø“±“õ”©“ª—ë]*)?  # –û—Ç—á–µ—Å—Ç–≤–æ
)
|
(
    [A-Z–ê-–Ø”ò–Ü“¢“í“Æ“∞“ö”®“∫][a-z–∞-—è”ô—ñ“£“ì“Ø“±“õ”©“ª—ë]+          # –§–∞–º–∏–ª–∏—è
    \s*
    [A-Z–ê-–Ø”ò–Ü“¢“í“Æ“∞“ö”®“∫]\.[A-Z–ê-–Ø”ò–Ü“¢“í“Æ“∞“ö”®“∫]\.        # –ò–Ω–∏—Ü–∏–∞–ª—ã (–ö.–¢.)
)
"""

# ============================================================
# üî• –ö–ê–¢–ï–ì–û–†–ò–ò –î–ï–ô–°–¢–í–ò–ô (—É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–µ —Ç—Ä–∏–≥–≥–µ—Ä—ã)
# ============================================================

CRIMINAL_ACTIONS = {
    "money_transfer": [
        "–ø–µ—Ä–µ–≤–µ–ª", "–ø–µ—Ä–µ–≤—ë–ª", "–ø–µ—Ä–µ–≤–µ–ª–∞", "–ø–µ—Ä–µ—á–∏—Å–ª–∏–ª", "–ø–µ—Ä–µ—á–∏—Å–ª–∏–ª–∞",
        "–æ—Ç–ø—Ä–∞–≤–∏–ª", "–æ—Ç–ø—Ä–∞–≤–∏–ª–∞", "–ø–æ–ª—É—á–∏–ª", "–ø–æ–ª—É—á–∏–ª–∞",
        "–ø–µ—Ä–µ–≤–æ–¥", "–ø–æ–ª—É—á–µ–Ω–∏–µ —Å—Ä–µ–¥—Å—Ç–≤", "–∑–∞—á–∏—Å–ª–µ–Ω–∏–µ", "–ø–æ—Å—Ç—É–ø–ª–µ–Ω–∏–µ —Å—Ä–µ–¥—Å—Ç–≤",
    ],
    "withdrawal": [
        "–≤—ã–≤–µ–ª", "–≤—ã–≤–µ–ª–∞", "—Å–Ω—è–ª", "—Å–Ω—è–ª–∞",
        "–≤—ã–≤–æ–¥ —Å—Ä–µ–¥—Å—Ç–≤", "—Å–Ω—è—Ç–∏–µ –Ω–∞–ª–∏—á–Ω—ã—Ö", "–æ–±–Ω–∞–ª–∏—á–∏–ª", "–æ–±–Ω–∞–ª–∏—á–∏–ª–∞",
    ],
    "investment": [
        "–≤–Ω–µ—Å", "–≤–Ω—ë—Å", "–≤–Ω–µ—Å–ª–∞", "–≤–ª–æ–∂–∏–ª", "–≤–ª–æ–∂–∏–ª–∞", "–∏–Ω–≤–µ—Å—Ç–∏—Ä–æ–≤–∞–ª",
        "–∏–Ω–≤–µ—Å—Ç–∏—Ä–æ–≤–∞–ª–∞", "–ø–æ–ø–æ–ª–Ω–∏–ª", "–ø–æ–ø–æ–ª–Ω–∏–ª–∞",
        "–±–∞–ª–∞–Ω—Å", "–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏—è", "–ø–æ–ø–æ–ª–Ω–µ–Ω–∏–µ", "–¥–µ–ø–æ–∑–∏—Ç",
    ],
    "fraud_signals": [
        "–æ–±–º–∞–Ω", "–æ–±–º–∞–Ω—É–ª", "–æ–±–º–∞–Ω—É–ª–∞", "–≤–≤–µ–ª –≤ –∑–∞–±–ª—É–∂–¥–µ–Ω–∏–µ", "–≤–≤—ë–ª –≤ –∑–∞–±–ª—É–∂–¥–µ–Ω–∏–µ",
        "–≤–≤–µ–ª –≤ –∑–∞–±–ª—É–∂–¥–µ–Ω–∏", "–Ω–µ –≤–µ—Ä–Ω—É–ª–∏", "–Ω–µ –ø–æ–ª—É—á–∏–ª", "–Ω–µ –ø–æ–ª—É—á–∏–ª–∞",
        "–¥–µ–Ω—å–≥–∏ –ø—Ä–æ–ø–∞–ª–∏", "–æ—Ç–∫–∞–∑–∞–ª–∏ –≤ –≤—ã–≤–æ–¥–µ", "–æ—Ç–∫–∞–∑–∞–ª–∏ –≤ –≤–æ–∑–≤—Ä–∞—Ç–µ",
        "–æ–±–º–∞–Ω–Ω—ã–º –ø—É—Ç–µ–º", "–æ–±–º–∞–Ω–Ω—ã–º –ø—É—Ç—ë–º",
    ],
    "pyramid_activity": [
        "–ø–ª–∞—Ç—Ñ–æ—Ä–º", "–ø—Ä–∏–ª–æ–∂–µ–Ω–∏", "–∑–∞–¥–∞–Ω–∏–µ",
        "–∏–Ω–≤–µ—Å—Ç", "–≥—Ä—É–ø–ø–∞", "—á–∞—Ç", "–≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏", "—Ä–µ—Ñ–µ—Ä–∞–ª—å–Ω",
        "–ø–∏—Ä–∞–º–∏–¥–∞", "–ø–ª–∞—Ç–µ–∂–Ω—ã–µ –ø–æ—Ä—É—á–µ–Ω–∏—è", "—Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è",
    ],
}

# ============================================================
# üö´ –¢–ï–•–ù–ò–ß–ï–°–ö–ò–ô –ú–£–°–û–† (–º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π, –±–µ–∑–æ–ø–∞—Å–Ω—ã–π)
# ============================================================

BANNED_PATTERNS = [
    "qr-–∫–æ–¥", "qr –∫–æ–¥",
    "—ç—Ü–ø", "ecp",
    "—ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç",
    "–∫–æ–¥ –¥–æ–∫—É–º–µ–Ω—Ç–∞",
    "–¥–∞—Ç–æ–π –∏ –≤—Ä–µ–º–µ–Ω–µ–º –ø–æ–¥–ø–∏—Å–∞–Ω–∏—è",
    "–ø–æ–¥–ø–∏—Å—å –Ω–∞–ª–æ–∂–µ–Ω–∞",
    "–ø—Ä–æ—Å–º–æ—Ç—Ä–µ–Ω–æ", "–¥–∞—Ç–∞ –ø–µ—á–∞—Ç–∏",
]

# ============================================================
# üõ†Ô∏è –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –£–¢–ò–õ–ò–¢–´
# ============================================================

def _split_sentences(text: str) -> list[str]:
    """
    –ü—Ä–æ—Å—Ç–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –ø–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º.
    –ù–µ –∏–¥–µ–∞–ª—å–Ω–æ, –Ω–æ –≥–ª–∞–≤–Ω–æ–µ ‚Äî –ù–ï —É–Ω–∏—á—Ç–æ–∂–∞—Ç—å —Ç–µ–∫—Å—Ç.
    """
    if not text:
        return []
    # —Ç–æ—á–∫–∏, ?, ! + –ø–µ—Ä–µ–Ω–æ—Å—ã
    parts = re.split(r"(?<=[\.\?!])\s+", text)
    return [p.strip() for p in parts if p and len(p.strip()) > 2]


def _is_technical_noise(sentence: str) -> bool:
    """
    –£–±–∏—Ä–∞–µ–º —á–∏—Å—Ç–æ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –º—É—Å–æ—Ä (QR, –≠–¶–ü, —Å–ª—É–∂–µ–±–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏).
    –ù–∏–∫–∞–∫–∏—Ö –∂—ë—Å—Ç–∫–∏—Ö —Ñ–∏–ª—å—Ç—Ä–æ–≤ –ø–æ —Ñ–∞–±—É–ª–µ!
    """
    lt = sentence.lower()
    if len(lt) < 5:
        return True

    if any(p in lt for p in BANNED_PATTERNS):
        return True

    # —Å—É–ø–µ—Ä-—Ç–µ—Ö —Å—Ç—Ä–æ–∫–∏ —Ç–∏–ø–∞ "—Å—Ç—Ä. 1 –∏–∑ 5"
    if re.search(r"—Å—Ç—Ä–∞–Ω–∏—Ü[–∞—ã]?\s+\d+\s+–∏–∑\s+\d+", lt):
        return True

    return False


# ============================================================
# üë§ –ù–û–†–ú–ê–õ–ò–ó–ê–¶–ò–Ø –§–ò–û
# ============================================================

def normalize_persons(persons: list[str]) -> dict:
    """
    –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –§–ò–û –ø–æ —Ñ–∞–º–∏–ª–∏—è–º, —á—Ç–æ–±—ã –Ω–µ –ø–ª–æ–¥–∏—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã.
    """
    clusters = defaultdict(list)
    for p in persons:
        clean = re.sub(r"\s+", " ", p).strip()
        if not clean:
            continue
        base = clean.lower()
        key = base.split()[0]  # —Ñ–∞–º–∏–ª–∏—è –∫–∞–∫ –∫–ª—é—á
        clusters[key].append(clean)
    return {k: list(set(v)) for k, v in clusters.items()}


# ============================================================
# üß© –†–û–õ–ò
# ============================================================

ROLE_MAP = {
    "suspect": [
        "–ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º", "–ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ—Ç—Å—è", "–ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º–æ–º—É",
        "–æ–±–≤–∏–Ω—è–µ–º", "–≤ –æ—Ç–Ω–æ—à–µ–Ω–∏–∏", "–∑–∞–¥–µ—Ä–∂–∞–Ω", "–ø–æ–¥—Å–ª–µ–¥—Å—Ç–≤–µ–Ω",
        "–∫“Ø–¥—ñ–∫—Ç—ñ", "–∫“Ø–¥—ñ–∫—Ç—ñ–Ω—ñ“£", "–∫“Ø–¥—ñ–∫—Ç—ñ–≥–µ",
    ],
    "victim": [
        "–ø–æ—Ç–µ—Ä–ø–µ–≤—à", "–∂”ô–±—ñ—Ä–ª–µ–Ω—É—à",
    ],
    "witness": [
        "—Å–≤–∏–¥–µ—Ç–µ–ª", "–∫—É”ô–≥–µ—Ä",
    ],
}

def extract_roles(facts: list[dict], persons: list[str]) -> dict:
    """
    –ü—ã—Ç–∞–µ–º—Å—è –ø—Ä–∏–≤—è–∑–∞—Ç—å –§–ò–û –∫ —Ä–æ–ª—è–º –ø–æ –æ–∫—Ä—É–∂–µ–Ω–∏—é —Ç–µ–∫—Å—Ç–∞.
    """
    roles = defaultdict(list)
    normalized = normalize_persons(persons)

    for f in facts:
        txt = (f.get("text") or "").lower()
        if not txt:
            continue

        for key, variants in normalized.items():
            if not variants:
                continue

            # –µ—Å–ª–∏ —Ñ–∞–º–∏–ª–∏—è —Ñ–∏–≥—É—Ä–∏—Ä—É–µ—Ç –≤ —Ç–µ–∫—Å—Ç–µ ‚Äî –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º, –∫—Ç–æ –æ–Ω
            if key in txt:
                for role, markers in ROLE_MAP.items():
                    if any(m in txt for m in markers):
                        roles[role].extend(variants)
                        break

    # –µ—Å–ª–∏ –∫–æ–≥–æ-—Ç–æ –Ω–µ –æ—Ç–Ω–µ—Å–ª–∏ –Ω–∏–∫—É–¥–∞ ‚Äî OTHER
    for key, variants in normalized.items():
        already = set()
        for rlist in roles.values():
            for v in rlist:
                already.add(v)
        for v in variants:
            if v not in already:
                roles["other"].append(v)

    # —É–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
    return {r: list(sorted(set(vs))) for r, vs in roles.items() if vs}


# ============================================================
# üîç –ü–û–ò–°–ö –ü–û–î–û–ó–†–ï–í–ê–ï–ú–û–ì–û
# ============================================================

def detect_suspect(all_sentences: list[str], persons_from_facts: list[str]) -> str | None:
    """
    –õ–æ–≥–∏–∫–∞:
        1) –ò—â–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ, –≥–¥–µ –µ—Å—Ç—å "–ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º"/"–æ–±–≤–∏–Ω—è–µ–º"/"–≤ –æ—Ç–Ω–æ—à–µ–Ω–∏–∏".
        2) –í –Ω—ë–º –∏—â–µ–º –§–ò–û.
        3) –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ ‚Äî –±–µ—Ä—ë–º –ø–µ—Ä–≤–æ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞ –∏–∑ roles['suspect'] (–ø–æ–∑–∂–µ).
    """
    markers = [
        "–ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º", "–ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ—Ç—Å—è", "–ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º–æ–º—É",
        "–æ–±–≤–∏–Ω—è–µ–º", "–≤ –æ—Ç–Ω–æ—à–µ–Ω–∏–∏", "–∑–∞–¥–µ—Ä–∂–∞–Ω",
        "–≤ –∫–∞—á–µ—Å—Ç–≤–µ –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º–æ–≥–æ",
        "–∫“Ø–¥—ñ–∫—Ç—ñ", "–∫“Ø–¥—ñ–∫—Ç—ñ–Ω—ñ“£", "–∫“Ø–¥—ñ–∫—Ç—ñ–≥–µ",
    ]

    # 1-–π –ø—Ä–æ—Ö–æ–¥ ‚Äî –∏—â–µ–º –§–ò–û –≤ "–ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º—ã—Ö" –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö
    for s in all_sentences:
        lt = s.lower()
        if not any(m in lt for m in markers):
            continue

        persons = re.findall(PERSON_REGEX, s, flags=re.VERBOSE)
        if not persons:
            continue

        for group in persons:
            for item in group:
                if item.strip():
                    cand = re.sub(r"\s+", " ", item.strip())
                    logger.info(f"üîé detect_suspect: –Ω–∞–π–¥–µ–Ω –∫–∞–Ω–¥–∏–¥–∞—Ç –∏–∑ —Ç–µ–∫—Å—Ç–∞: {cand}")
                    return cand

    # 2-–π –ø—Ä–æ—Ö–æ–¥ ‚Äî fallback: –µ—Å–ª–∏ —Å–ø–∏—Å–æ–∫ persons_from_facts –º–∞–ª–µ–Ω—å–∫–∏–π, –±–µ—Ä—ë–º –ø–µ—Ä–≤–æ–≥–æ
    if persons_from_facts:
        cand = re.sub(r"\s+", " ", persons_from_facts[0]).strip()
        logger.info(f"üîé detect_suspect: fallback –ø–æ –ø–µ—Ä–≤–æ–º—É –ª–∏—Ü—É: {cand}")
        return cand

    logger.warning("‚ö†Ô∏è detect_suspect: –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º—ã–π –Ω–µ –Ω–∞–π–¥–µ–Ω")
    return None


# ============================================================
# üß± –ò–ó–í–õ–ï–ß–ï–ù–ò–ï –°–û–ë–´–¢–ò–ô
# ============================================================

def extract_events(sentences: list[str]) -> list[dict]:
    """
    –î–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –¥–µ–ª–∞–µ–º –æ–±—ä–µ–∫—Ç —Å–æ–±—ã—Ç–∏—è:
        {
            "text": str,
            "action": one of CRIMINAL_ACTIONS keys or None,
            "amounts": [..],
            "persons": [..raw..],
            "date": "DD.MM.YYYY" or None
        }
    –ù–ò–ß–ï–ì–û –Ω–µ —É–¥–∞–ª—è–µ–º, –¥–∞–∂–µ –µ—Å–ª–∏ action = None.
    """
    events: list[dict] = []

    for s in sentences:
        if not s or _is_technical_noise(s):
            continue

        lt = s.lower()

        dates = re.findall(DATE_REGEX, s)
        amounts = re.findall(AMOUNT_REGEX, s)
        persons_raw = re.findall(PERSON_REGEX, s, flags=re.VERBOSE)

        # –≤—ã–ø—Ä—è–º–ª—è–µ–º PERSON_REGEX —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        persons: list[str] = []
        for group in persons_raw:
            for item in group:
                item = item.strip()
                if item:
                    persons.append(re.sub(r"\s+", " ", item))

        action = None
        for action_type, words in CRIMINAL_ACTIONS.items():
            if any(w in lt for w in words):
                action = action_type
                break

        events.append({
            "text": s.strip(),
            "action": action,
            "amounts": amounts,
            "persons": persons,
            "date": dates[0] if dates else None,
        })

    logger.info(f"üìå extract_events: —Å–æ–±—ã—Ç–∏–π={len(events)}")
    return events


# ============================================================
# üîó FLOW (—Å—Ç—É–ø–µ–Ω–∏ —Ä–∞–∑–≤–∏—Ç–∏—è —Å–æ–±—ã—Ç–∏—è)
# ============================================================

def build_crime_flow(events: list[dict]) -> list[dict]:
    """
    –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º "—Å—ã—Ä–æ–π" —Å–ø–∏—Å–æ–∫ —Å–æ–±—ã—Ç–∏–π –≤ –ø–æ–Ω—è—Ç–Ω—ã–µ —à–∞–≥–∏:
        –≤–ª–æ–∂–µ–Ω–∏–µ ‚Üí –ø–µ—Ä–µ–≤–æ–¥ ‚Üí –ø–æ–ø—ã—Ç–∫–∞ –≤—ã–≤–æ–¥–∞ ‚Üí –æ–±–º–∞–Ω/–Ω–µ–≤–æ–∑–≤—Ä–∞—Ç ‚Üí ...
    """
    flow: list[dict] = []

    mapping = {
        "investment": "–≤–ª–æ–∂–µ–Ω–∏–µ —Å—Ä–µ–¥—Å—Ç–≤",
        "money_transfer": "–ø–µ—Ä–µ–≤–æ–¥ —Å—Ä–µ–¥—Å—Ç–≤",
        "withdrawal": "–ø–æ–ø—ã—Ç–∫–∞ –≤—ã–≤–æ–¥–∞",
        "fraud_signals": "–æ–±–º–∞–Ω / –Ω–µ–≤–æ–∑–≤—Ä–∞—Ç",
        "pyramid_activity": "—É—á–∞—Å—Ç–∏–µ –≤ —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–π —Å—Ö–µ–º–µ",
    }

    for e in events:
        step = mapping.get(e["action"])
        if not step:
            continue

        flow.append({
            "step": step,
            "amount": ", ".join(e["amounts"]),
            "text": e["text"],
            "date": e["date"],
        })

    logger.info(f"üìå build_crime_flow: —à–∞–≥–æ–≤={len(flow)}")
    return flow


# ============================================================
# üìÖ –¢–ê–ô–ú–õ–ê–ô–ù
# ============================================================

def build_timeline(events: list[dict]) -> list[dict]:
    """
    –°–æ—Ä—Ç–∏—Ä—É–µ–º —Å–æ–±—ã—Ç–∏—è –ø–æ –¥–∞—Ç–µ (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–∞).
    """
    result: list[tuple[datetime, dict]] = []

    for e in events:
        d = e.get("date")
        if not d:
            continue
        try:
            dt = datetime.strptime(d, "%d.%m.%Y")
            result.append((dt, e))
        except Exception:
            # –µ—Å–ª–∏ —Ñ–æ—Ä–º–∞—Ç —Å—Ç—Ä–∞–Ω–Ω—ã–π ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
            continue

    result.sort(key=lambda x: x[0])
    timeline = [e for _, e in result]
    logger.info(f"üìå build_timeline: —Å–æ–±—ã—Ç–∏–π —Å –¥–∞—Ç–æ–π={len(timeline)}")
    return timeline


# ============================================================
# ‚öñÔ∏è –Æ–†–ò–î–ò–ß–ï–°–ö–ò –ó–ù–ê–ß–ò–ú–´–ï –§–ê–ö–¢–´
# ============================================================

def extract_legal_facts(events: list[dict], roles: dict) -> dict:
    legal = {
        "subject": roles.get("suspect", []),
        "objective_side": [],
        "damage": [],
        "method": [],
        "intent": None,
        "motive": None,
    }

    for e in events:
        txt = (e.get("text") or "").lower()

        if e.get("amounts"):
            legal["damage"].extend(e["amounts"])

        if e.get("action"):
            legal["objective_side"].append(
                f"{e['action']} ({', '.join(e['amounts'])})".strip("() ")
            )

        if "—Å —Ü–µ–ª—å—é" in txt and not legal["motive"]:
            after = txt.split("—Å —Ü–µ–ª—å—é", 1)[1]
            legal["motive"] = after[:150].strip()

        if "–ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω" in txt and not legal["intent"]:
            legal["intent"] = "–ø—Ä—è–º–æ–π —É–º—ã—Å–µ–ª (–ø–æ –æ–ø–∏—Å–∞–Ω–∏—é —Å–æ–±—ã—Ç–∏–π)"

    # —É–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
    legal["damage"] = list(sorted(set(legal["damage"])))
    legal["objective_side"] = list(sorted(set(legal["objective_side"])))

    logger.info(
        f"üìå extract_legal_facts: subject={legal['subject']}, "
        f"damage={len(legal['damage'])}, obj_side={len(legal['objective_side'])}"
    )
    return legal


# ============================================================
# üî• –û–ü–†–ï–î–ï–õ–ï–ù–ò–ï –¢–ò–ü–ê –ü–†–ï–°–¢–£–ü–õ–ï–ù–ò–Ø
# ============================================================

def detect_crime_type(events: list[dict]) -> str:
    blob = " ".join(e.get("text", "").lower() for e in events)

    if any(w in blob for w in CRIMINAL_ACTIONS["fraud_signals"]):
        return "–º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–æ"

    if any(w in blob for w in CRIMINAL_ACTIONS["pyramid_activity"]):
        return "—Ñ–∏–Ω–∞–Ω—Å–æ–≤–∞—è —Å—Ö–µ–º–∞"

    if any(w in blob for w in CRIMINAL_ACTIONS["investment"]):
        return "–Ω–µ–∑–∞–∫–æ–Ω–Ω–æ–µ –ø—Ä–∏–≤–ª–µ—á–µ–Ω–∏–µ —Å—Ä–µ–¥—Å—Ç–≤"

    if any(w in blob for w in CRIMINAL_ACTIONS["withdrawal"]):
        return "–ø—Ä–µ–ø—è—Ç—Å—Ç–≤–∏–µ –≤—ã–≤–æ–¥—É —Å—Ä–µ–¥—Å—Ç–≤ / –æ—Ç–∫–∞–∑ –≤ –≤—ã–≤–æ–¥–µ"

    if any(w in blob for w in CRIMINAL_ACTIONS["money_transfer"]):
        return "–¥–≤–∏–∂–µ–Ω–∏–µ –¥–µ–Ω–µ–∂–Ω—ã—Ö —Å—Ä–µ–¥—Å—Ç–≤"

    return "–Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ"

# ============================================================
# üîç –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
# ============================================================

def is_meaningful(sentence: str) -> bool:
    """
    –ú—è–≥–∫–∏–π —Ñ–∏–ª—å—Ç—Ä –≤–∞–∂–Ω–æ—Å—Ç–∏.
    –ù–ï —É–¥–∞–ª—è–µ—Ç —Ñ–∞–±—É–ª—É, —Ç–æ–ª—å–∫–æ —à—É–º.
    """
    if not sentence:
        return False

    s = sentence.lower().strip()
    if len(s) < 5:
        return False

    # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π —à—É–º ‚Äî —Å—Ä–∞–∑—É –≤ –º—É—Å–æ—Ä
    if any(p in s for p in BANNED_PATTERNS):
        return False

    # –ï—Å–ª–∏ —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–ª—é—á–µ–≤—ã–µ —Ç—Ä–∏–≥–≥–µ—Ä—ã –ø—Ä–µ—Å—Ç—É–ø–ª–µ–Ω–∏—è ‚Äî –≤—Å–µ–≥–¥–∞ OK
    for group in CRIMINAL_ACTIONS.values():
        if any(w in s for w in group):
            return True

    # –ï—Å–ª–∏ –µ—Å—Ç—å –¥–µ–Ω—å–≥–∏ / —Å—É–º–º—ã ‚Äî OK
    if re.search(AMOUNT_REGEX, s):
        return True

    # –ï—Å–ª–∏ –µ—Å—Ç—å –§–ò–û ‚Äî OK
    if re.search(PERSON_REGEX, s, flags=re.VERBOSE):
        return True

    # –ï—Å–ª–∏ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ñ—Ä–∞–∑—ã –ø—Ä–æ –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º–æ–≥–æ ‚Äî OK
    suspect_markers = [
        "–ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º", "–ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ—Ç—Å—è", "–≤ –æ—Ç–Ω–æ—à–µ–Ω–∏–∏",
        "–æ–±–≤–∏–Ω—è–µ–º", "–∑–∞–¥–µ—Ä–∂–∞–Ω",
        "–∫“Ø–¥—ñ–∫—Ç—ñ", "–∫“Ø–¥—ñ–∫—Ç—ñ–Ω—ñ“£", "–∫“Ø–¥—ñ–∫—Ç—ñ–≥–µ",
        "–≤ –∫–∞—á–µ—Å—Ç–≤–µ –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º–æ–≥–æ",
    ]
    if any(m in s for m in suspect_markers):
        return True

    # –ü–æ—Ç–µ—Ä–ø–µ–≤—à–∏–µ
    if "–ø–æ—Ç–µ—Ä–ø–µ–≤—à" in s or "–∂”ô–±—ñ—Ä–ª–µ–Ω—É—à" in s:
        return True

    # –§—Ä–∞–∑—ã –ø—Ä–æ –¥–µ–π—Å—Ç–≤–∏—è / —É—á–∞—Å—Ç–∏–µ
    if any(x in s for x in ["–ø–ª–∞—Ç—Ñ–æ—Ä–º", "–∏–Ω–≤–µ—Å—Ç", "–≥—Ä—É–ø–ø–∞", "—á–∞—Ç", "–≤—ã–≤–æ–¥", "–≤–ª–æ–∂"]):
        return True

    # –í—Å—ë –æ—Å—Ç–∞–ª—å–Ω–æ–µ ‚Äî –ù–ï —É–¥–∞–ª—è–µ–º, –Ω–æ –∫–∞–∫ meaningful –Ω–µ —Å—á–∏—Ç–∞–µ–º
    return False


# ============================================================
# üß© –ì–õ–ê–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø extract_all() ‚Äî –î–û–†–ê–ë–û–¢–ê–ù–ê
# ============================================================

def extract_all(facts, persons, dates, amounts):
    """
    –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è.
    –î–û–ë–ê–í–õ–ï–ù–û:
    ‚Äî super_pre_filter() –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –∫ –∫–∞–∂–¥–æ–º—É —Ñ–∞–∫—Ç—É
    ‚Äî fact["sentences"] –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–∞–ª—å—à–µ
    """

    safe = []
    for f in facts or []:
        if not isinstance(f, dict):
            continue

        txt = f.get("text") or ""
        if len(txt.strip()) < 3:
            continue

        # üî• –î–û–ë–ê–í–õ–ï–ù–û: PRE-FILTER
        f["sentences"] = super_pre_filter(txt)

        safe.append(f)

    facts = safe
    if not facts:
        return {
            "roles": {},
            "events": [],
            "timeline": [],
            "legal_facts": {
                "subject": [],
                "objective_side": [],
                "damage": [],
                "method": [],
                "intent": None,
                "motive": None,
            },
            "suspects": [],
            "primary_suspect": None,
            "crime_flow": [],
            "crime_type": "–Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ",
        }

    persons = persons or []
    dates = dates or []
    amounts = amounts or []

    # ---------------------------------------------------------
    # –°–±–æ—Ä –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
    # ---------------------------------------------------------
    all_sentences = []
    for f in facts:
        all_sentences.extend(f["sentences"])

    all_sentences = [s for s in all_sentences if isinstance(s, str) and s.strip()]

    # –ú—è–≥–∫–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Ñ–∞–±—É–ª—ã
    filtered = [s for s in all_sentences if is_meaningful(s)]
    if not filtered:
        filtered = all_sentences

    # ---------------------------------------------------------
    # –†–æ–ª–∏
    # ---------------------------------------------------------
    roles = extract_roles(facts, persons)

    suspects_list = roles.get("suspect", []) or []

    primary_suspect = detect_suspect(all_sentences, persons)
    if primary_suspect and primary_suspect not in suspects_list:
        suspects_list.append(primary_suspect)

    suspects_list = list(dict.fromkeys(suspects_list))

    # ---------------------------------------------------------
    # –°–æ–±—ã—Ç–∏—è ‚Üí —Ç–∞–π–º–ª–∞–π–Ω ‚Üí flow ‚Üí —é—Ä.—Ñ–∞–∫—Ç—ã ‚Üí —Ç–∏–ø
    # ---------------------------------------------------------
    events = extract_events(filtered) or extract_events(all_sentences)
    timeline = build_timeline(events)
    crime_flow = build_crime_flow(events)
    legal_facts = extract_legal_facts(events, roles)
    crime_type = detect_crime_type(events)

    return {
        "roles": roles,
        "events": events,
        "timeline": timeline,
        "legal_facts": legal_facts,
        "suspects": suspects_list,
        "primary_suspect": primary_suspect,
        "crime_flow": crime_flow,
        "crime_type": crime_type,
    }
