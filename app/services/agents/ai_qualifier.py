# –õ–æ–≥–∏–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏–∏ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –∑–¥–µ—Å—å:
# backend/app/services/agents/ai_qualifier.py

from __future__ import annotations

import logging
import re
import uuid
from collections import defaultdict
from datetime import datetime
from typing import Any, Dict, List, Optional

from fastapi import HTTPException

from app.utils.config import settings
from app.services.validation.verifier import run_full_verification
from app.services.agents.ai_laws import ALL_AFM_LAWS
from app.services.agents.ai_extractor import extract_all
from app.services.llm_client import LLMClient
from app.services.agents import prompts
from app.services.reranker import LLMReranker

logger = logging.getLogger(__name__)

# ============================================================
# ‚öôÔ∏è –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ / –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã
# ============================================================

MODEL_VERSION = "qualifier-llm-2.1-fixed"
MIN_FACT_CONFIDENCE = 0.5
CONTEXT_RADIUS = 60

# LLM-–∫–ª–∏–µ–Ω—Ç (–æ–±—â–∏–π –∞–¥–∞–ø—Ç–µ—Ä)
_llm_client = LLMClient()

# ============================================================
# üß© –ö–∞—Å—Ç–æ–º–Ω—ã–µ –æ—à–∏–±–∫–∏
# ============================================================

class LLMUnavailableError(Exception):
    """–ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –∏–ª–∏ –æ—à–∏–±–∫–µ LLM."""
    pass

# ============================================================
# üîå –û–±—ë—Ä—Ç–∫–∞ –Ω–∞–¥ LLMClient (–µ–¥–∏–Ω–∞—è —Ç–æ—á–∫–∞ –≤—ã–∑–æ–≤–∞)
# ============================================================

def _ask_llm(
    prompt: str,
    system_prompt: Optional[str] = None,
) -> str:
    """
    –í—ã–∑–æ–≤ LLM —á–µ—Ä–µ–∑ –æ–±—â–∏–π –∫–ª–∏–µ–Ω—Ç.
    –ï—Å–ª–∏ LLM –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω / –≤–µ—Ä–Ω—É–ª –æ—à–∏–±–∫—É ‚Äî –ø–æ–¥–Ω–∏–º–∞–µ–º LLMUnavailableError.
    """
    messages: List[Dict[str, str]] = []
    if system_prompt:
        messages.append({"role": "system", "content": system_prompt})
    messages.append({"role": "user", "content": prompt})

    try:
        content = _llm_client.chat(messages)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤—ã–∑–æ–≤–∞ LLM: {e}")
        raise LLMUnavailableError(str(e))

    if not content or (isinstance(content, str) and content.startswith("[LLM ERROR]")):
        raise LLMUnavailableError(content or "–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç LLM")

    return content.strip()

# ============================================================
# üßÆ –†–µ–≥—É–ª—è—Ä–∫–∏ –¥–ª—è –ø–µ—Ä–≤–∏—á–Ω–æ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
# ============================================================

PERSON_RX = re.compile(
    r"\b([–ê-–Ø–Å][–∞-—è—ë]+(?:\s+[–ê-–Ø–Å]\.){1,2}|[–ê-–Ø–Å][–∞-—è—ë]+(?:\s+[–ê-–Ø–Å][–∞-—è—ë]+){1,2})\b"
)
DATE_RX = re.compile(r"\b(\d{1,2}[./-]\d{1,2}[./-]\d{2,4}|\d{4}-\d{2}-\d{2})\b")
MONEY_RX = re.compile(
    r"(?:(\d{1,3}(?:\s?\d{3})+|\d+)(?:[.,]\d{1,2})?)\s?(?:—Ç–≥|—Ç–µ–Ω–≥–µ|KZT|‚Ç∏)",
    re.IGNORECASE,
)
ART_RX = re.compile(
    r"(—Å—Ç\.?|—Å—Ç–∞—Ç—å[—å—è–∏])\s*([0-9]{1,3}(?:[-‚Äì][0-9]+)?)(?:\s*(–£–ö|–£–ü–ö|–ì–ö)\s*–†–ö)?",
    re.IGNORECASE,
)

EVENT_HINTS = [
    "–ø–µ—Ä–µ–≤–µ–ª", "–ø–µ—Ä–µ–≤–µ–ª–∞", "–ø–µ—Ä–µ–≤—ë–ª", "–ø–µ—Ä–µ—á–∏—Å–ª–∏–ª", "–ø–µ—Ä–µ—á–∏—Å–ª–∏–ª–∞",
    "–æ—Ç–ø—Ä–∞–≤–∏–ª", "–æ—Ç–ø—Ä–∞–≤–∏–ª–∞",
    "–≤–Ω–µ—Å", "–≤–Ω–µ—Å–ª–∞", "–≤–Ω–µ—Å–µ–Ω—ã", "–ø–æ–ø–æ–ª–Ω–∏–ª", "–ø–æ–ø–æ–ª–Ω–∏–ª–∞",
    "–≤–ª–æ–∂–∏–ª", "–≤–ª–æ–∂–∏–ª–∞",
    "–ø–æ–ª—É—á–∏–ª", "–ø–æ–ª—É—á–∏–ª–∞", "–ø–æ–ª—É—á–µ–Ω–∏–µ —Å—Ä–µ–¥—Å—Ç–≤",
    "–≤—ã–≤–µ–ª", "–≤—ã–≤–µ–ª–∞", "–≤—ã–≤–æ–¥ —Å—Ä–µ–¥—Å—Ç–≤", "—Å–Ω—è–ª", "—Å–Ω—è–ª–∞", "—Å–Ω—è—Ç–∏–µ –Ω–∞–ª–∏—á–Ω—ã—Ö",
    "–Ω–µ –≤–µ—Ä–Ω—É–ª", "–Ω–µ –≤–µ—Ä–Ω—É–ª–∏", "–¥–µ–Ω—å–≥–∏ –ø—Ä–æ–ø–∞–ª–∏",
    "–æ–±–º–∞–Ω—É–ª", "–æ–±–º–∞–Ω", "–≤–≤–µ–ª –≤ –∑–∞–±–ª—É–∂–¥–µ–Ω–∏–µ",
    "–∑–∞–∫–ª—é—á–∏–ª –¥–æ–≥–æ–≤–æ—Ä", "–∑–∞–∫–ª—é—á–∏–ª–∞ –¥–æ–≥–æ–≤–æ—Ä", "–æ—Ñ–æ—Ä–º–∏–ª –¥–æ–≥–æ–≤–æ—Ä", "–æ—Ñ–æ—Ä–º–ª–µ–Ω–∞ —Å–¥–µ–ª–∫–∞",
    "—Ö–∏—â–µ–Ω–∏–µ", "–º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–æ", "–Ω–µ–∑–∞–∫–æ–Ω–Ω–æ–µ –æ–±–æ–≥–∞—â–µ–Ω–∏–µ", "–ø—Ä–∏—Å–≤–æ–µ–Ω–∏–µ",
]

# ============================================================
# üîé –§–∏–ª—å—Ç—Ä —á–∏—Å—Ç–æ –ø—Ä–æ—Ü–µ—Å—Å—É–∞–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
# ============================================================

def _is_procedural(text: str) -> bool:
    """–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å—É–∞–ª—å–Ω—ã—Ö —Ñ—Ä–∞–∑: –ø—Ä–∞–≤–∞, —Ä–∞–∑—ä—è—Å–Ω–µ–Ω–∏—è, –£–ü–ö, —Å–ª—É–∂–µ–±–Ω—ã–µ —á–∞—Å—Ç–∏."""
    t = text.lower()

    blocked = [
        "–ø–æ—Ç–µ—Ä–ø–µ–≤—à–∏–π –∏–º–µ–µ—Ç –ø—Ä–∞–≤–æ",
        "–ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º—ã–π –∏–º–µ–µ—Ç –ø—Ä–∞–≤–æ",
        "—Ä–∞–∑—ä—è—Å–Ω–µ–Ω—ã –ø—Ä–∞–≤–∞",
        "—Ä–∞–∑—ä—è—Å–Ω–∏–ª –ø—Ä–∞–≤–∞",
        "—Ä–∞–∑—ä—è—Å–Ω–∏–ª–∞ –ø—Ä–∞–≤–∞",
        "—Ä–∞–∑—ä—è—Å–Ω–µ–Ω—ã –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏",
        "—É–≥–æ–ª–æ–≤–Ω–æ-–ø—Ä–æ—Ü–µ—Å—Å—É–∞–ª—å–Ω—ã–π –∫–æ–¥–µ–∫—Å",
        "—É–ø–∫ —Ä–∫",
        "–≤–æ–ø—Ä–æ—Å:",
        "–æ—Ç–≤–µ—Ç:",
        "–æ–ø—Ä–æ—Å–∏–ª", "–¥–æ–ø—Ä–æ—Å–∏–ª",
        "–ø—Ä–æ—Ç–æ–∫–æ–ª –¥–æ–ø—Ä–æ—Å–∞",
        "—É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ",
        "–ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω", "–ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∞",
        "–∏–∑–≤–µ—â–µ–Ω",
        "–∫–∞–±–∏–Ω–µ—Ç–∞ ‚Ññ", "–∫–∞–±–∏–Ω–µ—Ç ‚Ññ",
        "—Å–ª–µ–¥—Å—Ç–≤–µ–Ω–Ω—ã–π —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç",
        "–≤–∏–¥–µ–æ–∑–∞–ø–∏—Å—å", "–∞—É–¥–∏–æ–∑–∞–ø–∏—Å—å",
        "–∑–≤—É–∫–æ- –∏ (–∏–ª–∏) –≤–∏–¥–µ–æ–∑–∞–ø–∏—Å—å",
    ]

    tech = [
        "qr-–∫–æ–¥", "qr –∫–æ–¥",
        "—ç—Ü–ø", "ecp",
        "—ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç",
        "–¥–∞—Ç–∞ –∏ –≤—Ä–µ–º—è –ø–æ–¥–ø–∏—Å–∞–Ω–∏—è",
        "–ø–æ–¥–ø–∏—Å—å –Ω–∞–ª–æ–∂–µ–Ω–∞",
    ]

    return any(b in t for b in blocked) or any(tk in t for tk in tech)

# ============================================================
# üß± FACT-BUILDER 3.0 ‚Äî —Å—Ç—Ä–æ–≥–∏–π —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–π —Ä–µ–∂–∏–º
# ============================================================

SENTENCE_SPLIT_RX = re.compile(r"(?<=[\.\?\!])\s+")

def _split_sentences(text: str) -> List[str]:
    """–ê–∫–∫—É—Ä–∞—Ç–Ω–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è."""
    if not text:
        return []
    parts = SENTENCE_SPLIT_RX.split(text)
    return [p.strip() for p in parts if len(p.strip()) > 0]

def _is_procedural_sentence(t: str) -> bool:
    """–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ñ–∏–ª—å—Ç—Ä —á–∏—Å—Ç–æ –ø—Ä–æ—Ü–µ—Å—Å—É–∞–ª—å–Ω—ã—Ö —Ñ—Ä–∞–∑."""
    lt = t.lower()

    blocked = [
        "–ø–æ—Ç–µ—Ä–ø–µ–≤—à–∏–π –∏–º–µ–µ—Ç –ø—Ä–∞–≤–æ",
        "–ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º—ã–π –∏–º–µ–µ—Ç –ø—Ä–∞–≤–æ",
        "—Ä–∞–∑—ä—è—Å–Ω–µ–Ω—ã –ø—Ä–∞–≤–∞",
        "–µ–º—É —Ä–∞–∑—ä—è—Å–Ω–µ–Ω—ã –ø—Ä–∞–≤–∞",
        "–µ–π —Ä–∞–∑—ä—è—Å–Ω–µ–Ω—ã –ø—Ä–∞–≤–∞",
        "—Ä–∞–∑—ä—è—Å–Ω–µ–Ω—ã –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏",
        "—É–≥–æ–ª–æ–≤–Ω–æ-–ø—Ä–æ—Ü–µ—Å—Å—É–∞–ª—å–Ω—ã–π –∫–æ–¥–µ–∫—Å",
        "—Å—Ç. 64 —É–ø–∫ —Ä–∫",
        "—Å—Ç. 71 —É–ø–∫ —Ä–∫",
        "—Å—Ç. 73 —É–ø–∫ —Ä–∫",
        "–≤–æ–ø—Ä–æ—Å:", "–æ—Ç–≤–µ—Ç:",
        "–¥–æ–ø—Ä–æ—Å –Ω–∞—á–∞—Ç", "–¥–æ–ø—Ä–æ—Å –æ–∫–æ–Ω—á–µ–Ω",
        "—Å–ª–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ –Ω–∞—á–∞—Ç–æ",
        "—Å–ª–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ –æ–∫–æ–Ω—á–µ–Ω–æ",
        "–∫–∞–±–∏–Ω–µ—Ç ‚Ññ", "—Å–ª—É–∂–µ–±–Ω—ã–π –∫–∞–±–∏–Ω–µ—Ç",
        "–∞—É–¥–∏–æ–∑–∞–ø–∏—Å—å", "–≤–∏–¥–µ–æ–∑–∞–ø–∏—Å—å",
        "–∑–≤—É–∫–æ- –∏ (–∏–ª–∏) –≤–∏–¥–µ–æ–∑–∞–ø–∏—Å—å",
    ]

    tech = [
        "qr-–∫–æ–¥", "qr –∫–æ–¥",
        "—ç—Ü–ø", "ecp",
        "—ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç",
        "–¥–∞—Ç–∞ –∏ –≤—Ä–µ–º—è –ø–æ–¥–ø–∏—Å–∞–Ω–∏—è",
        "–ø–æ–¥–ø–∏—Å—å –Ω–∞–ª–æ–∂–µ–Ω–∞",
    ]

    return any(b in lt for b in blocked) or any(tk in lt for tk in tech)

def _is_fact_sentence(t: str) -> bool:
    """–ö—Ä–∏—Ç–µ—Ä–∏–π: –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –°–£–©–ï–°–¢–í–ï–ù–ù–´–ô —Ñ–∞–∫—Ç (–¥–µ–Ω—å–≥–∏, –¥–µ–π—Å—Ç–≤–∏—è, —Ä–æ–ª—å, —É—â–µ—Ä–± –∏ —Ç.–ø.)."""
    if not t:
        return False

    lt = t.lower().strip()
    if len(lt) < 15:
        return False

    # –≤—ã–∫–∏–¥—ã–≤–∞–µ–º —á–∏—Å—Ç–æ –ø—Ä–æ—Ü–µ—Å—Å—É–∞–ª—å–Ω—ã–µ —Ñ—Ä–∞–∑—ã
    if _is_procedural_sentence(lt):
        return False

    # 1) –£–ø–æ–º–∏–Ω–∞–Ω–∏–µ –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º–æ–≥–æ / –ø–æ—Ç–µ—Ä–ø–µ–≤—à–µ–≥–æ / —Å–≤–∏–¥–µ—Ç–µ–ª—è
    if any(w in lt for w in ["–ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º", "–æ–±–≤–∏–Ω—è–µ–º", "–ø–æ—Ç–µ—Ä–ø–µ–≤—à", "—Å–≤–∏–¥–µ—Ç–µ–ª"]):
        return True

    # 2) –ü—Ä—è–º—ã–µ –¥–µ–π—Å—Ç–≤–∏—è —Å –¥–µ–Ω—å–≥–∞–º–∏
    money_actions = [
        "–≤–Ω–µ—Å", "–≤–Ω–µ—Å–ª–∞", "–≤–Ω–µ—Å–µ–Ω—ã",
        "–ø–µ—Ä–µ–≤–µ–ª", "–ø–µ—Ä–µ–≤–µ–ª–∞", "–ø–µ—Ä–µ—á–∏—Å–ª–∏–ª", "–ø–µ—Ä–µ—á–∏—Å–ª–∏–ª–∞",
        "–ø–µ—Ä–µ–¥–∞–ª", "–ø–µ—Ä–µ–¥–∞–ª–∞",
        "–æ—Ç–ø—Ä–∞–≤–∏–ª", "–æ—Ç–ø—Ä–∞–≤–∏–ª–∞",
        "–ø–æ–ø–æ–ª–Ω–∏–ª", "–ø–æ–ø–æ–ª–Ω–∏–ª–∞",
        "—Å–Ω—è–ª", "—Å–Ω—è–ª–∞", "–≤—ã–≤–µ–ª", "–≤—ã–≤–µ–ª–∞",
        "–ø–æ–ª—É—á–∏–ª", "–ø–æ–ª—É—á–∏–ª–∞",
    ]
    if any(w in lt for w in money_actions):
        return True

    # 3) –£—â–µ—Ä–± / –ø–æ—Ç–µ—Ä—è / –Ω–µ–≤–æ–∑–≤—Ä–∞—Ç
    if any(w in lt for w in ["—É—â–µ—Ä–±", "–¥–µ–Ω–µ–≥ –Ω–µ –≤–µ—Ä–Ω—É–ª–∏", "–¥–µ–Ω—å–≥–∏ –ø—Ä–æ–ø–∞–ª–∏", "–Ω–µ –≤–µ—Ä–Ω—É–ª–∏ –¥–µ–Ω—å–≥–∏"]):
        return True

    # 4) –ü—Ä–∏–∑–Ω–∞–∫–∏ –æ–±–º–∞–Ω–∞ / –ø–∏—Ä–∞–º–∏–¥—ã / –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–π
    if any(w in lt for w in ["–æ–±–º–∞–Ω", "–≤–≤–µ–ª –≤ –∑–∞–±–ª—É–∂–¥–µ–Ω–∏–µ", "–≤–ª–æ–∂–∏–ª", "–≤–ª–æ–∂–∏–ª–∞", "–∏–Ω–≤–µ—Å—Ç–∏—Ü", "–¥–æ—Ö–æ–¥", "–≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω"]):
        return True

    # 5) –Ø–≤–Ω–æ–µ –Ω–∞–ª–∏—á–∏–µ —Å—É–º–º—ã –¥–µ–Ω–µ–≥
    if MONEY_RX.search(t):
        return True

    # 6) –•—Ä–æ–Ω–æ–ª–æ–≥–∏—è/—Å–æ–±—ã—Ç–∏—è
    if any(w in lt for w in ["–ø—Ä–æ–∏–∑–æ—à–ª–æ", "—Å–ª—É—á–∏–ª–æ—Å—å", "–ø–æ—Å–ª–µ —ç—Ç–æ–≥–æ", "–≤ –¥–∞–ª—å–Ω–µ–π—à–µ–º", "–≤ —Ç–æ—Ç –∂–µ –¥–µ–Ω—å"]):
        return True

    # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å—á–∏—Ç–∞–µ–º –Ω–µ —Ñ–∞–∫—Ç–æ–º
    return False


# ============================================================
# üîé –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –§–ò–û –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º–æ–≥–æ (–ù–û–í–û–ï)
# ============================================================

def _extract_suspect_name(facts: List[dict], docs: List[Dict[str, Any]]) -> Optional[str]:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –§–ò–û –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º–æ–≥–æ –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.
    –ò—â–µ—Ç —è–≤–Ω—ã–µ –º–∞—Ä–∫–µ—Ä—ã:
    - "–ü–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º—ã–π –§–ò–û"
    - "–í –æ—Ç–Ω–æ—à–µ–Ω–∏–∏ –§–ò–û –≤–æ–∑–±—É–∂–¥–µ–Ω–æ"
    - "–ó–∞–¥–µ—Ä–∂–∞–Ω –≥—Ä–∞–∂–¥–∞–Ω–∏–Ω –§–ò–û"
    - "–ü—Ä–∏–∑–Ω–∞–Ω –≤ –∫–∞—á–µ—Å—Ç–≤–µ –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º–æ–≥–æ –§–ò–û"
    """
    patterns = [
        r"–ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º—ã–π(?:–æ–≥–æ)?(?:\s+–≤\s+—Å–æ–≤–µ—Ä—à–µ–Ω–∏–∏)?[:\s]+([–ê-–Ø–Å][–∞-—è—ë]+(?:\s+[–ê-–Ø–Å]\.[–ê-–Ø–Å]\.)?)",
        r"–≤\s+–æ—Ç–Ω–æ—à–µ–Ω–∏–∏\s+([–ê-–Ø–Å][–∞-—è—ë]+(?:\s+[–ê-–Ø–Å]\.[–ê-–Ø–Å]\.)?)\s+(?:–≤–æ–∑–±—É–∂–¥–µ–Ω–æ|–≤–æ–∑–±—É–∂–¥–µ–Ω|–ø—Ä–æ–≤–æ–¥–∏—Ç—Å—è)",
        r"–∑–∞–¥–µ—Ä–∂–∞–Ω(?:\s+–≥—Ä–∞–∂–¥–∞–Ω–∏–Ω)?\s+([–ê-–Ø–Å][–∞-—è—ë]+(?:\s+[–ê-–Ø–Å]\.[–ê-–Ø–Å]\.)?)",
        r"–ø—Ä–∏–∑–Ω–∞–Ω\s+–≤\s+–∫–∞—á–µ—Å—Ç–≤–µ\s+–ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º–æ–≥–æ\s+([–ê-–Ø–Å][–∞-—è—ë]+(?:\s+[–ê-–Ø–Å]\.[–ê-–Ø–Å]\.)?)",
        r"—É–≥–æ–ª–æ–≤–Ω–æ–µ\s+–¥–µ–ª–æ\s+–≤\s+–æ—Ç–Ω–æ—à–µ–Ω–∏–∏\s+([–ê-–Ø–Å][–∞-—è—ë]+(?:\s+[–ê-–Ø–Å]\.[–ê-–Ø–Å]\.)?)",
    ]
    
    # –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö –Ω–∞–ø—Ä—è–º—É—é
    for doc in docs:
        text = (doc.get("text") or "").strip()
        if not text:
            continue
        
        for pattern in patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                name = match.group(1).strip()
                if len(name) > 3:
                    logger.info(f"‚úÖ –ü–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º—ã–π –Ω–∞–π–¥–µ–Ω: {name}")
                    return name
    
    # Fallback: –∏—â–µ–º –≤ —Ñ–∞–∫—Ç–∞—Ö
    for fact in facts:
        t = fact.get("text", "").lower()
        for pattern in patterns:
            match = re.search(pattern, t, re.IGNORECASE)
            if match:
                name = match.group(1).strip()
                if len(name) > 3:
                    logger.info(f"‚úÖ –ü–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º—ã–π –Ω–∞–π–¥–µ–Ω –≤ —Ñ–∞–∫—Ç–∞—Ö: {name}")
                    return name
    
    logger.warning("‚ö†Ô∏è –§–ò–û –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º–æ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö")
    return None

# ============================================================
# üë§ –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–æ–ª–∏ –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º–æ–≥–æ (–ù–û–í–û–ï)
# ============================================================

def _determine_suspect_role(facts: List[dict], suspect_name: Optional[str]) -> Optional[str]:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ä–æ–ª—å –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º–æ–≥–æ –≤ –ø—Ä–µ—Å—Ç—É–ø–ª–µ–Ω–∏–∏."""
    if not facts or not suspect_name:
        return None
    
    text_all = " ".join(f.get("text", "").lower() for f in facts)
    
    role_patterns = {
        "–æ—Ä–≥–∞–Ω–∏–∑–∞—Ç–æ—Ä": [
            "–æ—Ä–≥–∞–Ω–∏–∑", "—Ä—É–∫–æ–≤–æ–¥", "—Å–æ–∑–¥–∞–ª —Å—Ö–µ–º—É",
            "–∏–Ω–∏—Ü–∏–∏—Ä–æ–≤–∞–ª", "–Ω–∞—á–∞–ª –ø—Ä–∏–≤–ª–µ—á–µ–Ω–∏–µ", "–≥–ª–∞–≤–Ω—ã–π", "–≤–æ–∑–≥–ª–∞–≤–ª—è–µ—Ç"
        ],
        "–∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä": [
            "–∞–¥–º–∏–Ω–∏—Å—Ç—Ä", "—É–ø—Ä–∞–≤–ª—è–ª –ø–ª–∞—Ç—Ñ–æ—Ä–º–æ–π", "–∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä–æ–≤–∞–ª",
            "–º–æ–¥–µ—Ä–∞—Ç–æ—Ä", "—É–ø—Ä–∞–≤–ª—è—é—â–∏–π", "–≤–µ–¥–µ–Ω–∏–µ –∞–∫–∫–∞—É–Ω—Ç–∞", "—É–ø—Ä–∞–≤–ª—è–µ—Ç"
        ],
        "–∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å": [
            "—Å–æ–≤–µ—Ä—à–∏–ª", "–≤–Ω–µ—Å –¥–µ–Ω—å–≥–∏", "–ø–µ—Ä–µ—á–∏—Å–ª–∏–ª", "–ø–µ—Ä–µ–¥–∞–ª —Å—Ä–µ–¥—Å—Ç–≤–∞",
            "–≤–ª–æ–∂–∏–ª", "–ø—Ä–∏–≤–ª–µ–∫–∞–ª", "–≤–æ–≤–ª–µ–∫–∞–ª", "—É—á–∞—Å—Ç–≤–æ–≤–∞–ª"
        ],
        "—Å–æ—É—á–∞—Å—Ç–Ω–∏–∫": [
            "–≤–º–µ—Å—Ç–µ —Å", "—Å–æ–≤–º–µ—Å—Ç–Ω–æ", "—Å–æ–¥–µ–π—Å—Ç–≤–æ–≤–∞–ª", "—Å–æ—É—á–∞—Å—Ç",
            "–ø–æ–º–æ–≥–∞–ª", "—Å–æ–¥–µ–π—Å—Ç–≤–∏–µ", "—É—á–∞—Å—Ç–≤–æ–≤–∞–ª —Å–æ–≤–º–µ—Å—Ç–Ω–æ"
        ],
    }
    
    scores = {}
    for role, keywords in role_patterns.items():
        scores[role] = sum(1 for kw in keywords if kw in text_all)
    
    best_role = max(scores, key=scores.get) if scores else None
    if best_role and scores[best_role] > 0:
        logger.info(f"üë§ –†–æ–ª—å –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º–æ–≥–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞: {best_role}")
        return best_role
    
    return None

def _looks_like_interrogation_doc(doc: Dict[str, Any]) -> bool:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –ø–æ—Ö–æ–∂ –ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç –Ω–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª –¥–æ–ø—Ä–æ—Å–∞/–æ–ø—Ä–æ—Å–∞/–æ–±—ä—è—Å–Ω–µ–Ω–∏—è."""
    name = (doc.get("filename") or "").lower()
    t0 = (doc.get("text") or "").lower()[:400]

    return (
        any(k in name for k in ["–¥–æ–ø—Ä–æ—Å", "–æ–ø—Ä–æ—Å", "–æ–±—ä—è—Å–Ω", "–ø–æ—è—Å–Ω–µ–Ω"])
        or "–ø—Ä–æ—Ç–æ–∫–æ–ª –¥–æ–ø—Ä–æ—Å–∞" in t0
        or "–ø—Ä–æ—Ç–æ–∫–æ–ª –æ–ø—Ä–æ—Å–∞" in t0
    )

def _clean_interrogation_text(raw: str) -> str:
    """
    –£–±–∏—Ä–∞–µ—Ç —à–∞–ø–∫—É, –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –∏ –≤–æ–ø—Ä–æ—Å—ã –∏–∑ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ –¥–æ–ø—Ä–æ—Å–∞.
    –û—Å—Ç–∞–≤–ª—è–µ—Ç —Ç–æ–ª—å–∫–æ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –æ—Ç–≤–µ—Ç—ã –∏ –ø–æ–≤–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ.
    """
    lines = raw.splitlines()
    cleaned: list[str] = []
    in_body = False

    for line in lines:
        l = line.strip()

        if not l:
            continue

        low = l.lower()

        # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —à–∞–ø–∫—É –∏ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
        if any(k in low for k in [
            "–ø–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º —Å–ª–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –¥–µ–π—Å—Ç–≤–∏—è",
            "—Ä–∞–∑—ä—è—Å–Ω–µ–Ω—ã –ø—Ä–∞–≤–∞",
            "–ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω", "–ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∞",
            "–æ–± –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏ –ø–æ —Å—Ç.",
            "–µ–º—É —Ä–∞–∑—ä—è—Å–Ω–µ–Ω–æ", "–µ–π —Ä–∞–∑—ä—è—Å–Ω–µ–Ω–æ",
            "–∫–æ–ø–∏—é –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ –ø–æ–ª—É—á–∏–ª",
        ]):
            continue

        # —É–±–∏—Ä–∞–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –≤–æ–ø—Ä–æ—Å–∞–º–∏
        if low.startswith("–≤–æ–ø—Ä–æ—Å:") or low.startswith("–≤–æ–ø—Ä–æ—Å ‚Ññ"):
            continue

        # —Å—á–∏—Ç–∞–µ–º, —á—Ç–æ —Ç–µ–ª–æ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å –ø–µ—Ä–≤—ã—Ö "–ø–æ—è—Å–Ω–∏–ª/–ø–æ—è—Å–Ω–∏–ª–∞/—Å–æ–æ–±—â–∏–ª"
        if not in_body and any(k in low for k in ["–ø–æ—è—Å–Ω–∏–ª", "–ø–æ—è—Å–Ω–∏–ª–∞", "—Å–æ–æ–±—â–∏–ª", "—Å–æ–æ–±—â–∏–ª–∞", "–ø–æ–∫–∞–∑–∞–ª", "–ø–æ–∫–∞–∑–∞–ª–∞"]):
            in_body = True

        if in_body:
            cleaned.append(l)

    # –µ—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —è–≤–Ω–æ–µ —Ç–µ–ª–æ ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç (–ª—É—á—à–µ —á–µ–º –≤—ã–∫–∏–Ω—É—Ç—å –≤—Å—ë)
    return "\n".join(cleaned) if cleaned else raw

# ============================================================
# üîé –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ñ–∞–∫—Ç–æ–≤ –∏ –±–∞–∑–æ–≤—ã—Ö —Å—É—â–Ω–æ—Å—Ç–µ–π –∏–∑ docs
# ============================================================

def _extract_facts_and_sources(
    docs: List[Dict[str, Any]]
) -> tuple[list[dict], list[str], list[str], list[str], list[dict]]:
    """
    FACT-BUILDER 3.0 (—Å—Ç—Ä–æ–≥–∏–π —Ä–µ–∂–∏–º):
    ‚Ä¢ –ö–∞–∂–¥—ã–π —Ñ–∞–∫—Ç = –æ–¥–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –∏–∑ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.
    ‚Ä¢ –ù–∏–∫–∞–∫–æ–π —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏, —Å–∫–ª–µ–π–∫–∏ –∏–ª–∏ –ø—Ä–∏–¥—É–º—ã–≤–∞–Ω–∏—è –¥–µ—Ç–∞–ª–µ–π.
    ‚Ä¢ –£ –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–∫—Ç–∞ –µ—Å—Ç—å –º–∏–Ω–∏–º—É–º –æ–¥–∏–Ω –∏—Å—Ç–æ—á–Ω–∏–∫ {file_id, page}.
    """
    facts: List[Dict[str, Any]] = []
    persons: List[str] = []
    dates: List[str] = []
    amounts: List[str] = []
    sources: List[Dict[str, Any]] = []
    fact_id = 1

    for d in docs:
        text = (d.get("text") or "").strip()
        file_id = d.get("file_id")
        page = d.get("page")

        if not text:
            continue

        # üîπ –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –¥–æ–ø—Ä–æ—Å–∞/–æ–ø—Ä–æ—Å–∞/–æ–±—ä—è—Å–Ω–µ–Ω–∏–π
        if _looks_like_interrogation_doc(d):
            text = _clean_interrogation_text(text)
            if not text.strip():
                continue

        src = {"file_id": file_id, "page": page}
        if file_id:
            sources.append(src)

        # üìå –û–±—â–∏–µ —Å—É—â–Ω–æ—Å—Ç–∏ –ø–æ –≤—Å–µ–º—É –∫—É—Å–∫—É
        for m in PERSON_RX.finditer(text):
            p = m.group(1)
            if len(p) > 2 and not any(x in p for x in ["–ê–û", "–¢–û–û", "–ò–ü", "–û–û–û"]):
                if p not in persons:
                    persons.append(p)

        for m in DATE_RX.finditer(text):
            dt = m.group(1)
            if dt not in dates:
                dates.append(dt)

        for m in MONEY_RX.finditer(text):
            amt = m.group(0)
            if amt not in amounts:
                amounts.append(amt)

        # üìå –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ ‚Üí —Ñ–∞–∫—Ç (—Å—Ç—Ä–æ–≥–∏–π —Ä–µ–∂–∏–º)
        sentences = _split_sentences(text)
        for sent in sentences:
            sent_clean = sent.strip()
            if not sent_clean:
                continue

            if not _is_fact_sentence(sent_clean):
                continue

            low = sent_clean.lower()

            # —Ç–∏–ø —Ñ–∞–∫—Ç–∞
            if "–ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º" in low and "–ø—Ä–∏–∑–Ω–∞—Ç—å" in low:
                fact_type = "status"
            else:
                fact_type = "event"

            facts.append(
                {
                    "fact_id": f"f{fact_id}",
                    "type": fact_type,
                    "text": sent_clean[:600],
                    "confidence": _conf_from_signal(sent_clean),
                    "sources": [src] if file_id else [],
                }
            )
            fact_id += 1

    # –ï—Å–ª–∏ —Ñ–∞–∫—Ç–æ–≤ –Ω–µ—Ç, –Ω–æ –µ—Å—Ç—å –±–∞–∑–æ–≤—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç ‚Äî –æ–¥–∏–Ω —Ñ–∞–∫—Ç-—Å–≤–æ–¥–∫–∞
    if not facts and (persons or dates or amounts):
        base_parts = []
        if persons:
            base_parts.append(f"–£—á–∞—Å—Ç–Ω–∏–∫–∏: {', '.join(persons[:5])}")
        if dates:
            base_parts.append(f"–î–∞—Ç—ã: {', '.join(dates[:5])}")
        if amounts:
            base_parts.append(f"–°—É–º–º—ã: {', '.join(amounts[:5])}")

        if base_parts:
            facts.append(
                {
                    "fact_id": f"f{fact_id}",
                    "type": "context",
                    "text": "; ".join(base_parts),
                    "confidence": 0.55,
                    "sources": [sources[0]] if sources else [],
                }
            )

    uniq_sources = _dedup_sources(sources)

    return facts, persons, dates, amounts, uniq_sources

# ============================================================
# üß† –û–±–æ–≥–∞—â–µ–Ω–∏–µ —Ñ–∞–∫—Ç–æ–≤ —Ä–æ–ª—è–º–∏ / –¥–µ–π—Å—Ç–≤–∏—è–º–∏ (–ª–µ–≥–∫–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞)
# ============================================================

def enrich_facts_with_roles(facts: list[dict]) -> list[dict]:
    ROLE_HINTS = {
        "–ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º": "–ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º—ã–π",
        "–æ–±–≤–∏–Ω—è": "–æ–±–≤–∏–Ω—è–µ–º—ã–π",
        "—Å–≤–∏–¥–µ—Ç–µ–ª": "—Å–≤–∏–¥–µ—Ç–µ–ª—å",
        "–ø–æ—Ç–µ—Ä–ø–µ–≤—à": "–ø–æ—Ç–µ—Ä–ø–µ–≤—à–∏–π",
        "—Å–æ—É—á–∞—Å—Ç": "—Å–æ—É—á–∞—Å—Ç–Ω–∏–∫",
        "–æ—Ä–≥–∞–Ω–∏–∑–∞—Ç–æ—Ä": "–æ—Ä–≥–∞–Ω–∏–∑–∞—Ç–æ—Ä",
    }
    ACTION_HINTS = [
        "–ø–µ—Ä–µ–≤—ë–ª", "–ø–µ—Ä–µ–¥–∞–ª", "–ø–æ–ª—É—á–∏–ª", "–ø—Ä–∏–Ω—è–ª", "–ø—Ä–µ–¥–ª–æ–∂–∏–ª",
        "–æ–±–º–∞–Ω—É–ª", "–≤–≤–µ–ª –≤ –∑–∞–±–ª—É–∂–¥–µ–Ω–∏–µ", "—Å–æ–≤–µ—Ä—à–∏–ª", "–ø—Ä–∏—Å–≤–æ–∏–ª", "–≤—ã–º–æ–≥–∞–ª",
        "–æ—Ä–≥–∞–Ω–∏–∑–æ–≤–∞–ª", "–∑–∞–∫–ª—é—á–∏–ª –¥–æ–≥–æ–≤–æ—Ä", "–ø–æ–ª—É—á–∏–ª –¥–æ—Å—Ç—É–ø", "—Å–Ω—è–ª –¥–µ–Ω—å–≥–∏"
    ]

    for f in facts:
        txt = f["text"].lower()
        f["role"] = next((r for k, r in ROLE_HINTS.items() if k in txt), "–Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ")
        f["action"] = next((a for a in ACTION_HINTS if a in txt), None)
        f["time"] = next(
            (d for d in re.findall(r"\d{1,2}[./]\d{1,2}[./]\d{2,4}", txt)), None
        )
    return facts

# ============================================================
# üß± –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –¥–∞–Ω–Ω—ã—Ö –æ –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º–æ–º
# ============================================================

def validate_facts_completeness(docs: list[Dict[str, Any]]):
    """–ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å—Ç—å –ª–∏ –í–û–û–ë–©–ï —Ñ–∞–∫—Ç—ã –∏ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º–æ–≥–æ."""
    if not docs:
        raise HTTPException(
            status_code=400,
            detail="‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω—ã –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, –∑–∞–≥—Ä—É–∂–µ–Ω—ã –ª–∏ —Ñ–∞–π–ª—ã –ø–æ –¥–µ–ª—É.",
        )

    has_suspect = any(
        "–ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º" in (d.get("text") or "").lower() for d in docs
    )
    if not has_suspect:
        raise HTTPException(
            status_code=404,
            detail="‚ùå –í —Ç–µ–∫—Å—Ç–∞—Ö –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã —Å–≤–µ–¥–µ–Ω–∏—è –æ –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º–æ–º. "
                   "–¢—Ä–µ–±—É–µ—Ç—Å—è –ø—Ä–æ–≤–µ—Ä–∏—Ç—å OCR –∏ –ø–æ–ª–Ω–æ—Ç—É –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤.",
        )

# ============================================================
# ‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–ª–Ω–æ—Ç—ã –ø–æ —Å—Ç. 204 –£–ü–ö –†–ö (–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø)
# ============================================================

def _check_204_completeness(
    facts,
    persons,
    dates,
    amounts,
    roles=None,
    events=None,
    legal_facts=None,
    timeline=None,
):
    roles = roles or {}
    events = events or []
    legal_facts = legal_facts or {}

    def present(x):
        return bool(x)

    checklist = [
        {
            "item": "–£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –ª–∏—á–Ω–æ—Å—Ç—å –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º–æ–≥–æ",
            "present": present(roles.get("suspect")),
        },
        {
            "item": "–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ —Ä–æ–ª—å –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º–æ–≥–æ",
            "present": present(roles.get("suspect_role")),
        },
        {
            "item": "–ï—Å—Ç—å –æ–ø–∏—Å–∞–Ω–∏–µ —Å–æ–±—ã—Ç–∏–π",
            "present": present(events),
        },
        {
            "item": "–ï—Å—Ç—å –¥–∞—Ç—ã —Å–æ–±—ã—Ç–∏–π",
            "present": present(dates),
        },
        {
            "item": "–ï—Å—Ç—å —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ —Å–≤–µ–¥–µ–Ω–∏—è",
            "present": present(amounts),
        },
        {
            "item": "–í—ã–¥–µ–ª–µ–Ω—ã —é—Ä–∏–¥–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏",
            "present": present(legal_facts),
        },
        {
            "item": "–ï—Å—Ç—å —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ (–≤—ã–¥–µ—Ä–∂–∫–∏ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤)",
            "present": present(facts),
        },
    ]

    missing = [x["item"] for x in checklist if not x["present"]]

    return {
        "article": "204 –£–ü–ö –†–ö",
        "checklist": checklist,
        "missing": missing,
        "enough_for_draft": len(missing) <= 3,
    }

# ============================================================
# ‚öñÔ∏è –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–µ–π –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤
# ============================================================

def _extract_articles(docs: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    arts: List[Dict[str, Any]] = []
    for d in docs:
        text = d.get("text") or ""
        file_id = d.get("file_id")
        page = d.get("page")
        for m in ART_RX.finditer(text):
            art_num = m.group(2)
            code = (m.group(3) or "–£–ö/–£–ü–ö/–ì–ö?").upper()
            arts.append(
                {
                    "code": (code.replace(" ", "") + " –†–ö") if "–†–ö" not in code else code,
                    "article": art_num,
                    "context": _context_snippet(text, m.start(), m.end()),
                    "source": {"file_id": file_id, "page": page},
                }
            )
    return _dedup_articles(arts)

def _resolve_law_context(article_num: str) -> str:
    data = ALL_AFM_LAWS.get(article_num)
    if not data:
        return f"–°—Ç–∞—Ç—å—è {article_num}: [–æ–ø–∏—Å–∞–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –±–∞–∑–µ AFM]"

    code = data.get("code", "–£–ö/–£–ü–ö –†–ö")
    name = data.get("name", "[–Ω–∞–∑–≤–∞–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç]")
    official_text = data.get("official_text") or data.get("text") or "[—Ç–µ–∫—Å—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç]"
    category = data.get("category", "–ø—Ä–æ—á–µ–µ")

    return f"{code} —Å—Ç.{article_num} ‚Äî {name}. {official_text} ({category})"

# ============================================================
# üßæ –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–∞ ¬´–£–°–¢–ê–ù–û–í–ò–õ¬ª (–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø)
# ============================================================

def _build_ustanovil_text(
    facts: List[dict],
    sources: List[dict],
    completeness: dict,
    suspect: Optional[str] = None,
    suspect_role: Optional[str] = None,
) -> str:
    """
    –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–∞ –£–°–¢–ê–ù–û–í–ò–õ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º–æ–º.
    
    ‚úÖ –ü–µ—Ä–µ–¥–∞—ë—Ç—Å—è –∏ –≤—ã–≤–æ–¥–∏—Ç—Å—è –§–ò–û –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º–æ–≥–æ
    ‚úÖ –£–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è —Ä–æ–ª—å –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º–æ–≥–æ
    """
    if not facts and not suspect:
        return "–°—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ñ–∞–∫—Ç–æ–≤ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ. [–¢–†–ï–ë–£–ï–¢ –ü–†–û–í–ï–†–ö–ò]"

    lines: List[str] = []
    
    # üü¶ –†–ê–ó–î–ï–õ –û –ü–û–î–û–ó–†–ï–í–ê–ï–ú–û–ú (–ù–û–í–û–ï)
    if suspect:
        lines.append(f"–ü–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º—ã–π: {suspect.upper()}")
        if suspect_role:
            lines.append(f"  –†–æ–ª—å –≤ –ø—Ä–µ—Å—Ç—É–ø–ª–µ–Ω–∏–∏: {suspect_role}")
        lines.append("")
    
    # üü® –†–ê–ó–î–ï–õ –û –§–ê–ö–¢–ê–•
    for i, f in enumerate(facts, 1):
        src_str = _src_str(f.get("sources"))
        conf = f.get("confidence", 0.5)
        suffix = "" if conf >= 0.75 else " [‚ö†Ô∏è –Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å]"
        
        lines.append(f"{i}. {f['text']} {src_str}{suffix}")
    
    # üü• –†–ê–ó–î–ï–õ –û –ù–ï–î–û–°–¢–ê–Æ–©–ò–• –≠–õ–ï–ú–ï–ù–¢–ê–•
    if completeness.get("missing"):
        lines.append("")
        lines.append("–ù–µ–¥–æ—Å—Ç–∞—é—â–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã –¥–ª—è –ø–æ–ª–Ω–æ–π –∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø–æ —Å—Ç. 204 –£–ü–ö –†–ö:")
        for m in completeness["missing"]:
            lines.append(f"  ‚Ä¢ {m}")
    
    return "\n".join(lines)

# ============================================================
# üßæ –ü—Ä–æ—Å—Ç–æ–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ü–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è (fallback, –±–µ–∑ LLM)
# ============================================================

def _build_postanovlenie_simple(
    city: str,
    date_str: str,
    investigator_line: str,
    case_id: Optional[str],
    ustanovil_text: str,
    mentioned_articles: List[Dict[str, Any]],
    completeness: dict,
    investigator_fio: str = "",
    intro_context: str = "",
    suspect: Optional[str] = None,
) -> str:

    rus_date = _rus_date(date_str)

    # —Å–ø–∏—Å–æ–∫ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π —Å—Ç–∞—Ç–µ–π (–±–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ –£–ö)
    if mentioned_articles:
        arts_filtered = [a for a in mentioned_articles if "–£–ö" in a.get("code", "")]
        if arts_filtered:
            arts = sorted({f"{a.get('code', '')} —Å—Ç.{a.get('article', '?')}" for a in arts_filtered})
            arts_line = "–£–ø–æ–º–∏–Ω–∞–Ω–∏—è —Å—Ç–∞—Ç–µ–π –£–ö: " + "; ".join(arts)
        else:
            arts_line = "–£–ø–æ–º–∏–Ω–∞–Ω–∏–π —Å—Ç–∞—Ç–µ–π –£–ö –Ω–µ –≤—ã—è–≤–ª–µ–Ω–æ."
    else:
        arts_line = "–£–ø–æ–º–∏–Ω–∞–Ω–∏–π —Å—Ç–∞—Ç–µ–π –Ω–µ—Ç."

    # —Ä–µ—à–µ–Ω–∏–µ
    if completeness.get("enough_for_draft"):
        decision = "–ö–≤–∞–ª–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –¥–µ—è–Ω–∏–µ –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º–æ–≥–æ –ø–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–º —Å—Ç–∞—Ç—å—è–º –£–ö –†–µ—Å–ø—É–±–ª–∏–∫–∏ –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω."
    else:
        decision = "–û–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω—É—é –∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏—é –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–æ—Å–ª–µ –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤."

    intro_block = ""
    if intro_context:
        intro_block = intro_context.strip() + "\n\n"

    return f"""–ü–û–°–¢–ê–ù–û–í–õ–ï–ù–ò–ï
–æ –∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏–∏ –¥–µ—è–Ω–∏—è –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º–æ–≥–æ

{city}, {rus_date}

–ú–∞—Ç–µ—Ä–∏–∞–ª—ã –¥–µ–ª–∞ ‚Ññ {case_id}
{arts_line}

{intro_block}–£–°–¢–ê–ù–û–í–ò–õ:
{ustanovil_text}

–ü–û–°–¢–ê–ù–û–í–ò–õ:
{decision}

–ü–æ–¥–ø–∏—Å—å:
–°–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å: {investigator_line}
–§–ò–û: {investigator_fio}
______________________
–î–∞—Ç–∞: {rus_date}

–ü—Ä–∞–≤–∞ –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º–æ–≥–æ, –ø—Ä–µ–¥—É—Å–º–æ—Ç—Ä–µ–Ω–Ω—ã–µ —Å—Ç. 64 –£–ü–ö –†–ö:
- –ø—Ä–∞–≤–æ –∑–Ω–∞—Ç—å, –≤ —á—ë–º –æ–Ω –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ—Ç—Å—è;
- –ø—Ä–∞–≤–æ –¥–∞–≤–∞—Ç—å –æ–±—ä—è—Å–Ω–µ–Ω–∏—è –∏–ª–∏ –æ—Ç–∫–∞–∑–∞—Ç—å—Å—è –æ—Ç –¥–∞—á–∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏–π;
- –ø—Ä–∞–≤–æ –Ω–∞ –∑–∞—â–∏—Ç–Ω–∏–∫–∞;
- –ø—Ä–∞–≤–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—Ç—å –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞;
- –ø—Ä–∞–≤–æ –∑–∞—è–≤–ª—è—Ç—å —Ö–æ–¥–∞—Ç–∞–π—Å—Ç–≤–∞;
- –ø—Ä–∞–≤–æ –æ–±–∂–∞–ª–æ–≤–∞—Ç—å –¥–µ–π—Å—Ç–≤–∏—è –∏ —Ä–µ—à–µ–Ω–∏—è –æ—Ä–≥–∞–Ω–∞ —Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è.

–ß–µ—Ä–Ω–æ–≤–∏–∫ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏; –æ–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å –ø–æ—Å–ª–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –ø—Ä–æ–∫—É—Ä–æ—Ä–æ–º.
""".strip()

# ============================================================
# üéØ –§–∏–ª—å—Ç—Ä—ã —é—Ä–∏–¥–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º—ã—Ö —Ñ–∞–∫—Ç–æ–≤
# ============================================================

def _legal_fact_filter(fact_text: str) -> bool:
    """
    –§–∏–ª—å—Ç—Ä —é—Ä–∏–¥–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º—ã—Ö —Ñ–∞–∫—Ç–æ–≤.
    True  ‚Üí —Ñ–∞–∫—Ç –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ –ø—Ä–µ—Å—Ç—É–ø–ª–µ–Ω–∏—é (–æ—Å—Ç–∞–≤–ª—è–µ–º).
    False ‚Üí —è–≤–Ω—ã–π —Ç–µ—Ö/—Å–ª—É–∂–µ–±–Ω—ã–π –º—É—Å–æ—Ä.
    """
    if not fact_text:
        return False

    t = fact_text.lower().strip()

    # ‚ùå 1. –Ø–≤–Ω—ã–π PDF/–≠–¶–ü/QR-–º—É—Å–æ—Ä
    blocked_pdf = [
        "qr-–∫–æ–¥", "qr –∫–æ–¥", "—Ö–µ—à", "—Ö—ç—à", "hash",
        "ecp", "—ç—Ü–ø", "—ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç",
        "–¥–∞–Ω–Ω—ã–µ —ç—Ü–ø", "–∫–æ–¥ –¥–æ–∫—É–º–µ–Ω—Ç–∞", "–≤—Ä–µ–º—è –ø–æ–¥–ø–∏—Å–∞–Ω–∏—è",
        "–¥–∞—Ç–æ–π –∏ –≤—Ä–µ–º–µ–Ω–µ–º –ø–æ–¥–ø–∏—Å–∞–Ω–∏—è", "—ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω—ã–π pdf",
    ]
    if any(w in t for w in blocked_pdf):
        return False

    # ‚ùå 2. –ß–∏—Å—Ç–æ–µ —Ä–∞–∑—ä—è—Å–Ω–µ–Ω–∏–µ –ø—Ä–∞–≤ / –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–µ–π (–±–µ–∑ —Ñ–∞–∫—Ç–æ–≤)
    if "—Ä–∞–∑—ä—è—Å–Ω" in t and "–ø—Ä–∞–≤" in t and "–ø–æ–∫–∞–∑–∞–Ω" not in t and "–ø–æ—è—Å–Ω–∏–ª" not in t:
        return False

    # ‚ùå 3. –û–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏ –ø–æ—Ç–µ—Ä–ø–µ–≤—à–µ–≥–æ / –æ–±—â–∏–µ –ø—Ä–∞–≤–∏–ª–∞ –ø–æ–≤–µ–¥–µ–Ω–∏—è
    if "—è–≤–∏—Ç—å—Å—è –ø–æ –≤—ã–∑–æ–≤—É" in t or "–Ω–µ —Ä–∞–∑–≥–ª–∞—à–∞—Ç—å —Å–≤–µ–¥–µ–Ω–∏—è" in t:
        return False

    # ‚ùå 4. –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Å—Ä–µ–¥—Å—Ç–≤–∞ –≤–∏–¥–µ–æ–∑–∞–ø–∏—Å–∏
    if "–≤–∏–¥–µ–æ–∫–∞–º–µ—Ä–∞" in t or "–≤–∏–¥–µ–æ–∑–∞–ø–∏—Å—å" in t or "–∞—É–¥–∏–æ–∑–∞–ø–∏—Å—å" in t:
        return False

    # ‚ùå 5. –°–ª—É–∂–µ–±–Ω—ã–µ –≤—Å—Ç—É–ø–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ—Ä–∞–∑—ã
    intro_markers = [
        "–ø—Ä–æ–≤–æ–¥–∏—Ç—Å—è –¥–æ—Å—É–¥–µ–±–Ω–æ–µ —Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ",
        "—Ä–∞—Å—Å–º–æ—Ç—Ä–µ–≤ –º–∞—Ç–µ—Ä–∏–∞–ª—ã –¥–æ—Å—É–¥–µ–±–Ω–æ–≥–æ —Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è",
        "—Ä–∞—Å—Å–º–æ—Ç—Ä–µ–≤ –º–∞—Ç–µ—Ä–∏–∞–ª—ã —É–≥–æ–ª–æ–≤–Ω–æ–≥–æ –¥–µ–ª–∞",
        "–º–∞—Ç–µ—Ä–∏–∞–ª—ã –¥–æ—Å—É–¥–µ–±–Ω–æ–≥–æ —Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è ‚Ññ",
        "–º–∞—Ç–µ—Ä–∏–∞–ª—ã —É–≥–æ–ª–æ–≤–Ω–æ–≥–æ –¥–µ–ª–∞ ‚Ññ",
        "—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å —Å–æ–≥",
        "—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å —Å—É –¥–µ—Ä",
        "—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å —Å–ª–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ–π-–æ–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ–π –≥—Ä—É–ø–ø—ã",
        "—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å —Å–ª–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ–π –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ–π –≥—Ä—É–ø–ø—ã",
    ]
    if any(m in t for m in intro_markers):
        return False

    # ‚ùå 6. –ü–ª–∞–Ω —Å–ª–µ–¥—Å—Ç–≤–µ–Ω–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π
    plan_markers = [
        "—Å–∞–Ω–∫—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–æ –æ–±—ã—Å–∫–æ–≤—ã—Ö –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π",
        "—Å–∞–Ω–∫—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–æ –æ–±—ã—Å–∫–∞",
        "–Ω–∞–ø—Ä–∞–≤–∏—Ç—å –≤ —Ç–µ—Ä—Ä–∏—Ç–æ—Ä–∏–∞–ª—å–Ω—ã–µ –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç—ã",
        "–Ω–∞–ø—Ä–∞–≤–∏—Ç—å –ø–æ—Ä—É—á–µ–Ω–∏—è –≤ —Ç–µ—Ä—Ä–∏—Ç–æ—Ä–∏–∞–ª—å–Ω—ã–µ –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç—ã",
        "–ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–∏–æ–±—Ä–µ—Ç–µ–Ω–∏–µ –∏–º—É—â–µ—Å—Ç–≤–∞",
        "–∏—Å—Ç—Ä–µ–±–æ–≤–∞—Ç—å —Å–ø—Ä–∞–≤–∫–∏ –∏ –¥–µ–∫–ª–∞—Ä–∞—Ü–∏–∏ –æ –¥–æ—Ö–æ–¥–∞—Ö",
        "–∏—Å—Ç—Ä–µ–±–æ–≤–∞—Ç—å —Å–ø—Ä–∞–≤–∫–∏ –∏ –¥–µ–∫–ª–∞—Ä–∞—Ü–∏–∏",
        "–ø–æ—Ä—É—á–∏—Ç—å –ø—Ä–æ–≤–µ—Å—Ç–∏",
        "–ø–æ—Ä—É—á–∏—Ç—å –æ—Ä–≥–∞–Ω–∞–º",
        "–ø—Ä–æ–≤–µ—Å—Ç–∏ –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ-—Ä–æ–∑—ã—Å–∫–Ω—ã–µ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è",
        "–ø–æ –º–µ—Ä–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∫–æ–º–ø–ª–µ–∫—Å–∞ —Å–ª–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ-–æ–ø–µ—Ä–∞—Ç–∏–≤–Ω—ã—Ö",
    ]
    if any(m in t for m in plan_markers):
        return False

    # ‚ùå 7. –°–æ–≤—Å–µ–º –ø—É—Å—Ç—ã–µ –∏–ª–∏ –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏–µ —Ñ—Ä–∞–∑—ã
    if len(t) < 15:
        return False

    # ‚úî 8. –ï—Å–ª–∏ —Ñ—Ä–∞–∑–∞ –ø—Ä–æ –ø–æ—Ç–µ—Ä–ø–µ–≤—à–µ–≥–æ –∏ –µ–≥–æ –ø–æ–∫–∞–∑–∞–Ω–∏—è ‚Äî –æ—Å—Ç–∞–≤–ª—è–µ–º
    if "–ø–æ—Ç–µ—Ä–ø–µ–≤" in t and ("–ø–æ—è—Å–Ω–∏–ª" in t or "–ø–æ—è—Å–Ω–∏–ª–∞" in t or "–ø–æ–∫–∞–∑–∞–ª" in t or "–ø–æ–∫–∞–∑–∞–ª–∞" in t):
        return True

    # ‚úî 9. –ï—Å–ª–∏ –µ—Å—Ç—å —è–≤–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π / —É—â–µ—Ä–±–∞
    crime_keywords = [
        "–ø–∏—Ä–∞–º–∏–¥", "–≤–æ–≤–ª–µ–∫", "–ø—Ä–∏–≤–ª–µ–∫", "–≤–Ω–µ—Å", "–≤–Ω–µ—Å–ª–∞",
        "–≤–ª–æ–∂–∏–ª", "–≤–ª–æ–∂–∏–ª–∞", "–ø–µ—Ä–µ–≤–µ–ª", "–ø–µ—Ä–µ–≤–µ–ª–∞", "–ø–µ—Ä–µ—á–∏—Å–ª–∏–ª",
        "–¥–µ–Ω–µ–∂–Ω", "–¥–µ–Ω—å–≥–∏", "—Å—Ä–µ–¥—Å—Ç–≤–∞", "—É—â–µ—Ä–±", "–±–∞–ª–∞–Ω—Å", "usdt",
        "–ø—Ä–∏–ª–æ–∂–µ–Ω–∏", "–ø–ª–∞—Ç—Ñ–æ—Ä–º", "–∏–Ω–≤–µ—Å—Ç", "–¥–æ—Ö–æ–¥", "–≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏–µ",
    ]
    if any(w in t for w in crime_keywords):
        return True

    # ‚úî 10. –õ—é–±—ã–µ –¥–µ–π—Å—Ç–≤–∏—è –ª–∏—Ü–∞, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –¥–µ—è–Ω–∏–µ–º
    action_words = ["—Å–æ–≤–µ—Ä—à", "–æ—Ä–≥–∞–Ω–∏–∑", "—Ä—É–∫–æ–≤–æ–¥", "–ø–æ–ª—É—á–∏–ª", "–ø–æ–ª—É—á–∏–ª–∞", "–ø—Ä–∏—Å–≤–æ", "–æ–±–º–∞–Ω—É–ª"]
    if any(w in t for w in action_words):
        return True

    # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é: –æ—Å—Ç–∞–≤–ª—è–µ–º —á—É—Ç—å –±–æ–ª—å—à–µ, —á–µ–º –≤—ã–∫–∏–¥—ã–≤–∞–µ–º.
    return True

def _hard_fact_clean(fact_text: str) -> bool:
    """
    –ë–æ–ª–µ–µ –º—è–≥–∫–∏–π –∞–Ω—Ç–∏-–º—É—Å–æ—Ä–Ω—ã–π —Ñ–∏–ª—å—Ç—Ä.
    –¶–µ–ª—å ‚Äî —É–±—Ä–∞—Ç—å —è–≤–Ω—ã–π –±—ã—Ç–æ–≤–æ–π/—ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç –∏ —á–∏—Å—Ç—ã–π –ø—Ä–æ—Ü–µ—Å—Å—É–∞–ª—å–Ω—ã–π —à—É–º,
    –Ω–æ –ù–ï –≤—ã–∫–∏–¥—ã–≤–∞—Ç—å —Ñ–∞–±—É–ª—É.
    """
    if not fact_text:
        return False

    t = fact_text.lower().strip()

    # 0. –ë—ã—Ç–æ–≤—ã–µ / —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Ñ—Ä–∞–∑—ã –±–µ–∑ —Ñ–∞–∫—Ç–æ–≤
    noise = [
        "—è –ª–∏—á–Ω–æ –Ω–∏—á–µ–≥–æ –Ω–µ –ø–æ–º–Ω—é",
        "—è –Ω–µ –∑–Ω–∞—é", "–º—ã –¥—É–º–∞–ª–∏", "–∫–∞–∫-—Ç–æ", "–≤—Ä–æ–¥–µ",
        "–º–∞–º–∞ —Å–∫–∞–∑–∞–ª–∞", "—Å–æ—Å–µ–¥ —Ä–∞—Å—Å–∫–∞–∑–∞–ª",
    ]
    if any(p in t for p in noise):
        return False

    # 1. –ß–∏—Å—Ç—ã–π –ø—Ä–æ—Ü–µ—Å—Å—É–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ —Ñ–∞–±—É–ª—ã
    procedural = [
        "—É–ø–∫ —Ä–∫", "—É–≥–æ–ª–æ–≤–Ω–æ-–ø—Ä–æ—Ü–µ—Å—Å—É–∞–ª—å–Ω—ã–π –∫–æ–¥–µ–∫—Å",
        "–∏–º–µ–µ—Ç –ø—Ä–∞–≤–æ", "–æ–±—è–∑–∞–Ω", "–æ–±—è–∑–∞–Ω–∞",
        "—Ä–∞–∑—ä—è—Å–Ω–µ–Ω—ã –ø—Ä–∞–≤–∞", "–ø—Ä–∞–≤–∞ –∏ –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏",
        "–ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω –æ–± –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏", "–ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∞ –æ–± –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏",
    ]
    if any(p in t for p in procedural) and "–ø–æ—è—Å–Ω–∏–ª" not in t and "–ø–æ—è—Å–Ω–∏–ª–∞" not in t:
        return False

    # 2. –¢–µ—Ö. –º—É—Å–æ—Ä
    tech = ["qr-–∫–æ–¥", "qr –∫–æ–¥", "ecp", "—ç—Ü–ø", "pdf", "—Å–∫–∞–Ω-–∫–æ–ø–∏—è"]
    if any(k in t for k in tech):
        return False

    return True

# ============================================================
# ü§ñ –ê–≤—Ç–æ-–∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
# ============================================================

def _auto_qualify(facts, roles, events, legal_facts):
    """
    –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä —Å—Ç–∞—Ç—å–∏ –£–ö –†–ö –ø–æ –ø—Ä–∏–∑–Ω–∞–∫–∞–º –≤ —Ñ–∞–∫—Ç–∞—Ö.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
        (article_num: str | None,
         part: str | None,
         reason: str ‚Äî –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ)
    """

    text_all = " ".join(f.get("text", "").lower() for f in facts)

    # 1) –§–ò–ù–ê–ù–°–û–í–ê–Ø –ü–ò–†–ê–ú–ò–î–ê (—Å—Ç.217)
    pyramid_keywords = [
        "–ø–∏—Ä–∞–º–∏–¥–∞", "–≤–ª–æ–∂–∏–ª", "–ø—Ä–∏–≤–ª–µ–∫", "–∑–∞–≤–ª–µ–∫–∞–ª",
        "–≤–æ–≤–ª–µ–∫–∞–ª", "–≤—Å—Ç—É–ø–∏–ª", "—Å—Ö–µ–º–∞", "–¥–æ—Ö–æ–¥ –∑–∞ —Å—á–µ—Ç –Ω–æ–≤—ã—Ö —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤",
        "–ø–µ—Ä–µ—Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ", "–∏–Ω–≤–µ—Å—Ç –ø—Ä–æ–µ–∫—Ç –±–µ–∑ –∞–∫—Ç–∏–≤–∞",
    ]

    if any(k in text_all for k in pyramid_keywords):
        return (
            "217",
            "1",
            "–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–∏–∑–Ω–∞–∫–∏ —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–π –ø–∏—Ä–∞–º–∏–¥—ã (–ø—Ä–∏–≤–ª–µ—á–µ–Ω–∏–µ —Å—Ä–µ–¥—Å—Ç–≤, –ø–µ—Ä–µ—Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–∫–ª–∞–¥–æ–≤)."
        )

    # 2) –ú–û–®–ï–ù–ù–ò–ß–ï–°–¢–í–û (—Å—Ç.190)
    fraud_keywords = [
        "–æ–±–º–∞–Ω", "–∑–∞–±–ª—É–∂–¥–µ–Ω–∏", "–º–æ—à–µ–Ω–Ω–∏—á", "–ø—Ä–∏—Å–≤–æ–∏–ª",
        "–∑–∞–≤–µ–¥–æ–º–æ –ª–æ–∂–Ω—ã–µ", "–Ω–µ–∑–∞–∫–æ–Ω–Ω–æ –ø–æ–ª—É—á–∏–ª",
    ]

    if any(k in text_all for k in fraud_keywords):
        return (
            "190",
            "2",
            "–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–∏–∑–Ω–∞–∫–∏ –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞ (–æ–±–º–∞–Ω, –≤–≤–µ–¥–µ–Ω–∏–µ –≤ –∑–∞–±–ª—É–∂–¥–µ–Ω–∏–µ, –ø—Ä–∏—Å–≤–æ–µ–Ω–∏–µ)."
        )

    # 3) –ù–µ–∑–∞–∫–æ–Ω–Ω–∞—è –ø—Ä–µ–¥–ø—Ä–∏–Ω–∏–º–∞—Ç–µ–ª—å—Å–∫–∞—è –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å (—Å—Ç. 214/245)
    business_keywords = [
        "–±–µ–∑ –ª–∏—Ü–µ–Ω–∑–∏–∏", "–Ω–µ–∑–∞–∫–æ–Ω–Ω–∞—è –ø—Ä–µ–¥–ø—Ä–∏–Ω–∏–º–∞—Ç–µ–ª—å—Å–∫–∞—è", "–Ω–µ–ª–µ–≥–∞–ª—å–Ω–∞—è –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å",
        "–æ–∫–∞–∑–∞–Ω–∏–µ —É—Å–ª—É–≥ –±–µ–∑ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏", "–±–µ–∑ —É–¥–æ—Å—Ç–æ–≤–µ—Ä–µ–Ω–∏—è", "–Ω–µ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω"
    ]

    if any(k in text_all for k in business_keywords):
        return (
            "214",
            "1",
            "–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–∏–∑–Ω–∞–∫–∏ –Ω–µ–∑–∞–∫–æ–Ω–Ω–æ–π –ø—Ä–µ–¥–ø—Ä–∏–Ω–∏–º–∞—Ç–µ–ª—å—Å–∫–æ–π –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏."
        )

    # 4) –û—Ç–º—ã–≤–∞–Ω–∏–µ –¥–µ–Ω–µ–≥ (218)
    laundering_keywords = [
        "–ª–µ–≥–∞–ª–∏–∑", "–æ—Ç–º—ã–≤–∞–ª", "—Å–∫—Ä—ã–≤–∞–ª –ø—Ä–æ–∏—Å—Ö–æ–∂–¥–µ–Ω–∏–µ", "–¥–≤–∏–∂–µ–Ω–∏–µ –¥–µ–Ω–µ–∂–Ω—ã—Ö —Å—Ä–µ–¥—Å—Ç–≤",
    ]

    if any(k in text_all for k in laundering_keywords):
        return (
            "218",
            "1",
            "–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–∏–∑–Ω–∞–∫–∏ –ª–µ–≥–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–æ—Ö–æ–¥–æ–≤ (–æ—Ç–º—ã–≤–∞–Ω–∏–µ –¥–µ–Ω–µ–≥)."
        )

    # 5) –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ—Ç ‚Äî —Å—Ç–∞—Ç—å—è –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞
    return None, None, "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏–∏."

def classify_crime(facts: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä —Å—Ç–∞—Ç—å–∏ –£–ö –†–ö –ø–æ –ø—Ä–∏–∑–Ω–∞–∫–∞–º.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
    {
        "primary": "190",
        "secondary": ["218", "385"]
    }
    """
    text_blob = " ".join(f.get("text", "").lower() for f in facts)

    flags = {
        "190": any(kw in text_blob for kw in [
            "–æ–±–º–∞–Ω", "–∑–∞–±–ª—É–∂–¥–µ–Ω–∏", "–Ω–µ –≤–µ—Ä–Ω—É–ª", "–ø–æ–ª—É—á–∏–ª –¥–µ–Ω—å–≥–∏",
            "–Ω–µ –≤—ã–ø–æ–ª–Ω–∏–ª –æ–±—è–∑–∞—Ç–µ–ª—å—Å—Ç–≤", "—É—â–µ—Ä–±", "–≤–≤–µ–ª –≤ –∑–∞–±–ª—É–∂–¥"
        ]),

        "217": any(kw in text_blob for kw in [
            "–ø—Ä–∏–≤–ª–µ–∫", "–≤–æ–≤–ª–µ–∫", "–æ–±–µ—â–∞–ª –¥–æ—Ö–æ–¥", "–≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏–µ",
            "—É—á–∞—Å—Ç–Ω–∏–∫", "—Å—Ç—Ä—É–∫—Ç—É—Ä", "–¥–æ—Ö–æ–¥ –∑–∞ —Å—á–µ—Ç –¥—Ä—É–≥–∏—Ö",
            "–º–∞—Å—Å–æ–≤–æ–µ –ø—Ä–∏–≤–ª–µ—á–µ–Ω–∏–µ", "–≤—ã—Å–æ–∫–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç"
        ]),

        "385": any(kw in text_blob for kw in [
            "–±–µ–∑ –ª–∏—Ü–µ–Ω–∑–∏–∏", "–±–µ–∑ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏", "–Ω–µ–∑–∞–∫–æ–Ω–Ω",
            "–ø—Ä–µ–¥–ø—Ä–∏–Ω–∏–º–∞—Ç–µ–ª—å—Å–∫–∞—è –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å", "–ø—Ä–∏–±—ã–ª—å –±–µ–∑ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏"
        ]),

        "189": any(kw in text_blob for kw in [
            "–¥–æ–≤–µ—Ä–µ–Ω", "—Ä–∞—Å–ø–æ—Ä—è–¥–∏–ª—Å—è —á—É–∂–∏–º", "–ø—Ä–∏—Å–≤–æ–∏–ª",
            "—Ä–∞—Å—Ç—Ä–∞—Ç–∞", "–∏–º—É—â–µ—Å—Ç–≤–æ –±—ã–ª–æ –ø–µ—Ä–µ–¥–∞–Ω–æ"
        ]),

        "218": any(kw in text_blob for kw in [
            "—Å–∫—Ä—ã—Ç—å –ø—Ä–æ–∏—Å—Ö–æ–∂–¥–µ–Ω–∏–µ", "–æ–±–Ω–∞–ª–∏—á", "–ø–µ—Ä–µ–≤–µ–ª –º–µ–∂–¥—É —Å—á–µ—Ç–∞–º–∏",
            "–ª–µ–≥–∞–ª–∏–∑", "–º–∞—Å–∫–∏—Ä–æ–≤"
        ]),
    }

    primary = None
    if flags["217"]:
        primary = "217"
    elif flags["190"]:
        primary = "190"
    elif flags["189"]:
        primary = "189"
    elif flags["218"]:
        primary = "218"
    elif flags["385"]:
        primary = "385"

    secondary = [
        art for art, ok in flags.items()
        if ok and art != primary
    ]

    return {
        "primary": primary,
        "secondary": secondary
    }

# ============================================================
# üß† –ü—Ä–æ—Ü–µ—Å—Å—É–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (–¥–æ ¬´–£–°–¢–ê–ù–û–í–ò–õ¬ª)
# ============================================================

def _extract_intro_context(docs: List[Dict[str, Any]]) -> str:
    """
    –î–æ—Å—Ç–∞—ë–º –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∫–æ—Ä–æ—Ç–∫–∏–µ –ø—Ä–æ—Ü–µ—Å—Å—É–∞–ª—å–Ω—ã–µ —Ñ—Ä–∞–∑—ã:
    - –∫—Ç–æ –≤–µ–¥—ë—Ç —Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ (–°–£ –î–≠–† / —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –°–û–ì)
    - —É–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ –º–∞—Ç–µ—Ä–∏–∞–ª—ã –¥–æ—Å—É–¥–µ–±–Ω–æ–≥–æ —Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
    - —Ñ–æ—Ä–º—É–ª—É ¬´—Ä–∞—Å—Å–º–æ—Ç—Ä–µ–≤ –º–∞—Ç–µ—Ä–∏–∞–ª—ã ...¬ª
    """
    intro_sentences: List[str] = []

    for d in docs:
        text = d.get("text") or ""
        if not text.strip():
            continue

        for sent in _split_sentences(text):
            lt = sent.lower()

            ban = [
                "–ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ",
                "–æ –ø—Ä–∏–∑–Ω–∞–Ω–∏–∏",
                "–ø–æ—Ç–µ—Ä–ø–µ–≤—à–∏–º",
            ]

            if any(b in lt for b in ban):
                continue

            if "–ø—Ä–æ–≤–æ–¥–∏—Ç—Å—è –¥–æ—Å—É–¥–µ–±–Ω–æ–µ —Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ" in lt:
                intro_sentences.append(sent.strip())
                continue

            if "—Ä–∞—Å—Å–º–æ—Ç—Ä–µ–≤ –º–∞—Ç–µ—Ä–∏–∞–ª—ã –¥–æ—Å—É–¥–µ–±–Ω–æ–≥–æ —Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è" in lt or \
               "—Ä–∞—Å—Å–º–æ—Ç—Ä–µ–≤ –º–∞—Ç–µ—Ä–∏–∞–ª—ã —É–≥–æ–ª–æ–≤–Ω–æ–≥–æ –¥–µ–ª–∞" in lt or \
               "—Ä–∞—Å—Å–º–æ—Ç—Ä–µ–≤ –º–∞—Ç–µ—Ä–∏–∞–ª—ã –¥–µ–ª–∞" in lt:
                intro_sentences.append(sent.strip())
                continue

            if "–º–∞—Ç–µ—Ä–∏–∞–ª—ã –¥–æ—Å—É–¥–µ–±–Ω–æ–≥–æ —Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è ‚Ññ" in lt or \
               "–º–∞—Ç–µ—Ä–∏–∞–ª—ã —É–≥–æ–ª–æ–≤–Ω–æ–≥–æ –¥–µ–ª–∞ ‚Ññ" in lt or \
               "–º–∞—Ç–µ—Ä–∏–∞–ª—ã –¥–µ–ª–∞ ‚Ññ" in lt:
                intro_sentences.append(sent.strip())
                continue

            if "—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å —Å–æ–≥" in lt or \
               "—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å —Å—É –¥–µ—Ä" in lt or \
               "—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å —Å–ª–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ–π –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ–π –≥—Ä—É–ø–ø—ã" in lt or \
               "—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å —Å–ª–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ-–æ–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ–π –≥—Ä—É–ø–ø—ã" in lt:
                intro_sentences.append(sent.strip())
                continue

    # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø–æ—Ä—è–¥–∫–∞
    seen = set()
    uniq = []
    for s in intro_sentences:
        if s not in seen:
            seen.add(s)
            uniq.append(s)

    # –ë–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ 2 —Å—Ç—Ä–æ–∫–∞
    return "\n".join(uniq[:2])

def _is_pure_procedural_doc(doc: Dict[str, Any]) -> bool:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç —á–∏—Å—Ç–æ –ø—Ä–æ—Ü–µ—Å—Å—É–∞–ª—å–Ω—ã–º (—É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ, –ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∏ —Ç.–ø.),
    –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–Ω–æ —Ü–µ–ª–∏–∫–æ–º –∏—Å–∫–ª—é—á–∏—Ç—å –∏–∑ –∞–Ω–∞–ª–∏–∑–∞ —Ñ–∞–∫—Ç–æ–≤.
    –î–æ–ø—Ä–æ—Å—ã, –æ–±—ä—è—Å–Ω–µ–Ω–∏—è, –∑–∞—è–≤–ª–µ–Ω–∏—è –ù–ï –≤—ã–∫–∏–¥—ã–≤–∞–µ–º.
    """
    text = (doc.get("text") or "").lower()
    filename = (doc.get("filename") or "").lower()

    # –ï—Å–ª–∏ —ç—Ç–æ –¥–æ–ø—Ä–æ—Å/–æ–±—ä—è—Å–Ω–µ–Ω–∏–µ/–∑–∞—è–≤–ª–µ–Ω–∏–µ ‚Äî –≤—Å–µ–≥–¥–∞ –æ—Å—Ç–∞–≤–ª—è–µ–º
    if any(key in filename for key in ["–¥–æ–ø—Ä–æ—Å", "–æ–ø—Ä–æ—Å", "–æ–±—ä—è—Å–Ω", "–ø–æ—è—Å–Ω–µ–Ω", "–∑–∞—è–≤–ª–µ–Ω"]):
        return False
    if "–ø—Ä–æ—Ç–æ–∫–æ–ª –¥–æ–ø—Ä–æ—Å–∞" in text or "–ø—Ä–æ—Ç–æ–∫–æ–ª –æ–ø—Ä–æ—Å–∞" in text:
        return False

    # –ü—Ä–æ—Ü–µ—Å—Å—É–∞–ª—å–Ω—ã–µ –º–∞—Ä–∫–µ—Ä—ã
    if (
        "—Ä–∞–∑—ä—è—Å–Ω–µ–Ω—ã –ø—Ä–∞–≤–∞" in text
        or "—Ä–∞–∑—ä—è—Å–Ω–µ–Ω—ã –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏" in text
        or "–ø–æ—Ç–µ—Ä–ø–µ–≤—à–∏–π –∏–º–µ–µ—Ç –ø—Ä–∞–≤–æ" in text
        or "–ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º—ã–π –∏–º–µ–µ—Ç –ø—Ä–∞–≤–æ" in text
        or "–∫–æ–ø–∏—é –ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è" in text
        or "—É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ" in text
        or "–ø–æ–¥–ø–∏—Å–∫–∞" in text
    ):
        return True

    return False

# ============================================================
# üß† –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏–∏ (–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø)
# ============================================================

def qualify_documents(
    case_id: Optional[str],
    docs: List[Dict[str, Any]],
    city: str = "–≥. –ü–∞–≤–ª–æ–¥–∞—Ä",
    date_str: Optional[str] = None,
    investigator_line: str = "–°–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å –ø–æ –æ—Å–æ–±–æ –≤–∞–∂–Ω—ã–º –¥–µ–ª–∞–º",
    investigator_fio: str = "",
) -> Dict[str, Any]:
    logger.info(f"‚ñ∂Ô∏è –ù–∞—á–∞–ª–æ –∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏–∏: case_id={case_id}, –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤={len(docs)}")

    # 0Ô∏è‚É£ –ë–∞–∑–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
    if not docs:
        logger.warning("‚ö†Ô∏è –ù–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        return _empty_result(case_id, "–î–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç")

    if not date_str:
        date_str = datetime.now().strftime("%d.%m.%Y")

    # üü¶ 0.2 RERANKER 2.0 ‚Äî –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–µ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    try:
        reranker = LLMReranker()

        before = len(docs)
        docs = [
            d for d in docs
            if "—Ä–∞–∑—ä—è—Å–Ω" not in (d.get("text", "") or "").lower()
            and "–∏–º–µ–µ—Ç –ø—Ä–∞–≤–æ" not in (d.get("text", "") or "").lower()
            and "–∫–æ–ø–∏—é –ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è" not in (d.get("text", "") or "").lower()
        ]
        logger.info(f"‚ö†Ô∏è –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ –ø—Ä–æ—Ü–µ—Å—Å—É–∞–ª—å–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {before - len(docs)}")

        QUERY = (
            "—Ñ–∞–∫—Ç—ã –ø—Ä–µ—Å—Ç—É–ø–ª–µ–Ω–∏—è: –ø–µ—Ä–µ–≤–æ–¥—ã –¥–µ–Ω–µ–≥, –≤–ª–æ–∂–µ–Ω–∏—è, –≤—ã–≤–æ–¥ —Å—Ä–µ–¥—Å—Ç–≤, "
            "–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏, –æ–±–º–∞–Ω, –¥–µ–π—Å—Ç–≤–∏—è –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º–æ–≥–æ, —Å–æ–±—ã—Ç–∏—è, —Å—É–º–º—ã, –¥–∞—Ç—ã"
        )

        
        docs = reranker.rerank(query=QUERY, items=docs)
        logger.info(f"üìä Reranker PRO 3.0 –ø—Ä–∏–º–µ–Ω—ë–Ω: –≤—ã–±—Ä–∞–Ω–æ TOP={len(docs)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")


    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ Reranker 2.0: {e}")

    # ============================================================
    # ‚≠ê VIP-PRIORITY: –ø—Ä–æ—Ç–æ–∫–æ–ª –¥–æ–ø—Ä–æ—Å–∞ –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º–æ–≥–æ
    # ============================================================
    for it in docs:
        text = it.get("text", "").lower()

        # VIP: –ü—Ä–æ—Ç–æ–∫–æ–ª –¥–æ–ø—Ä–æ—Å–∞ –ü–û–î–û–ó–†–ï–í–ê–ï–ú–û–ì–û
        if "–ø—Ä–æ—Ç–æ–∫–æ–ª –¥–æ–ø—Ä–æ—Å–∞ –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º" in text:
            it["cross_score"] = 0.999  # –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç

        # VIP: –ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –æ –ø—Ä–∏–∑–Ω–∞–Ω–∏–∏ –ª–∏—Ü–∞ –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º—ã–º
        if "–ø—Ä–∏–∑–Ω–∞–Ω–∏–∏ –ª–∏—Ü–∞ –≤ –∫–∞—á–µ—Å—Ç–≤–µ –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º" in text:
            it["cross_score"] = 0.998  # –ø–æ—á—Ç–∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π
    

    # üß∑ –û—Ç–¥–µ–ª—å–Ω–æ –∑–∞–±–∏—Ä–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å—É–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è —à–∞–ø–∫–∏
    intro_context = _extract_intro_context(docs)

    try:
        # 1Ô∏è‚É£ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ñ–∞–∫—Ç–æ–≤ / —Å—É—â–Ω–æ—Å—Ç–µ–π –∏–∑ docs
        try:
            facts, persons, dates, amounts, sources = _extract_facts_and_sources(docs)
        except Exception as e:
            raise RuntimeError(f"_extract_facts_and_sources error: {e}")

        facts = enrich_facts_with_roles(facts)

        # 1.1 –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –º—É—Å–æ—Ä–Ω—ã—Ö —Ñ–∞–∫—Ç–æ–≤
        raw_count = len(facts)
        facts = [
            f for f in facts
            if _legal_fact_filter(f.get("text", "")) and _hard_fact_clean(f.get("text", ""))
        ]
        facts = [f for f in facts if len(f["text"].split()) >= 3]

        logger.info(f"–§–ò–õ–¨–¢–† –§–ê–ö–¢–û–í: –±—ã–ª–æ={raw_count}, –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞={len(facts)}")

        # üü© NEW: –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —é—Ä–∏–¥–∏—á–µ—Å–∫–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è (–ø–æ —Ç–µ–∫—Å—Ç—É —Ñ–∞–∫—Ç–æ–≤)
        crime_class = classify_crime(facts)
        primary_article = crime_class["primary"]
        secondary_articles = crime_class["secondary"]
        logger.info(f"–ê–í–¢–û-–ö–í–ê–õ–ò–§–ò–ö–ê–¶–ò–Ø (classify_crime): primary={primary_article}, secondary={secondary_articles}")

        logger.info("RAW INPUT TO EXTRACTOR ‚Üì‚Üì‚Üì")
        for i, doc in enumerate(docs):
            t = doc.get("text", "") or ""
            logger.info(f"[{i}] len={len(t)} | page={doc.get('page')} | {t[:300].replace(chr(10), ' ')}")

        # 2Ô∏è‚É£ EXTRACTOR 2.0 (–±–µ–∑ LLM): suspect / events / crime_flow / crime_type
        try:
            extracted = extract_all(facts, persons, dates, amounts)
            suspect = extracted.get("suspect")
            events = extracted.get("events", [])
            crime_flow = extracted.get("crime_flow", [])
            crime_type = extracted.get("crime_type")
            
            # üî• –ù–û–í–û–ï: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º–æ–≥–æ
            if not suspect:
                suspect = _extract_suspect_name(facts, docs)
                logger.info(f"üìå –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º–æ–≥–æ: {suspect}")
            
            logger.info(f"üìå EXTRACTOR 2.0: suspect={suspect}, events={len(events)}, crime_type={crime_type}")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ EXTRACTOR 2.0: {e}")
            suspect, events, crime_flow, crime_type = None, [], [], None

        # üë§ –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–æ–ª—å –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º–æ–≥–æ
        suspect_role = _determine_suspect_role(facts, suspect) if suspect else None
        logger.info(f"üë§ –†–æ–ª—å –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º–æ–≥–æ: {suspect_role}")

        # 2.1 –§–æ—Ä–º–∏—Ä—É–µ–º roles/timeline/legal_facts –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        roles: Dict[str, Any] = {}
        if suspect:
            roles["suspect"] = [suspect]
            roles["suspect_role"] = suspect_role

        timeline = _build_timeline_from_events(events)

        legal_facts: Dict[str, Any] = {
            "crime_type": crime_type,
            "primary_article_hint": primary_article,
            "secondary_articles_hint": secondary_articles,
            "has_flow": bool(crime_flow),
        }

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∞–≤—Ç–æ-–∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏—è (–ø–æ —Å—Ç–∞—Ä–æ–º—É –±–ª–æ–∫—É)
        auto_article, auto_part, auto_reason = _auto_qualify(
            facts=facts,
            roles=roles,
            events=events,
            legal_facts=legal_facts,
        )
        logger.info(f"–ê–≤—Ç–æ-–∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏—è (auto_qualify): —Å—Ç–∞—Ç—å—è={auto_article}, —á–∞—Å—Ç—å={auto_part} ‚Äî {auto_reason}")

        # 3Ô∏è‚É£ –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–ª–Ω–æ—Ç—ã –ø–æ —Å—Ç. 204 –£–ü–ö –†–ö
        completeness = _check_204_completeness(
            facts=facts,
            persons=persons,
            dates=dates,
            amounts=amounts,
            roles=roles,
            events=events,
            legal_facts=legal_facts,
            timeline=timeline,
        )

        # 4Ô∏è‚É£ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–µ–π –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ê–§–ú
        mentioned_articles = _extract_articles(docs)
        logger.info(f"–£–ø–æ–º–∏–Ω–∞–Ω–∏–π —Å—Ç–∞—Ç–µ–π: {len(mentioned_articles)}")

        law_contexts: List[str] = []
        for art in mentioned_articles:
            num = art.get("article")
            if num and num in ALL_AFM_LAWS:
                law_contexts.append(_resolve_law_context(num))
        law_context_text = "\n".join(law_contexts[:5]) if law_contexts else ""

        # 5Ô∏è‚É£ –ë–∞–∑–æ–≤—ã–π —Ä–∞–∑–¥–µ–ª ¬´–£–°–¢–ê–ù–û–í–ò–õ¬ª (—Å –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º—ã–º!)
        ustanovil_text = _build_ustanovil_text(
            facts=facts,
            sources=sources,
            completeness=completeness,
            suspect=suspect,
            suspect_role=suspect_role,
        )
        logger.info(f"üìù –†–∞–∑–¥–µ–ª –£–°–¢–ê–ù–û–í–ò–õ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω (–ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º—ã–π: {suspect})")

        # 6Ô∏è‚É£ –ü–æ–ø—ã—Ç–∫–∞ —É–ª—É—á—à–∏—Ç—å ¬´–£–°–¢–ê–ù–û–í–ò–õ¬ª —á–µ—Ä–µ–∑ LLM
        if facts:
            try:
                fact_lines: List[str] = []
                for f in facts:
                    fact_lines.append(f"- {f['text']} {_src_str(f.get('sources'))}")

                missing_text = ", ".join(completeness.get("missing", [])) or "–Ω–µ—Ç"

                # üî• –ù–û–í–û–ï: –¥–æ–±–∞–≤–ª—è–µ–º –±–ª–æ–∫ –æ –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º–æ–º
                suspect_block = ""
                if suspect:
                    suspect_block = f"""
–ü–û–î–û–ó–†–ï–í–ê–ï–ú–´–ô:
–ò–º—è: {suspect}
–†–æ–ª—å: {suspect_role or '–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞'}
---

"""

                strict_prompt = prompts.U_STSTRICT.format(
                    suspect_info=suspect_block,
                    facts="\n".join(fact_lines),
                    missing=missing_text,
                )

                system_prompt = (
                    "–¢—ã ‚Äî —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –º–æ–¥—É–ª—å ¬´AI_Qualifier¬ª –¥–ª—è –æ—Ä–≥–∞–Ω–æ–≤ —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–≥–æ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞. "
                    "–¢–≤–æ—è –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–∞—è –∑–∞–¥–∞—á–∞ ‚Äî —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å —Ä–∞–∑–¥–µ–ª ¬´–£–°–¢–ê–ù–û–í–ò–õ¬ª —Å—Ç—Ä–æ–≥–æ –∏ –∏—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ "
                    "–ø–µ—Ä–µ–¥–∞–Ω–Ω–æ–≥–æ –º–∞—Å—Å–∏–≤–∞ facts[] –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º–æ–º. "

                    "============================== "
                    "üîí –û–°–ù–û–í–ù–û–ï –ü–†–ê–í–ò–õ–û "
                    "============================== "
                    "–†–∞–∑—Ä–µ—à–µ–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¢–û–õ–¨–ö–û —Ç–æ—Ç —Ç–µ–∫—Å—Ç, –∫–æ—Ç–æ—Ä—ã–π —Å–æ–¥–µ—Ä–∂–∏—Ç—Å—è –≤ facts[]. "
                    "–ó–∞–ø—Ä–µ—â–µ–Ω–æ –æ–±—Ä–∞—â–∞—Ç—å—Å—è –∫ –∏—Å—Ö–æ–¥–Ω—ã–º –¥–æ–∫—É–º–µ–Ω—Ç–∞–º, —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∏—Ä–æ–≤–∞—Ç—å –∏—Ö, –¥–æ–ø–æ–ª–Ω—è—Ç—å –ø—Ä–æ–ø—É—Å–∫–∏ "
                    "–∏–ª–∏ –ø—ã—Ç–∞—Ç—å—Å—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –Ω–µ–¥–æ—Å—Ç–∞—é—â—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. "

                    "============================== "
                    "üö´ –°–¢–†–û–ì–ò–ô –ó–ê–ü–†–ï–¢ –ù–ê –î–û–ë–ê–í–õ–ï–ù–ò–ï –ù–û–í–´–• –°–í–ï–î–ï–ù–ò–ô "
                    "============================== "
                    "–ó–∞–ø—Ä–µ—â–µ–Ω–æ –¥–æ–±–∞–≤–ª—è—Ç—å —Å–≤–µ–¥–µ–Ω–∏—è, –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –≤ facts[], –≤–∫–ª—é—á–∞—è: "
                    "–Ω–∞–∑–≤–∞–Ω–∏—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π, –ø–ª–∞—Ç—Ñ–æ—Ä–º, –ª—é–¥–µ–π, —Å—É–º–º—ã, –¥–∞—Ç—ã, —Å–ø–æ—Å–æ–±—ã –ø–µ—Ä–µ–≤–æ–¥–∞, "
                    "—É—Å–ª–æ–≤–∏—è –Ω–∞—á–∏—Å–ª–µ–Ω–∏–π, –æ–±–µ—â–∞–Ω–∏—è –¥–æ—Ö–æ–¥–∞, —Å—Ö–µ–º—ã, –º–æ—Ç–∏–≤—ã, –≤–µ—Ä—Å–∏–∏ —Å–æ–±—ã—Ç–∏–π, "
                    "—é—Ä–∏–¥–∏—á–µ—Å–∫–∏–µ –≤—ã–≤–æ–¥—ã, –∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏—é, —Å—Ç–∞—Ç—å–∏ –£–ö/–£–ü–ö, –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è, –æ–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–µ—Å—Ç—É–ø–ª–µ–Ω–∏—è, "
                    "–∞ —Ç–∞–∫–∂–µ –ª—é–±—ã–µ –¥–µ–π—Å—Ç–≤–∏—è –∏–ª–∏ –¥–µ—Ç–∞–ª–∏, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ —Ñ–∞–∫—Ç–∞—Ö. "
                    "–ù–∏–∫–∞–∫–∏—Ö –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–π, –≥–∏–ø–æ—Ç–µ–∑, –ø—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏–π –∏–ª–∏ –ø—Ä–∏—á–∏–Ω–Ω–æ-—Å–ª–µ–¥—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Å–≤—è–∑–µ–π. "

                    "============================== "
                    "‚úçÔ∏è –ß–¢–û –†–ê–ó–†–ï–®–ï–ù–û "
                    "============================== "
                    "–†–∞–∑—Ä–µ—à–µ–Ω–æ —Ç–æ–ª—å–∫–æ: "
                    "‚Äî –æ–±—ä–µ–¥–∏–Ω—è—Ç—å —Ñ–∞–∫—Ç—ã; "
                    "‚Äî —É—Å—Ç—Ä–∞–Ω—è—Ç—å –ø–æ–≤—Ç–æ—Ä—ã; "
                    "‚Äî –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Å–º—ã—Å–ª–∞; "
                    "‚Äî –≤—ã—Å—Ç—Ä–∞–∏–≤–∞—Ç—å —Ñ–∞–∫—Ç—ã –≤ –ª–æ–≥–∏—á–Ω—É—é —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—é. "
                    "–õ—é–±–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Å–º—ã—Å–ª–∞ ‚Äî –ù–ê–†–£–®–ï–ù–ò–ï. "

                    "============================== "
                    "üîó –ò–°–¢–û–ß–ù–ò–ö–ò "
                    "============================== "
                    "–ö–∞–∂–¥–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –∑–∞–∫–∞–Ω—á–∏–≤–∞—Ç—å—Å—è —Å—Å—ã–ª–∫–æ–π –≤–∏–¥–∞ [file_id:page]. "
                    "–†–∞–∑—Ä–µ—à–µ–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ —Ç–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ —É–∫–∞–∑–∞–Ω—ã –≤ fact['sources']. "
                    "–ï—Å–ª–∏ —É —Ñ–∞–∫—Ç–∞ –Ω–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–∞ ‚Äî —ç—Ç–æ—Ç —Ñ–∞–∫—Ç –ù–ï–õ–¨–ó–Ø –≤–∫–ª—é—á–∞—Ç—å. "

                    "============================== "
                    "‚ö†Ô∏è –ï–°–õ–ò –§–ê–ö–¢–û–í –ù–ï–î–û–°–¢–ê–¢–û–ß–ù–û "
                    "============================== "
                    "–ï—Å–ª–∏ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ —Å–æ—Å—Ç–∞–≤–∏—Ç—å —Å–≤—è–∑–Ω—ã–π —Ä–∞–∑–¥–µ–ª ¬´–£–°–¢–ê–ù–û–í–ò–õ¬ª —Ç–æ–ª—å–∫–æ –∏–∑ facts[], "
                    "–∏–ª–∏ —Ñ–∞–∫—Ç—ã —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞—Ä–Ω—ã, –∏–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–∏ ‚Äî –Ω–∞–ø–∏—à–∏ —Å—Ç—Ä–æ–≥–æ: "
                    "¬´–°—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ñ–∞–∫—Ç–æ–≤ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, —Ç—Ä–µ–±—É–µ—Ç—Å—è –ø—Ä–æ–≤–µ—Ä–∫–∞¬ª. "

                    "============================== "
                    "üìå –§–û–†–ú–ê–¢ –í–´–í–û–î–ê "
                    "============================== "
                    "–í—ã–≤–æ–¥–∏ —Å—Ç—Ä–æ–≥–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ: "
                    "–£–°–¢–ê–ù–û–í–ò–õ: "
                    "<–ø–µ—Ä–µ—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Ñ–∞–∫—Ç—ã> "
                    "–ë–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π, –±–µ–∑ –∞–Ω–∞–ª–∏–∑–∞, –±–µ–∑ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π, –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤. "
                )

                ustanovil_text = _ask_llm(
                    prompt=strict_prompt,
                    system_prompt=system_prompt,
                )
                logger.info("‚úÖ –†–∞–∑–¥–µ–ª ¬´–£–°–¢–ê–ù–û–í–ò–õ¬ª —É–ª—É—á—à–µ–Ω —á–µ—Ä–µ–∑ LLM.")
            except LLMUnavailableError as e:
                logger.warning(f"LLM –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è —Ä–∞–∑–¥–µ–ª–∞ ¬´–£–°–¢–ê–ù–û–í–ò–õ¬ª: {e}")

        # üßº –£–¥–∞–ª—è–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Å—Å—ã–ª–∫–∏ –ø–µ—Ä–µ–¥ –≤–∫–ª—é—á–µ–Ω–∏–µ–º –≤ —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ –ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ
        clean_ustanovil = _remove_sources(ustanovil_text)

        # 7Ô∏è‚É£ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –ü–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
        final_postanovlenie: str
        try:
            safe_article = primary_article or auto_article or "[–¢—Ä–µ–±—É–µ—Ç —É—Ç–æ—á–Ω–µ–Ω–∏—è]"

            post_prompt = prompts.P_POST.format(ustanovil=clean_ustanovil)

            system_for_post = (
                "–¢—ã ‚Äî —É–∑–∫–æ—Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –º–æ–¥—É–ª—å ¬´AI_Qualifier_Post¬ª. "
                "–¢–≤–æ—è –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–∞—è –∑–∞–¥–∞—á–∞ ‚Äî —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å —Ä–∞–∑–¥–µ–ª ¬´–ü–û–°–¢–ê–ù–û–í–ò–õ¬ª "
                "–∏—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–∞ —Ä–∞–∑–¥–µ–ª–∞ ¬´–£–°–¢–ê–ù–û–í–ò–õ¬ª. "

                "üîí –û–ì–†–ê–ù–ò–ß–ï–ù–ò–Ø (–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û): "
                "- –∑–∞–ø—Ä–µ—â–µ–Ω–æ –¥–æ–±–∞–≤–ª—è—Ç—å –ù–û–í–´–ï —Å–≤–µ–¥–µ–Ω–∏—è; "
                "- –∑–∞–ø—Ä–µ—â–µ–Ω–æ —É–ø–æ–º–∏–Ω–∞—Ç—å –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏, –≤–µ–¥–æ–º—Å—Ç–≤–∞, —Å—Ç—Ä—É–∫—Ç—É—Ä—ã (–ú–í–î, –°–û, –î–ü, –ø—Ä–æ–∫—É—Ä–∞—Ç—É—Ä–∞ –∏ —Ç.–ø.); "
                "- –∑–∞–ø—Ä–µ—â–µ–Ω–æ –æ–ø–∏—Å—ã–≤–∞—Ç—å —Å—Ö–µ–º—ã, –º–æ—Ç–∏–≤—ã, —É–º—ã—Å–µ–ª, –¥–µ–π—Å—Ç–≤–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ –£–°–¢–ê–ù–û–í–ò–õ; "
                "- –∑–∞–ø—Ä–µ—â–µ–Ω–æ –¥–æ–±–∞–≤–ª—è—Ç—å –∏–º–µ–Ω–∞, –¥–∞—Ç—ã, —Å—É–º–º—ã, —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤; "
                "- –∑–∞–ø—Ä–µ—â–µ–Ω–æ –ø—Ä–∏–¥—É–º—ã–≤–∞—Ç—å —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–µ –≤—ã–≤–æ–¥—ã; "
                "- –∑–∞–ø—Ä–µ—â–µ–Ω–æ –¥–∞–≤–∞—Ç—å —Å–æ–≤–µ—Ç—ã —Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—é; "
                "- –∑–∞–ø—Ä–µ—â–µ–Ω–æ –¥–æ–±–∞–≤–ª—è—Ç—å —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è —ç–∫—Å–ø–µ—Ä—Ç–∏–∑, –±–∞–Ω–∫–æ–≤—Å–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤, –¥–æ–ø—Ä–æ—Å–æ–≤; "
                "- –∑–∞–ø—Ä–µ—â–µ–Ω–æ –ø–∏—Å–∞—Ç—å –æ—Ü–µ–Ω–æ—á–Ω—ã–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏; "

                "–†–∞–∑–¥–µ–ª ¬´–£–°–¢–ê–ù–û–í–ò–õ¬ª –Ω—É–∂–Ω–æ –≤—Å—Ç–∞–≤–∏—Ç—å –î–û–°–õ–û–í–ù–û, –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π. "

                "–¢—ã –ù–ï —Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å. –ù–∏–∫–∞–∫–∏—Ö –∫–ª–∏—à–µ –ú–í–î, —à–∞–ø–æ–∫, –≥–µ—Ä–±–æ–≤, —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã—Ö –±–ª–æ–∫–æ–≤. "
                "–°—Ç—Ä–æ–≥–æ –æ–¥–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞: "
                "–£–°–¢–ê–ù–û–í–ò–õ ‚Üí –ü–û–°–¢–ê–ù–û–í–ò–õ ‚Üí –ø–æ–¥–ø–∏—Å—å. "

                "–ï—Å–ª–∏ –≤ –£–°–¢–ê–ù–û–í–ò–õ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö ‚Äî "
                "–≤ —Ä–∞–∑–¥–µ–ª–µ –ü–û–°–¢–ê–ù–û–í–ò–õ –Ω—É–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å —Ç–æ–ª—å–∫–æ: "
                "¬´–¢—Ä–µ–±—É–µ—Ç—Å—è –ø–æ–ª—É—á–µ–Ω–∏–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –¥–ª—è –æ–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω–æ–π –∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏–∏¬ª. "
            )

            full_user_prompt = f"""
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã—è–≤–ª–µ–Ω–Ω–∞—è —Å—Ç–∞—Ç—å—è –£–ö –†–ö (–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä): {primary_article or "–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞"}.
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã—è–≤–ª–µ–Ω–Ω–∞—è —Å—Ç–∞—Ç—å—è –£–ö –†–ö (–∞–Ω–∞–ª–∏–∑ —Ñ–∞–∫—Ç–æ–≤): {auto_article or "–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞"} —á.{auto_part or "-"}.
–ü—Ä–∏—á–∏–Ω–∞: {auto_reason}.

–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π —Ç–∏–ø –ø—Ä–µ—Å—Ç—É–ø–ª–µ–Ω–∏—è (–±–µ–∑ LLM): {crime_type or "–Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ"}.

–ú–∞—Ç–µ—Ä–∏–∞–ª—ã –¥–µ–ª–∞ ‚Ññ {case_id}.
–ú–µ—Å—Ç–æ –≤—ã–Ω–µ—Å–µ–Ω–∏—è: {city}.
–î–∞—Ç–∞: {_rus_date(date_str)}.

–ü—Ä–æ—Ü–µ—Å—Å—É–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (–µ–≥–æ –Ω—É–∂–Ω–æ –î–û–°–õ–û–í–ù–û –≤—Å—Ç–∞–≤–∏—Ç—å –ø–µ—Ä–µ–¥ —Ä–∞–∑–¥–µ–ª–æ–º ¬´–£–°–¢–ê–ù–û–í–ò–õ¬ª, –µ—Å–ª–∏ –æ–Ω –Ω–µ –ø—É—Å—Ç–æ–π):
{intro_context or "[–Ω–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å—É–∞–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞]"}

–í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–π —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (–µ—Å–ª–∏ –µ—Å—Ç—å):
{law_context_text or "[–Ω–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–æ–∫ –∑–∞–∫–æ–Ω–æ–≤]"}

–û—Å–Ω–æ–≤—ã–≤–∞–π—Å—è –∏—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ –Ω–∞ —Ä–∞–∑–¥–µ–ª–µ ¬´–£–°–¢–ê–ù–û–í–ò–õ¬ª –Ω–∏–∂–µ –∏ –Ω–∞ –±–ª–æ–∫–µ –ø—Ä–æ—Ü–µ—Å—Å—É–∞–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –≤—ã—à–µ.

{post_prompt}

–°—Ç–∞—Ç—å—è –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–π –∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏–∏ (–µ—Å–ª–∏ —ç—Ç–æ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç—Å—è —Ñ–∞–∫—Ç–∞–º–∏): {safe_article}.
–ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ ‚Äî –≤ —Ä–∞–∑–¥–µ–ª–µ ¬´–ü–û–°–¢–ê–ù–û–í–ò–õ¬ª –æ—Ç—Ä–∞–∑–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –ø–æ–ª—É—á–µ–Ω–∏—è
–¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤ –ø–µ—Ä–µ–¥ –æ–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω–æ–π –∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏–µ–π.
"""

            final_postanovlenie = _ask_llm(
                prompt=full_user_prompt,
                system_prompt=system_for_post,
            )
            logger.info("‚úÖ –ü–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ —á–µ—Ä–µ–∑ LLM.")
        except LLMUnavailableError as e:
            logger.warning(f"LLM –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è –ü–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è: {e}")
            final_postanovlenie = _build_postanovlenie_simple(
                city=city,
                date_str=date_str,
                investigator_line=investigator_line,
                case_id=case_id,
                ustanovil_text=clean_ustanovil,
                mentioned_articles=mentioned_articles,
                completeness=completeness,
                investigator_fio=investigator_fio,
                intro_context=intro_context,
                suspect=suspect,
            )

        # 8Ô∏è‚É£ –°—Ç—Ä–∞—Ö–æ–≤–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã (–Ω–∞–ª–∏—á–∏–µ ¬´–£–°–¢–ê–ù–û–í–ò–õ¬ª –∏ ¬´–ü–û–°–¢–ê–ù–û–í–ò–õ¬ª)
        lower_body = final_postanovlenie.lower()
        if "—É—Å—Ç–∞–Ω–æ–≤–∏–ª" not in lower_body or "–ø–æ—Å—Ç–∞–Ω–æ–≤–∏–ª" not in lower_body:
            logger.warning("‚ö†Ô∏è LLM –æ—Ç–∫–ª–æ–Ω–∏–ª—Å—è –æ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—ã, –ø—Ä–∏–º–µ–Ω—è—é fallback-—à–∞–±–ª–æ–Ω –ü–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è.")
            final_postanovlenie = _build_postanovlenie_simple(
                city=city,
                date_str=date_str,
                investigator_line=investigator_line,
                case_id=case_id,
                ustanovil_text=clean_ustanovil,
                mentioned_articles=mentioned_articles,
                completeness=completeness,
                investigator_fio=investigator_fio,
                intro_context=intro_context,
                suspect=suspect,
            )

        # 9Ô∏è‚É£ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å + –±–∞–∑–æ–≤—ã–π result
        overall_conf = _overall_confidence(facts, completeness)
        warnings: List[str] = []

        result: Dict[str, Any] = {
            "generation_id": str(uuid.uuid4()),
            "model_version": MODEL_VERSION,
            "case_id": case_id,
            "facts": facts,
            "persons": persons,
            "dates": dates,
            "amounts": amounts,
            "mentioned_articles": mentioned_articles,
            "roles": roles,
            "events": events,
            "timeline": timeline,
            "legal_facts": legal_facts,
            "completeness_204": completeness,
            "established_text": clean_ustanovil.strip(),
            "final_postanovlenie": final_postanovlenie.strip(),
            "sources": sources,
            "confidence": round(overall_conf, 3),
            "timestamp": datetime.utcnow().isoformat() + "Z",
            "investigator_fio": investigator_fio,
            "investigator_line": investigator_line,
            "auto_article": auto_article,
            "auto_part": auto_part,
            "auto_reason": auto_reason,
            "auto_classification": crime_class,
            "suspect": suspect,
            "suspect_role": suspect_role,
            "crime_flow": crime_flow,
            "crime_type": crime_type,
            "warnings": warnings,
        }

        # üîü Anti-hallucination –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è
        try:
            verification = run_full_verification(result)
            if not isinstance(verification, dict):
                raise ValueError("–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏")

            result["verification"] = verification
            result["verdict"] = (
                "OK"
                if verification.get("overall_ok")
                else verification.get("texts", {}).get("verdict", "UNVERIFIED")
            )

            if not verification.get("overall_ok"):
                result["warnings"].append("‚ö†Ô∏è –í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è –≤—ã—è–≤–∏–ª–∞ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –Ω–µ—Ç–æ—á–Ω–æ—Å—Ç–∏")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏: {e}")
            result["verification"] = {"error": str(e)}
            result["verdict"] = "VERIFICATION_FAILED"
            result["warnings"].append(f"–û—à–∏–±–∫–∞ –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏: {str(e)}")

        logger.info(
            f"‚úÖ –ö–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞. verdict={result.get('verdict')}, "
            f"conf={result.get('confidence'):.2f}, suspect={suspect}"
        )
        return result

    except LLMUnavailableError as e:
        logger.error(f"LLMUnavailableError –≤ qualify_documents: {e}")
        raise
    except Exception as e:
        logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏–∏: {e}", exc_info=True)
        return _empty_result(case_id, f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}")

# ============================================================
# üîπ Fallback-—Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö
# ============================================================

def _empty_result(case_id: str, msg: str, investigator_fio: str = "", investigator_line: str = "") -> dict:
    return {
        "generation_id": None,
        "model_version": MODEL_VERSION,
        "case_id": case_id,
        "established_text": "",
        "final_postanovlenie": f"[–û–®–ò–ë–ö–ê]: {msg}",
        "facts": [],
        "persons": [],
        "dates": [],
        "amounts": [],
        "mentioned_articles": [],
        "roles": {},
        "events": [],
        "timeline": [],
        "legal_facts": {},
        "completeness_204": {},
        "sources": [],
        "confidence": 0.0,
        "timestamp": datetime.utcnow().isoformat() + "Z",
        "investigator_fio": investigator_fio,
        "investigator_line": investigator_line,
        "warnings": [msg],
        "verification": {"overall_ok": False},
        "verdict": "ERROR",
        "suspect": None,
        "suspect_role": None,
        "crime_flow": [],
        "crime_type": None,
    }

# ============================================================
# üß∞ –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —É—Ç–∏–ª–∏—Ç—ã
# ============================================================

def _remove_sources(text: str) -> str:
    """–£–¥–∞–ª—è–µ—Ç —Å—Å—ã–ª–∫–∏ –≤–∏–¥–∞ [uuid:page] –∏–∑ —Ç–µ–∫—Å—Ç–∞."""
    return re.sub(r"\[[0-9a-fA-F\-]{36}:\d+\]", "", text)

def _context_snippet(text: str, start: int, end: int, radius: int = CONTEXT_RADIUS) -> str:
    a, b = max(0, start - radius), min(len(text), end + radius)
    return text[a:b].replace("\n", " ").strip()

def _src_str(sources: List[Dict[str, Any]] | None) -> str:
    if not sources:
        return "[–∏—Å—Ç–æ—á–Ω–∏–∫: –Ω–µ —É–∫–∞–∑–∞–Ω]"
    show = [f"[{s.get('file_id', '?')}:{s.get('page', '-')}]"
            for s in sources[:3]]
    if len(sources) > 3:
        show.append(f"(–∏ –µ—â—ë {len(sources) - 3})")
    return " ".join(show)

def _conf_from_signal(sentence: str) -> float:
    score = MIN_FACT_CONFIDENCE
    if DATE_RX.search(sentence):
        score += 0.15
    if MONEY_RX.search(sentence):
        score += 0.15
    if PERSON_RX.search(sentence):
        score += 0.1
    return min(score, 0.95)

def _dedup_sources(sources: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    seen, out = set(), []
    for s in sources:
        key = (s.get("file_id"), s.get("page"))
        if key not in seen:
            seen.add(key)
            out.append(s)
    return out

def _dedup_articles(arts: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    seen, out = set(), []
    for a in arts:
        key = (
            a["code"],
            a["article"],
            a["source"].get("file_id"),
            a["source"].get("page"),
        )
        if key not in seen:
            seen.add(key)
            out.append(a)
    return out

def _overall_confidence(facts: List[dict], completeness: dict) -> float:
    if not facts:
        return 0.4
    avg = sum(f.get("confidence", 0.5) for f in facts) / max(1, len(facts))
    miss_penalty = 0.05 * len(completeness.get("missing", []))
    return max(0.1, min(0.98, avg - miss_penalty))

def _rus_date(d: str) -> str:
    """
    –ü–æ–Ω–∏–º–∞–µ—Ç 'DD.MM.YYYY' –∏ ISO 'YYYY-MM-DD'.
    –ï—Å–ª–∏ —Ñ–æ—Ä–º–∞—Ç –Ω–µ–∏–∑–≤–µ—Å—Ç–µ–Ω ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏—Å—Ö–æ–¥–Ω—É—é —Å—Ç—Ä–æ–∫—É.
    """
    try:
        if re.fullmatch(r"\d{4}-\d{2}-\d{2}", d):
            dt = datetime.fromisoformat(d)
        else:
            dt = datetime.strptime(d, "%d.%m.%Y")
    except Exception:
        return d

    months = [
        "—è–Ω–≤–∞—Ä—è", "—Ñ–µ–≤—Ä–∞–ª—è", "–º–∞—Ä—Ç–∞", "–∞–ø—Ä–µ–ª—è", "–º–∞—è", "–∏—é–Ω—è",
        "–∏—é–ª—è", "–∞–≤–≥—É—Å—Ç–∞", "—Å–µ–Ω—Ç—è–±—Ä—è", "–æ–∫—Ç—è–±—Ä—è", "–Ω–æ—è–±—Ä—è", "–¥–µ–∫–∞–±—Ä—è",
    ]
    return f"{dt.day} {months[dt.month - 1]} {dt.year} –≥–æ–¥–∞"

def _build_timeline_from_events(events: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    –°—Ç—Ä–æ–∏—Ç —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—é –ø–æ —Å–æ–±—ã—Ç–∏—è–º Extractor 2.0 (–ø–æ –ø–æ–ª—é 'date' —Ñ–æ—Ä–º–∞—Ç–∞ DD.MM.YYYY).
    """
    cleaned: List[tuple[datetime, Dict[str, Any]]] = []
    for e in events:
        d = e.get("date")
        if not d:
            continue
        try:
            dt = datetime.strptime(d, "%d.%m.%Y")
            cleaned.append((dt, e))
        except Exception:
            continue

    cleaned.sort(key=lambda x: x[0])
    return [e for _, e in cleaned]

