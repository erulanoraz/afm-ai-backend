# app/services/agents/ai_qualifier.py
from __future__ import annotations

import logging
import re
import uuid
from collections import defaultdict
from datetime import datetime
from typing import Any, Dict, List, Optional

from fastapi import HTTPException

from app.utils.config import settings
from app.services.validation.verifier import run_full_verification
from app.services.agents.ai_laws import ALL_AFM_LAWS
from app.services.agents.ai_extractor import extract_all
from app.services.llm_client import LLMClient
from app.services.agents import prompts

logger = logging.getLogger(__name__)

# ============================================================
# ‚öôÔ∏è –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ / –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã
# ============================================================

MODEL_VERSION = "qualifier-llm-2.1"
MIN_FACT_CONFIDENCE = 0.5
CONTEXT_RADIUS = 60

# LLM-–∫–ª–∏–µ–Ω—Ç (–∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–≤–æ–π –æ–±—â–∏–π –∞–¥–∞–ø—Ç–µ—Ä)
_llm_client = LLMClient()


# ============================================================
# üß© –ö–∞—Å—Ç–æ–º–Ω—ã–µ –æ—à–∏–±–∫–∏
# ============================================================

class LLMUnavailableError(Exception):
    """–ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –∏–ª–∏ –æ—à–∏–±–∫–µ LLM."""
    pass


# ============================================================
# üîå –û–±—ë—Ä—Ç–∫–∞ –Ω–∞–¥ LLMClient (–µ–¥–∏–Ω–∞—è —Ç–æ—á–∫–∞ –≤—ã–∑–æ–≤–∞)
# ============================================================

def _ask_llm(
    prompt: str,
    system_prompt: Optional[str] = None,
) -> str:
    """
    –í—ã–∑–æ–≤ LLM —á–µ—Ä–µ–∑ –æ–±—â–∏–π –∫–ª–∏–µ–Ω—Ç.
    –ï—Å–ª–∏ LLM –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω / –≤–µ—Ä–Ω—É–ª –æ—à–∏–±–∫—É ‚Äî –ø–æ–¥–Ω–∏–º–∞–µ–º LLMUnavailableError.
    """
    messages: List[Dict[str, str]] = []
    if system_prompt:
        messages.append({"role": "system", "content": system_prompt})
    messages.append({"role": "user", "content": prompt})

    try:
        content = _llm_client.chat(messages)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤—ã–∑–æ–≤–∞ LLM: {e}")
        raise LLMUnavailableError(str(e))

    if not content or isinstance(content, str) and content.startswith("[LLM ERROR]"):
        raise LLMUnavailableError(content or "–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç LLM")

    return content.strip()


# ============================================================
# üßÆ –†–µ–≥—É–ª—è—Ä–∫–∏ –¥–ª—è –ø–µ—Ä–≤–∏—á–Ω–æ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
# ============================================================

PERSON_RX = re.compile(
    r"\b([–ê-–Ø–Å][–∞-—è—ë]+(?:\s+[–ê-–Ø–Å]\.){1,2}|[–ê-–Ø–Å][–∞-—è—ë]+(?:\s+[–ê-–Ø–Å][–∞-—è—ë]+){1,2})\b"
)
DATE_RX = re.compile(r"\b(\d{1,2}[./-]\d{1,2}[./-]\d{2,4}|\d{4}-\d{2}-\d{2})\b")
MONEY_RX = re.compile(
    r"(?:(\d{1,3}(?:\s?\d{3})+|\d+)(?:[.,]\d{1,2})?)\s?(?:—Ç–≥|—Ç–µ–Ω–≥–µ|KZT|‚Ç∏)",
    re.IGNORECASE,
)
ART_RX = re.compile(
    r"(—Å—Ç\.?|—Å—Ç–∞—Ç—å[—å—è–∏])\s*([0-9]{1,3}(?:[-‚Äì][0-9]+)?)(?:\s*(–£–ö|–£–ü–ö|–ì–ö)\s*–†–ö)?",
    re.IGNORECASE,
)

EVENT_HINTS = [
    "–ø–µ—Ä–µ–≤—ë–ª", "–ø–µ—Ä–µ–≤–µ–ª–∞", "–ø–µ—Ä–µ—á–∏—Å–ª–∏–ª", "–ø–µ—Ä–µ—á–∏—Å–ª–∏–ª–∞",
    "–ø–æ–ª—É—á–∏–ª", "–ø–æ–ª—É—á–∏–ª–∞", "–∑–∞–∫–ª—é—á–∏–ª –¥–æ–≥–æ–≤–æ—Ä", "–∑–∞–∫–ª—é—á–∏–ª–∞ –¥–æ–≥–æ–≤–æ—Ä",
    "–ø–æ–¥–ø–∏—Å–∞–ª", "–ø–æ–¥–ø–∏—Å–∞–ª–∞", "–≤—ã–≤–æ–¥ —Å—Ä–µ–¥—Å—Ç–≤", "—Å–Ω—è—Ç–∏–µ –Ω–∞–ª–∏—á–Ω—ã—Ö",
    "—Ö–∏—â–µ–Ω–∏–µ", "–º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–æ", "–Ω–µ–∑–∞–∫–æ–Ω–Ω–æ–µ –æ–±–æ–≥–∞—â–µ–Ω–∏–µ", "–ø—Ä–∏—Å–≤–æ–µ–Ω–∏–µ"
]


# ============================================================
# üîé –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ñ–∞–∫—Ç–æ–≤ –∏ –±–∞–∑–æ–≤—ã—Ö —Å—É—â–Ω–æ—Å—Ç–µ–π –∏–∑ docs
# ============================================================

def _extract_facts_and_sources(
    docs: List[Dict[str, Any]]
) -> tuple[list[dict], list[str], list[str], list[str], list[dict]]:
    """
    docs –ø—Ä–∏—Ö–æ–¥–∏—Ç –∏–∑ retrieval.get_file_docs_for_qualifier –≤ —Ñ–æ—Ä–º–∞—Ç–µ:
    {
        "file_id": "uuid",
        "page": 1,
        "chunk_id": "uuid",
        "text": "..."
    }
    """
    facts: List[Dict[str, Any]] = []
    persons: List[str] = []
    dates: List[str] = []
    amounts: List[str] = []
    sources: List[Dict[str, Any]] = []
    fact_id = 1

    for d in docs:
        text = (d.get("text") or "").strip()
        file_id = d.get("file_id")
        page = d.get("page")

        if not text:
            continue

        if file_id:
            sources.append({"file_id": file_id, "page": page})

        # üë§ –ò–º–µ–Ω–∞
        for m in PERSON_RX.finditer(text):
            p = m.group(1)
            if len(p) > 2 and not any(x in p for x in ["–ê–û", "–¢–û–û", "–ò–ü", "–û–û–û"]):
                if p not in persons:
                    persons.append(p)

        # üìÖ –î–∞—Ç—ã
        for m in DATE_RX.finditer(text):
            dt = m.group(1)
            if dt not in dates:
                dates.append(dt)

        # üí∞ –°—É–º–º—ã
        for m in MONEY_RX.finditer(text):
            amt = m.group(0)
            if amt not in amounts:
                amounts.append(amt)

        # ‚ö° –°–æ–±—ã—Ç–∏—è –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
        for sent in _split_sentences(text):
            if any(h in sent.lower() for h in EVENT_HINTS):
                if sent not in [f["text"] for f in facts]:
                    facts.append(
                        {
                            "fact_id": f"f{fact_id}",
                            "type": "event",
                            "text": sent.strip()[:500],
                            "confidence": _conf_from_signal(sent),
                            "sources": [{"file_id": file_id, "page": page}],
                        }
                    )
                    fact_id += 1

    # –ï—Å–ª–∏ —Å–æ–±—ã—Ç–∏–π –Ω–µ—Ç, –Ω–æ –µ—Å—Ç—å –±–∞–∑–æ–≤—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç ‚Äî —Å–æ–±–∏—Ä–∞–µ–º –∫—Ä–∞—Ç–∫—É—é —Å–≤–æ–¥–∫—É
    if not facts and (persons or dates or amounts):
        base_parts = []
        if persons:
            base_parts.append(f"–£—á–∞—Å—Ç–Ω–∏–∫–∏: {', '.join(persons[:5])}")
        if dates:
            base_parts.append(f"–î–∞—Ç—ã: {', '.join(dates[:5])}")
        if amounts:
            base_parts.append(f"–°—É–º–º—ã: {', '.join(amounts[:5])}")

        if base_parts:
            facts.append(
                {
                    "fact_id": f"f{fact_id}",
                    "type": "context",
                    "text": "; ".join(base_parts),
                    "confidence": 0.55,
                    "sources": sources[:1] if sources else [],
                }
            )

    return facts, persons, dates, amounts, _dedup_sources(sources)


# ============================================================
# üß† –û–±–æ–≥–∞—â–µ–Ω–∏–µ —Ñ–∞–∫—Ç–æ–≤ —Ä–æ–ª—è–º–∏ / –¥–µ–π—Å—Ç–≤–∏—è–º–∏
# ============================================================

def enrich_facts_with_roles(facts: list[dict]) -> list[dict]:
    ROLE_HINTS = {
        "–ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º": "–ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º—ã–π",
        "–æ–±–≤–∏–Ω—è": "–æ–±–≤–∏–Ω—è–µ–º—ã–π",
        "—Å–≤–∏–¥–µ—Ç–µ–ª": "—Å–≤–∏–¥–µ—Ç–µ–ª—å",
        "–ø–æ—Ç–µ—Ä–ø–µ–≤—à": "–ø–æ—Ç–µ—Ä–ø–µ–≤—à–∏–π",
        "—Å–æ—É—á–∞—Å—Ç": "—Å–æ—É—á–∞—Å—Ç–Ω–∏–∫",
        "–æ—Ä–≥–∞–Ω–∏–∑–∞—Ç–æ—Ä": "–æ—Ä–≥–∞–Ω–∏–∑–∞—Ç–æ—Ä",
    }
    ACTION_HINTS = [
        "–ø–µ—Ä–µ–≤—ë–ª", "–ø–µ—Ä–µ–¥–∞–ª", "–ø–æ–ª—É—á–∏–ª", "–ø—Ä–∏–Ω—è–ª", "–ø—Ä–µ–¥–ª–æ–∂–∏–ª",
        "–æ–±–º–∞–Ω—É–ª", "–≤–≤–µ–ª –≤ –∑–∞–±–ª—É–∂–¥–µ–Ω–∏–µ", "—Å–æ–≤–µ—Ä—à–∏–ª", "–ø—Ä–∏—Å–≤–æ–∏–ª", "–≤—ã–º–æ–≥–∞–ª",
        "–æ—Ä–≥–∞–Ω–∏–∑–æ–≤–∞–ª", "–∑–∞–∫–ª—é—á–∏–ª –¥–æ–≥–æ–≤–æ—Ä", "–ø–æ–ª—É—á–∏–ª –¥–æ—Å—Ç—É–ø", "—Å–Ω—è–ª –¥–µ–Ω—å–≥–∏"
    ]

    for f in facts:
        txt = f["text"].lower()
        f["role"] = next((r for k, r in ROLE_HINTS.items() if k in txt), "–Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ")
        f["action"] = next((a for a in ACTION_HINTS if a in txt), None)
        f["time"] = next(
            (d for d in re.findall(r"\d{1,2}[./]\d{1,2}[./]\d{2,4}", txt)), None
        )
    return facts


# ============================================================
# üîó –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ —Ñ–∞–∫—Ç–æ–≤ –ø–æ —Ç–∏–ø–∞–º –ª–∏—Ü (–¥–ª—è –±—É–¥—É—â–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞)
# ============================================================

def group_facts_by_entities(facts: list[dict]) -> dict:
    groups = {
        "—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏": defaultdict(list),
        "–ø–æ—Ç–µ—Ä–ø–µ–≤—à–∏–µ": defaultdict(list),
        "–ø—Ä–æ—á–∏–µ": [],
    }

    for fact in facts:
        text = fact.get("text", "").lower()
        if any(name in text for name in ["–∑–∞–∫–∏–µ–≤", "—à–∞–∫–µ–Ω–æ–≤", "–¥–∂–µ–Ω–∞–ª–∏–Ω–æ–≤"]):
            groups["—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏"]["–°–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å"].append(fact)
        elif any(name in text for name in ["–Ω—É—Ä–∫–∏–º–±–∞–µ–≤", "–±–µ–∫–æ–≤", "–∫–æ—Ö", "–∫—É—Å–∞–∏–Ω–æ–≤"]):
            groups["–ø–æ—Ç–µ—Ä–ø–µ–≤—à–∏–µ"]["–ü–æ—Ç–µ—Ä–ø–µ–≤—à–∏–π"].append(fact)
        else:
            groups["–ø—Ä–æ—á–∏–µ"].append(fact)
    return groups


# ============================================================
# üß± –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –¥–∞–Ω–Ω—ã—Ö –æ –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º–æ–º (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ API)
# ============================================================

def validate_facts_completeness(docs: list[Dict[str, Any]]):
    """
    –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å—Ç—å –ª–∏ –í–û–û–ë–©–ï —Ñ–∞–∫—Ç—ã –∏ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º–æ–≥–æ.
    –í API —Å—é–¥–∞ –ø–µ—Ä–µ–¥–∞—é—Ç—Å—è raw-docs, –∞ –Ω–µ facts ‚Äî —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ: –º—ã —Å–º–æ—Ç—Ä–∏–º –ø–æ text.
    """
    if not docs:
        raise HTTPException(
            status_code=400,
            detail="‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω—ã –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, –∑–∞–≥—Ä—É–∂–µ–Ω—ã –ª–∏ —Ñ–∞–π–ª—ã –ø–æ –¥–µ–ª—É.",
        )

    has_suspect = any(
        "–ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º" in (d.get("text") or "").lower() for d in docs
    )
    if not has_suspect:
        raise HTTPException(
            status_code=404,
            detail="‚ùå –í —Ç–µ–∫—Å—Ç–∞—Ö –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã —Å–≤–µ–¥–µ–Ω–∏—è –æ –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º–æ–º. "
                   "–¢—Ä–µ–±—É–µ—Ç—Å—è –ø—Ä–æ–≤–µ—Ä–∏—Ç—å OCR –∏ –ø–æ–ª–Ω–æ—Ç—É –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤.",
        )


# ============================================================
# ‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–ª–Ω–æ—Ç—ã –ø–æ —Å—Ç. 204 –£–ü–ö –†–ö
# ============================================================

def _check_204_completeness(
    facts,
    persons,
    dates,
    amounts,
    roles=None,
    events=None,
    legal_facts=None,
    timeline=None,
):
    roles = roles or {}
    events = events or []
    legal_facts = legal_facts or {}

    def present(x):
        return bool(x)

    checklist = [
        {
            "item": "–£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –ª–∏—á–Ω–æ—Å—Ç—å –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º–æ–≥–æ",
            "present": present(roles.get("suspect")),
        },
        {
            "item": "–ï—Å—Ç—å –æ–ø–∏—Å–∞–Ω–∏–µ —Å–æ–±—ã—Ç–∏–π",
            "present": present(events),
        },
        {
            "item": "–ï—Å—Ç—å –¥–∞—Ç—ã —Å–æ–±—ã—Ç–∏–π",
            "present": present(dates),
        },
        {
            "item": "–ï—Å—Ç—å —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ —Å–≤–µ–¥–µ–Ω–∏—è",
            "present": present(amounts),
        },
        {
            "item": "–í—ã–¥–µ–ª–µ–Ω—ã —é—Ä–∏–¥–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏",
            "present": present(legal_facts),
        },
        {
            "item": "–ï—Å—Ç—å —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ (–≤—ã–¥–µ—Ä–∂–∫–∏ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤)",
            "present": present(facts),
        },
    ]

    missing = [x["item"] for x in checklist if not x["present"]]

    return {
        "article": "204 –£–ü–ö –†–ö",
        "checklist": checklist,
        "missing": missing,
        "enough_for_draft": len(missing) <= 2,
    }


# ============================================================
# ‚öñÔ∏è –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–µ–π –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤
# ============================================================

def _extract_articles(docs: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    arts: List[Dict[str, Any]] = []
    for d in docs:
        text = d.get("text") or ""
        file_id = d.get("file_id")
        page = d.get("page")
        for m in ART_RX.finditer(text):
            art_num = m.group(2)
            code = (m.group(3) or "–£–ö/–£–ü–ö/–ì–ö?").upper()
            arts.append(
                {
                    "code": (code.replace(" ", "") + " –†–ö") if "–†–ö" not in code else code,
                    "article": art_num,
                    "context": _context_snippet(text, m.start(), m.end()),
                    "source": {"file_id": file_id, "page": page},
                }
            )
    return _dedup_articles(arts)


def _resolve_law_context(article_num: str) -> str:
    data = ALL_AFM_LAWS.get(article_num)
    if not data:
        return f"–°—Ç–∞—Ç—å—è {article_num}: [–æ–ø–∏—Å–∞–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –±–∞–∑–µ AFM]"

    code = data.get("code", "–£–ö/–£–ü–ö –†–ö")
    name = data.get("name", "[–Ω–∞–∑–≤–∞–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç]")
    official_text = data.get("official_text") or data.get("text") or "[—Ç–µ–∫—Å—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç]"
    category = data.get("category", "–ø—Ä–æ—á–µ–µ")

    return f"{code} —Å—Ç.{article_num} ‚Äî {name}. {official_text} ({category})"


# ============================================================
# üßæ –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–∞ ¬´–£–°–¢–ê–ù–û–í–ò–õ¬ª (fallback-–≤–µ—Ä—Å–∏—è)
# ============================================================

def _build_ustanovil_text(
    facts: List[dict],
    sources: List[dict],
    completeness: dict,
) -> str:
    if not facts:
        return "–°—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ñ–∞–∫—Ç–æ–≤ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ. [–¢–†–ï–ë–£–ï–¢ –ü–†–û–í–ï–†–ö–ò]"

    lines: List[str] = []
    for f in facts:
        src_str = _src_str(f.get("sources"))
        conf = f.get("confidence", 0.5)
        suffix = "" if conf >= 0.75 else " [–¢–†–ï–ë–£–ï–¢ –ü–†–û–í–ï–†–ö–ò]"
        lines.append(f"‚Äî {f['text']} {src_str} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å={conf:.2f}){suffix}")

    if completeness.get("missing"):
        lines.append("")
        lines.append("–ù–µ–¥–æ—Å—Ç–∞—é—â–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã –¥–ª—è –ø–æ–ª–Ω–æ–π –∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø–æ —Å—Ç. 204 –£–ü–ö –†–ö:")
        for m in completeness["missing"]:
            lines.append(f"‚Ä¢ {m}")

    return "\n".join(lines)


# ============================================================
# üßæ –ü—Ä–æ—Å—Ç–æ–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ü–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è (fallback, –±–µ–∑ LLM)
# ============================================================

def _build_postanovlenie_simple(
    city: str,
    date_str: str,
    investigator_line: str,
    case_id: Optional[str],
    ustanovil_text: str,
    mentioned_articles: List[Dict[str, Any]],
    completeness: dict,
    investigator_fio: str = ""
) -> str:

    rus_date = _rus_date(date_str)

    # —Å–ø–∏—Å–æ–∫ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π —Å—Ç–∞—Ç–µ–π
    if mentioned_articles:
        arts = sorted({f"{a.get('code', '')} —Å—Ç.{a.get('article', '?')}" for a in mentioned_articles})
        arts_line = "–£–ø–æ–º–∏–Ω–∞–Ω–∏—è —Å—Ç–∞—Ç–µ–π: " + "; ".join(arts)
    else:
        arts_line = "–£–ø–æ–º–∏–Ω–∞–Ω–∏–π —Å—Ç–∞—Ç–µ–π –Ω–µ—Ç."

    # —Ä–µ—à–µ–Ω–∏–µ
    if completeness.get("enough_for_draft"):
        decision = "–ö–≤–∞–ª–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –¥–µ—è–Ω–∏–µ –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º–æ–≥–æ –ø–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–º —Å—Ç–∞—Ç—å—è–º –£–ö –†–µ—Å–ø—É–±–ª–∏–∫–∏ –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω."
    else:
        decision = "–û–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω—É—é –∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏—é –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–æ—Å–ª–µ –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤."

    return f"""
–ü–û–°–¢–ê–ù–û–í–õ–ï–ù–ò–ï
–æ –∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏–∏ –¥–µ—è–Ω–∏—è –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º–æ–≥–æ

{city}, {rus_date}

–ú–∞—Ç–µ—Ä–∏–∞–ª—ã –¥–µ–ª–∞ ‚Ññ {case_id}
{arts_line}

–£–°–¢–ê–ù–û–í–ò–õ:
{ustanovil_text}

–ü–û–°–¢–ê–ù–û–í–ò–õ:
{decision}

–ü–æ–¥–ø–∏—Å—å:
–°–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å: {investigator_line}
–§–ò–û: {investigator_fio}
______________________
–î–∞—Ç–∞: {rus_date}

–ü—Ä–∞–≤–∞ –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º–æ–≥–æ, –ø—Ä–µ–¥—É—Å–º–æ—Ç—Ä–µ–Ω–Ω—ã–µ —Å—Ç. 64 –£–ü–ö –†–ö:
- –ø—Ä–∞–≤–æ –∑–Ω–∞—Ç—å, –≤ —á—ë–º –æ–Ω –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ—Ç—Å—è;
- –ø—Ä–∞–≤–æ –¥–∞–≤–∞—Ç—å –æ–±—ä—è—Å–Ω–µ–Ω–∏—è –∏–ª–∏ –æ—Ç–∫–∞–∑–∞—Ç—å—Å—è –æ—Ç –¥–∞—á–∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏–π;
- –ø—Ä–∞–≤–æ –Ω–∞ –∑–∞—â–∏—Ç–Ω–∏–∫–∞;
- –ø—Ä–∞–≤–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—Ç—å –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞;
- –ø—Ä–∞–≤–æ –∑–∞—è–≤–ª—è—Ç—å —Ö–æ–¥–∞—Ç–∞–π—Å—Ç–≤–∞;
- –ø—Ä–∞–≤–æ –æ–±–∂–∞–ª–æ–≤–∞—Ç—å –¥–µ–π—Å—Ç–≤–∏—è –∏ —Ä–µ—à–µ–Ω–∏—è –æ—Ä–≥–∞–Ω–∞ —Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è.

–ß–µ—Ä–Ω–æ–≤–∏–∫ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏; –æ–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å –ø–æ—Å–ª–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –ø—Ä–æ–∫—É—Ä–æ—Ä–æ–º.
""".strip()

def _legal_fact_filter(fact_text: str) -> bool:
    """
    –§–∏–ª—å—Ç—Ä —é—Ä–∏–¥–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º—ã—Ö —Ñ–∞–∫—Ç–æ–≤.
    True  ‚Üí —Ñ–∞–∫—Ç –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ –ø—Ä–µ—Å—Ç—É–ø–ª–µ–Ω–∏—é (–æ—Å—Ç–∞–≤–ª—è–µ–º).
    False ‚Üí —Å–ª—É–∂–µ–±–Ω—ã–π/–º—É—Å–æ—Ä–Ω—ã–π/–ø—Ä–æ—Ü–µ—Å—Å—É–∞–ª—å–Ω—ã–π —Ñ–∞–∫—Ç (–≤—ã–±—Ä–∞—Å—ã–≤–∞–µ–º).
    """
    if not fact_text:
        return False

    t = fact_text.lower().strip()

    # ‚ùå 1. QR-–∫–æ–¥—ã, –≠–¶–ü, —Ö—ç—à–∏, —Ç–µ—Ö–Ω–∏—á. –¥–∞–Ω–Ω—ã–µ PDF
    blocked_pdf = [
        "qr", "—Ö–µ—à", "—Ö—ç—à", "ecp", "—ç—Ü–ø", "—ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç",
        "–ø–æ–¥–ø–∏—Å–∞–ª", "–ø–æ–¥–ø–∏—Å–∞–Ω–æ", "–ø–æ–¥–ø–∏—Å–∞–Ω", "–ø–æ–¥–ø–∏—Å–∞–Ω–æ —Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–µ–º",
        "–¥–∞–Ω–Ω—ã–µ —ç—Ü–ø", "–∫–æ–¥", "–ø–æ–¥–≥–æ—Ç–æ–≤–∏–ª", "–ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ",
        "–∫–æ–ø–∏—è –ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è", "–ø–æ–ª—É—á–µ–Ω–∞ –∫–æ–ø–∏—è", "–ø–æ–ª—É—á–∏–ª –∫–æ–ø–∏—é",
        "—ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω—ã–π pdf", "–≤—Ä–µ–º—è –ø–æ–¥–ø–∏—Å–∞–Ω–∏—è", "–¥–∞—Ç–∞ –ø–æ–¥–ø–∏—Å–∞–Ω–∏—è",
    ]
    if any(w in t for w in blocked_pdf):
        return False

    # ‚ùå 2. –†–∞–∑—ä—è—Å–Ω–µ–Ω–∏–µ –ø—Ä–∞–≤ / –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–µ–π (–ø–æ—Ç–µ—Ä–ø–µ–≤—à–∏–π, –≥—Ä–∞–∂–¥–∞–Ω—Å–∫–∏–π –∏—Å—Ç–µ—Ü –∏ —Ç.–ø.)
    if "—Ä–∞–∑—ä—è—Å–Ω" in t and ("–ø—Ä–∞–≤" in t or "–æ–±—è–∑–∞–Ω" in t):
        return False

    # ‚ùå 3. –û–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏ –ø–æ—Ç–µ—Ä–ø–µ–≤—à–µ–≥–æ, –ø—Ä–∞–≤–∏–ª–∞ –ø–æ–≤–µ–¥–µ–Ω–∏—è
    if "—è–≤–∏—Ç—å—Å—è –ø–æ –≤—ã–∑–æ–≤—É" in t or "–æ–±—è–∑–∞–Ω" in t:
        return False

    # ‚ùå 4. –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Å—Ä–µ–¥—Å—Ç–≤–∞ –≤–∏–¥–µ–æ–∑–∞–ø–∏—Å–∏
    if "–≤–∏–¥–µ–æ–∫–∞–º–µ—Ä–∞" in t or "iphone" in t or "sony" in t:
        return False

    # ‚ùå 5. –†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª–∏ –°–û–ì / –°–£ –î–≠–† (—Å–ª—É–∂–µ–±–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è)
    if "—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª" in t and ("—Å–æ–≥" in t or "–¥–µ—Ä" in t or "—Å—É –¥–µ—Ä" in t):
        return False

    # ‚ùå 6. –ü–∞—É–∑–∞ / –≤–µ–¥–µ–Ω–∏–µ –≤–∏–¥–µ–æ–∑–∞–ø–∏—Å–∏
    if "–≤–∏–¥–µ–æ—Å—ä–µ–º" in t or "–≤–∏–¥–µ–æ–∑–∞–ø–∏—Å—å" in t or "–ø—Ä–∏–æ—Å—Ç–∞–Ω–æ–≤" in t:
        return False

    # ‚ùå 7. –û–±—â–∏–µ —Å–ª—É–∂–µ–±–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã (–µ—Å–ª–∏ –Ω–µ—Ç –ø–æ–∫–∞–∑–∞–Ω–∏–π)
    blocked_docs = ["–ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ", "–ø—Ä–æ—Ç–æ–∫–æ–ª", "—É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ"]
    if any(w in t for w in blocked_docs) and "–ø–æ–∫–∞–∑–∞–Ω" not in t and "–¥–æ–ø—Ä–æ—Å" not in t:
        # –∏—Å–∫–ª—é—á–µ–Ω–∏–µ: –ø—Ä–æ—Ç–æ–∫–æ–ª –¥–æ–ø—Ä–æ—Å–∞ / –ø–æ–∫–∞–∑–∞–Ω–∏–π ‚Äî –æ—Å—Ç–∞–≤–∏—Ç—å
        return False

    # ‚ùå 8. –ü—É—Å—Ç—ã–µ / —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Ñ–∞–∫—Ç—ã
    if len(t) < 30:
        return False

    # ‚úî 9. –ü–æ–∫–∞–∑–∞–Ω–∏—è –ø–æ—Ç–µ—Ä–ø–µ–≤—à–∏—Ö
    if "–ø–æ—Ç–µ—Ä–ø–µ–≤" in t and ("–ø–æ–∫–∞–∑–∞–ª" in t or "–ø–æ–∫–∞–∑–∞–Ω" in t or "–ø–æ–∫–∞–∑–∞–Ω–∏" in t):
        return True

    # ‚úî 10. –ü—Ä–∏–∑–Ω–∞–∫–∏ –ø–∏—Ä–∞–º–∏–¥—ã / TACORP / –¥–≤–∏–∂–µ–Ω–∏—è –¥–µ–Ω–µ–≥ / —É—â–µ—Ä–±–∞
    keywords_crime = [
        "tacorp", "—Ç–∞corp", "–ø–∏—Ä–∞–º–∏–¥", "–≤–æ–≤–ª–µ—á–µ–Ω", "–≤—Å—Ç—É–ø–∏–ª", "–ø—Ä–∏–≤–ª–µ–∫",
        "–¥–µ–Ω–µ–∂–Ω", "–ø–µ—Ä–µ–≤–µ–ª", "–ø–µ—Ä–µ–≤—ë–ª", "–ø–æ–ª—É—á–∏–ª –¥–µ–Ω—å–≥–∏", "—É—â–µ—Ä–±", "—Å—Ä–µ–¥—Å—Ç–≤–∞",
        "—Ñ–∏–Ω–∞–Ω—Å–æ–≤", "—ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫", "—ç–∫—Å–ø–µ—Ä—Ç–∏–∑",
    ]
    if any(w in t for w in keywords_crime):
        return True

    # ‚úî 11. –õ—é–±—ã–µ –¥–µ–π—Å—Ç–≤–∏—è –ª–∏—Ü–∞, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –ø—Ä–µ—Å—Ç—É–ø–ª–µ–Ω–∏–µ–º
    action_words = ["—Å–æ–≤–µ—Ä—à", "–¥–µ–π—Å—Ç–≤", "–æ—Ä–≥–∞–Ω–∏–∑", "—Ä—É–∫–æ–≤–æ–¥", "–ø–æ–ª—É—á", "–ø—Ä–∏—Å–≤–æ", "–æ–±–º–∞–Ω—É–ª"]
    if any(w in t for w in action_words):
        return True

    # ‚ùå –í—Å—ë –æ—Å—Ç–∞–ª—å–Ω–æ–µ ‚Äî –≤—ã–±—Ä–∞—Å—ã–≤–∞–µ–º
    return False


# ============================================================
# üß† –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏–∏
# ============================================================

def qualify_documents(
    case_id: Optional[str],
    docs: List[Dict[str, Any]],
    city: str = "–≥. –ü–∞–≤–ª–æ–¥–∞—Ä",
    date_str: Optional[str] = None,
    investigator_line: str = "–°–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å –ø–æ –æ—Å–æ–±–æ –≤–∞–∂–Ω—ã–º –¥–µ–ª–∞–º",
    investigator_fio: str = "",
) -> Dict[str, Any]:
    logger.info(f"‚ñ∂Ô∏è –ù–∞—á–∞–ª–æ –∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏–∏: case_id={case_id}, –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤={len(docs)}")

    # 0Ô∏è‚É£ –ë–∞–∑–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
    if not docs:
        logger.warning("‚ö†Ô∏è –ù–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        return _empty_result(case_id, "–î–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç")

    if not date_str:
        date_str = datetime.now().strftime("%d.%m.%Y")

    try:
        # 1Ô∏è‚É£ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ñ–∞–∫—Ç–æ–≤ / —Å—É—â–Ω–æ—Å—Ç–µ–π –∏–∑ docs
        try:
            facts, persons, dates, amounts, sources = _extract_facts_and_sources(docs)
        except Exception as e:
            raise RuntimeError(f"_extract_facts_and_sources error: {e}")

        facts = enrich_facts_with_roles(facts)

        # 1.1 –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –º—É—Å–æ—Ä–Ω—ã—Ö —Ñ–∞–∫—Ç–æ–≤
        raw_count = len(facts)
        facts = [f for f in facts if _legal_fact_filter(f.get("text", ""))]
        logger.info(f"–§–ò–õ–¨–¢–† –§–ê–ö–¢–û–í: –±—ã–ª–æ={raw_count}, –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞={len(facts)}")

        # 2Ô∏è‚É£ –ì–ª—É–±–æ–∫–∏–π EXTRACTOR (—Ä–æ–ª–∏, —Å–æ–±—ã—Ç–∏—è, —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—è, —é—Ä. –ø—Ä–∏–∑–Ω–∞–∫–∏)
        try:
            extracted = extract_all(facts, persons, dates, amounts)
            roles = extracted.get("roles", {})
            events = extracted.get("events", [])
            timeline = extracted.get("timeline", [])
            legal_facts = extracted.get("legal_facts", {})
            logger.info("üìå EXTRACTOR: roles/events/timeline/legal_facts –ø–æ–ª—É—á–µ–Ω—ã")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ EXTRACTOR: {e}")
            roles, events, timeline, legal_facts = {}, [], [], {}

        # 3Ô∏è‚É£ –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–ª–Ω–æ—Ç—ã –ø–æ —Å—Ç. 204 –£–ü–ö –†–ö
        completeness = _check_204_completeness(
            facts=facts,
            persons=persons,
            dates=dates,
            amounts=amounts,
            roles=roles,
            events=events,
            legal_facts=legal_facts,
            timeline=timeline,
        )

        # 4Ô∏è‚É£ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–µ–π –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ê–§–ú
        mentioned_articles = _extract_articles(docs)
        logger.info(f"–£–ø–æ–º–∏–Ω–∞–Ω–∏–π —Å—Ç–∞—Ç–µ–π: {len(mentioned_articles)}")

        law_contexts: List[str] = []
        for art in mentioned_articles:
            num = art.get("article")
            if num and num in ALL_AFM_LAWS:
                law_contexts.append(_resolve_law_context(num))
        law_context_text = "\n".join(law_contexts[:5]) if law_contexts else ""

        # 5Ô∏è‚É£ –ë–∞–∑–æ–≤—ã–π —Ä–∞–∑–¥–µ–ª ¬´–£–°–¢–ê–ù–û–í–ò–õ¬ª (fallback)
        ustanovil_text = _build_ustanovil_text(facts, sources, completeness)

        # 6Ô∏è‚É£ –ü–æ–ø—ã—Ç–∫–∞ —É–ª—É—á—à–∏—Ç—å ¬´–£–°–¢–ê–ù–û–í–ò–õ¬ª —á–µ—Ä–µ–∑ LLM
        if facts:
            try:
                fact_lines: List[str] = []
                for f in facts:
                    fact_lines.append(f"- {f['text']} {_src_str(f.get('sources'))}")

                missing_text = ", ".join(completeness.get("missing", [])) or "–Ω–µ—Ç"

                strict_prompt = prompts.U_STSTRICT.format(
                    facts="\n".join(fact_lines),
                    missing=missing_text,
                )

                system_prompt = (
                    "–¢—ã ‚Äî —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –º–æ–¥—É–ª—å ¬´AI_Qualifier¬ª "
                    "–¥–ª—è –æ—Ä–≥–∞–Ω–æ–≤ —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–≥–æ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞. "
                    "–°—Ç—Ä–æ–≥–æ —Å–ª–µ–¥—É–π —Ñ–∞–∫—Ç–∞–º, –Ω–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –Ω–æ–≤—ã—Ö —Å–≤–µ–¥–µ–Ω–∏–π. "
                    "–ù–µ–ª—å–∑—è –≤–∫–ª—é—á–∞—Ç—å –≤ —Ä–∞–∑–¥–µ–ª ¬´–£–°–¢–ê–ù–û–í–ò–õ¬ª —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –æ QR-–∫–æ–¥–∞—Ö, –≠–¶–ü, "
                    "–≤–∏–¥–µ–æ–∫–∞–º–µ—Ä–∞—Ö, —Å–ª—É–∂–µ–±–Ω—ã—Ö –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è—Ö –∏ —Ä–∞–∑—ä—è—Å–Ω–µ–Ω–∏—è –ø—Ä–∞–≤; "
                    "–æ–ø–∏—Å—ã–≤–∞–π —Ç–æ–ª—å–∫–æ –∫–∞—Ä—Ç–∏–Ω—É –ø—Ä–µ—Å—Ç—É–ø–ª–µ–Ω–∏—è (–∫—Ç–æ, —á—Ç–æ —Å–¥–µ–ª–∞–ª, –∫–æ–≥–¥–∞, –≥–¥–µ, –∫–∞–∫–∏–º —Å–ø–æ—Å–æ–±–æ–º, "
                    "–∫–∞–∫–æ–π —É—â–µ—Ä–±, —Å–≤—è–∑—å —Å TACORP/–ø–∏—Ä–∞–º–∏–¥–æ–π –∏ –¥–≤–∏–∂–µ–Ω–∏–µ–º –¥–µ–Ω–µ–≥)."
                )

                ustanovil_text = _ask_llm(
                    prompt=strict_prompt,
                    system_prompt=system_prompt,
                )
                logger.info("–†–∞–∑–¥–µ–ª ¬´–£–°–¢–ê–ù–û–í–ò–õ¬ª —É–ª—É—á—à–µ–Ω —á–µ—Ä–µ–∑ LLM.")
            except LLMUnavailableError as e:
                logger.warning(f"LLM –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è —Ä–∞–∑–¥–µ–ª–∞ ¬´–£–°–¢–ê–ù–û–í–ò–õ¬ª: {e}")

        # 7Ô∏è‚É£ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –ü–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
        final_postanovlenie: str

        try:
            safe_article = (
                mentioned_articles[0].get("article", "[–¢—Ä–µ–±—É–µ—Ç —É—Ç–æ—á–Ω–µ–Ω–∏—è]")
                if mentioned_articles else "[–¢—Ä–µ–±—É–µ—Ç —É—Ç–æ—á–Ω–µ–Ω–∏—è]"
            )

            post_prompt = prompts.P_POST.format(ustanovil=ustanovil_text)

            system_for_post = (
                "–¢—ã ‚Äî –æ–ø—ã—Ç–Ω—ã–π —Å—Ç–∞—Ä—à–∏–π —Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å –ê–§–ú —Å —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–º –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ–º. "
                "–°–æ—Å—Ç–∞–≤—å –ø—Ä–æ–µ–∫—Ç –ø—Ä–æ—Ü–µ—Å—Å—É–∞–ª—å–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞ "
                "¬´–ü–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –æ –∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏–∏ –¥–µ—è–Ω–∏—è –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º–æ–≥–æ¬ª "
                "–ø–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º –£–ü–ö –†–ö. "
                "–ù–µ –¥–æ–±–∞–≤–ª—è–π —Ñ–∞–∫—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ —Ä–∞–∑–¥–µ–ª–µ ¬´–£–°–¢–ê–ù–û–í–ò–õ¬ª. "
                "–í —Ç–µ–∫—Å—Ç–µ –Ω–µ –¥—É–±–ª–∏—Ä—É–π –¥–æ–∫—É–º–µ–Ω—Ç –¥–≤–∞–∂–¥—ã, –∏—Å–ø–æ–ª—å–∑—É–π –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ "
                "–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É: —à–∞–ø–∫–∞ ‚Üí –£–°–¢–ê–ù–û–í–ò–õ ‚Üí –ü–û–°–¢–ê–ù–û–í–ò–õ ‚Üí –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø–æ–¥–ø–∏—Å—å."
            )

            full_user_prompt = f"""
–ú–∞—Ç–µ—Ä–∏–∞–ª—ã –¥–µ–ª–∞ ‚Ññ {case_id}.
–ú–µ—Å—Ç–æ –≤—ã–Ω–µ—Å–µ–Ω–∏—è: {city}.
–î–∞—Ç–∞: {_rus_date(date_str)}.

–í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–π —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (–µ—Å–ª–∏ –µ—Å—Ç—å):
{law_context_text or "[–Ω–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–æ–∫ –∑–∞–∫–æ–Ω–æ–≤]"}

–û—Å–Ω–æ–≤—ã–≤–∞–π—Å—è –∏—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ –Ω–∞ —Ä–∞–∑–¥–µ–ª–µ ¬´–£–°–¢–ê–ù–û–í–ò–õ¬ª –Ω–∏–∂–µ.

{post_prompt}

–°—Ç–∞—Ç—å—è –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–π –∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏–∏ (–µ—Å–ª–∏ —ç—Ç–æ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç—Å—è —Ñ–∞–∫—Ç–∞–º–∏): {safe_article}.
–ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ ‚Äî –≤ —Ä–∞–∑–¥–µ–ª–µ ¬´–ü–û–°–¢–ê–ù–û–í–ò–õ¬ª –æ—Ç—Ä–∞–∑–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –ø–æ–ª—É—á–µ–Ω–∏—è
–¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤ –ø–µ—Ä–µ–¥ –æ–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω–æ–π –∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏–µ–π.
"""

            final_postanovlenie = _ask_llm(
                prompt=full_user_prompt,
                system_prompt=system_for_post,
            )
            logger.info("–ü–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ —á–µ—Ä–µ–∑ LLM.")
        except LLMUnavailableError as e:
            logger.warning(f"LLM –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è –ü–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è: {e}")
            final_postanovlenie = _build_postanovlenie_simple(
                city=city,
                date_str=date_str,
                investigator_line=investigator_line,
                case_id=case_id,
                ustanovil_text=ustanovil_text,
                mentioned_articles=mentioned_articles,
                completeness=completeness,
                investigator_fio=investigator_fio,
            )

        # 8Ô∏è‚É£ –°—Ç—Ä–∞—Ö–æ–≤–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã (–Ω–∞–ª–∏—á–∏–µ ¬´–£–°–¢–ê–ù–û–í–ò–õ¬ª –∏ ¬´–ü–û–°–¢–ê–ù–û–í–ò–õ¬ª)
        lower_body = final_postanovlenie.lower()
        if "—É—Å—Ç–∞–Ω–æ–≤–∏–ª" not in lower_body or "–ø–æ—Å—Ç–∞–Ω–æ–≤–∏–ª" not in lower_body:
            logger.warning("‚ö†Ô∏è LLM –æ—Ç–∫–ª–æ–Ω–∏–ª—Å—è –æ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—ã, –ø—Ä–∏–º–µ–Ω—è—é fallback-—à–∞–±–ª–æ–Ω –ü–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è.")
            final_postanovlenie = _build_postanovlenie_simple(
                city=city,
                date_str=date_str,
                investigator_line=investigator_line,
                case_id=case_id,
                ustanovil_text=ustanovil_text,
                mentioned_articles=mentioned_articles,
                completeness=completeness,
                investigator_fio=investigator_fio,
            )

        # 9Ô∏è‚É£ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å + –±–∞–∑–æ–≤—ã–π result
        overall_conf = _overall_confidence(facts, completeness)
        warnings: List[str] = []

        result: Dict[str, Any] = {
            "generation_id": str(uuid.uuid4()),
            "model_version": MODEL_VERSION,
            "case_id": case_id,
            "facts": facts,
            "persons": persons,
            "dates": dates,
            "amounts": amounts,
            "mentioned_articles": mentioned_articles,
            "roles": roles,
            "events": events,
            "timeline": timeline,
            "legal_facts": legal_facts,
            "completeness_204": completeness,
            "established_text": ustanovil_text.strip(),
            "final_postanovlenie": final_postanovlenie.strip(),
            "sources": sources,
            "confidence": round(overall_conf, 3),
            "timestamp": datetime.utcnow().isoformat() + "Z",
            "investigator_fio": investigator_fio,
            "investigator_line": investigator_line,
            "warnings": warnings,
        }

        # üîü Anti-hallucination –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è
        try:
            verification = run_full_verification(result)
            if not isinstance(verification, dict):
                raise ValueError("–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏")

            result["verification"] = verification
            result["verdict"] = (
                "OK"
                if verification.get("overall_ok")
                else verification.get("texts", {}).get("verdict", "UNVERIFIED")
            )

            if not verification.get("overall_ok"):
                result["warnings"].append("‚ö†Ô∏è –í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è –≤—ã—è–≤–∏–ª–∞ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –Ω–µ—Ç–æ—á–Ω–æ—Å—Ç–∏")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏: {e}")
            result["verification"] = {"error": str(e)}
            result["verdict"] = "VERIFICATION_FAILED"
            result["warnings"].append(f"–û—à–∏–±–∫–∞ –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏: {str(e)}")

        logger.info(
            f"‚úÖ –ö–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞. verdict={result.get('verdict')}, "
            f"conf={result.get('confidence'):.2f}"
        )
        return result

    except LLMUnavailableError as e:
        logger.error(f"LLMUnavailableError –≤ qualify_documents: {e}")
        raise
    except Exception as e:
        logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏–∏: {e}", exc_info=True)
        return _empty_result(case_id, f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}")

# ============================================================
# üîπ Fallback-—Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö
# ============================================================

def _empty_result(case_id: str, msg: str, investigator_fio: str = "", investigator_line: str = "") -> dict:
    return {
        "generation_id": None,
        "model_version": MODEL_VERSION,
        "case_id": case_id,
        "established_text": "",
        "final_postanovlenie": f"[–û–®–ò–ë–ö–ê]: {msg}",
        "facts": [],
        "persons": [],
        "dates": [],
        "amounts": [],
        "mentioned_articles": [],
        "roles": {},
        "events": [],
        "timeline": [],
        "legal_facts": {},
        "completeness_204": {},
        "sources": [],
        "confidence": 0.0,
        "timestamp": datetime.utcnow().isoformat() + "Z",
        "investigator_fio": investigator_fio,
        "investigator_line": investigator_line,
        "warnings": [msg],
        "verification": {"overall_ok": False},
        "verdict": "ERROR",
    }


# ============================================================
# üß∞ –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —É—Ç–∏–ª–∏—Ç—ã
# ============================================================

def _split_sentences(text: str) -> List[str]:
    parts = re.split(r"(?<=[\.!\?])\s+", text)
    return [p.strip() for p in parts if len(p.strip()) > 10]


def _context_snippet(text: str, start: int, end: int, radius: int = CONTEXT_RADIUS) -> str:
    a, b = max(0, start - radius), min(len(text), end + radius)
    return text[a:b].replace("\n", " ").strip()


def _src_str(sources: List[Dict[str, Any]] | None) -> str:
    if not sources:
        return "[–∏—Å—Ç–æ—á–Ω–∏–∫: –Ω–µ —É–∫–∞–∑–∞–Ω]"
    show = [f"[{s.get('file_id', '?')}:{s.get('page', '-')}]"
            for s in sources[:3]]
    if len(sources) > 3:
        show.append(f"(–∏ –µ—â—ë {len(sources) - 3})")
    return " ".join(show)


def _conf_from_signal(sentence: str) -> float:
    score = MIN_FACT_CONFIDENCE
    if DATE_RX.search(sentence):
        score += 0.15
    if MONEY_RX.search(sentence):
        score += 0.15
    if PERSON_RX.search(sentence):
        score += 0.1
    return min(score, 0.95)


def _dedup_sources(sources: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    seen, out = set(), []
    for s in sources:
        key = (s.get("file_id"), s.get("page"))
        if key not in seen:
            seen.add(key)
            out.append(s)
    return out


def _dedup_articles(arts: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    seen, out = set(), []
    for a in arts:
        key = (
            a["code"],
            a["article"],
            a["source"].get("file_id"),
            a["source"].get("page"),
        )
        if key not in seen:
            seen.add(key)
            out.append(a)
    return out


def _overall_confidence(facts: List[dict], completeness: dict) -> float:
    if not facts:
        return 0.4
    avg = sum(f.get("confidence", 0.5) for f in facts) / max(1, len(facts))
    miss_penalty = 0.05 * len(completeness.get("missing", []))
    return max(0.1, min(0.98, avg - miss_penalty))


def _rus_date(d: str) -> str:
    """
    –ü–æ–Ω–∏–º–∞–µ—Ç 'DD.MM.YYYY' –∏ ISO 'YYYY-MM-DD'.
    –ï—Å–ª–∏ —Ñ–æ—Ä–º–∞—Ç –Ω–µ–∏–∑–≤–µ—Å—Ç–µ–Ω ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏—Å—Ö–æ–¥–Ω—É—é —Å—Ç—Ä–æ–∫—É.
    """
    try:
        if re.fullmatch(r"\d{4}-\d{2}-\d{2}", d):
            dt = datetime.fromisoformat(d)
        else:
            dt = datetime.strptime(d, "%d.%m.%Y")
    except Exception:
        return d

    months = [
        "—è–Ω–≤–∞—Ä—è", "—Ñ–µ–≤—Ä–∞–ª—è", "–º–∞—Ä—Ç–∞", "–∞–ø—Ä–µ–ª—è", "–º–∞—è", "–∏—é–Ω—è",
        "–∏—é–ª—è", "–∞–≤–≥—É—Å—Ç–∞", "—Å–µ–Ω—Ç—è–±—Ä—è", "–æ–∫—Ç—è–±—Ä—è", "–Ω–æ—è–±—Ä—è", "–¥–µ–∫–∞–±—Ä—è",
    ]
    return f"{dt.day} {months[dt.month - 1]} {dt.year} –≥–æ–¥–∞"
