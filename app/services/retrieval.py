# app/services/retrieval.py

import logging
from typing import List, Dict, Any, Optional
from sqlalchemy.orm import Session
from uuid import UUID

from app.db.models import File, Chunk

logger = logging.getLogger(__name__)


# ============================================================
# üî• –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è retrieval ‚Äî EXTRACTOR-READY FORMAT
# ============================================================

def get_file_docs_for_qualifier(
    db: Session,
    file_ids: Optional[List[str]] = None,
    case_id: Optional[str] = None,
) -> List[Dict[str, Any]]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å—Ç—Ä–æ–≥–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ:

        {
            "file_id": "uuid",
            "page": 1,
            "chunk_id": "uuid",
            "text": "..."
        }

    –≠—Ç–æ—Ç —Ñ–æ—Ä–º–∞—Ç —è–≤–ª—è–µ—Ç—Å—è –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–º –¥–ª—è:
    - roles extractor
    - events extractor
    - timeline builder
    - legal facts extractor
    - inline citations
    """

    query = db.query(File)

    if case_id:
        query = query.filter(File.case_id == case_id)

    if file_ids:
        query = query.filter(File.file_id.in_(file_ids))

    files = query.all()
    logger.info(f"üìÑ Retrieval: –Ω–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(files)}")

    docs: List[Dict[str, Any]] = []

    for f in files:
        file_id_str = str(f.file_id)

        # –ß–∞–Ω–∫–∏ —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–æ–π
        try:
            chunks = (
                db.query(Chunk)
                .filter(Chunk.file_id == UUID(file_id_str))     # –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ UUID
                .order_by(
                    Chunk.page.asc(),
                    Chunk.start_offset.asc()
                )
                .all()
            )
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —á–∞–Ω–∫–æ–≤ –¥–ª—è —Ñ–∞–π–ª–∞ {file_id_str}: {e}")
            chunks = []

        if not chunks:
            logger.warning(f"‚ö†Ô∏è –§–∞–π–ª {file_id_str} –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —á–∞–Ω–∫–æ–≤ ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞—é.")
            continue

        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —á–∞–Ω–∫–æ–≤ –≤ EXTRACTOR-ready —Ñ–æ—Ä–º–∞—Ç
        for ch in chunks:
            text = getattr(ch, "text", None) or getattr(ch, "content", None) or ""

            docs.append({
                "file_id": file_id_str,
                "page": ch.page or 1,
                "chunk_id": str(ch.chunk_id),
                "text": text.strip(),
            })

    logger.info(f"üì¶ Retrieval –≤–µ—Ä–Ω—É–ª {len(docs)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")

    return docs


# ============================================================
# üîπ –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: –ø–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö —á–∞–Ω–∫–æ–≤ —Ñ–∞–π–ª–∞
# ============================================================

def get_chunks_by_file_id(db: Session, file_id: str) -> List[Dict[str, Any]]:
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —á–∞–Ω–∫–æ–≤ —Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π –¥–∞–Ω–Ω—ã—Ö."""

    try:
        chunks = (
            db.query(Chunk)
            .filter(Chunk.file_id == UUID(file_id))
            .order_by(
                Chunk.page.asc(),
                Chunk.start_offset.asc()
            )
            .all()
        )
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ get_chunks_by_file_id –¥–ª—è {file_id}: {e}")
        return []

    result = []

    for ch in chunks:
        text = getattr(ch, "text", None) or getattr(ch, "content", None) or ""

        result.append({
            "chunk_id": str(ch.chunk_id),
            "file_id": file_id,
            "page": ch.page or 1,
            "text": text,
            "metadata": {
                "start_offset": getattr(ch, "start_offset", None),
                "created_at": getattr(ch, "created_at", None),
            },
        })

    if not result:
        logger.warning(f"‚ö†Ô∏è –§–∞–π–ª {file_id} –≤–µ—Ä–Ω—É–ª 0 —á–∞–Ω–∫–æ–≤ ‚Äî —Å–æ–∑–¥–∞—é placeholder.")
        return [{
            "chunk_id": f"{file_id}-empty",
            "file_id": file_id,
            "page": 1,
            "text": "",
            "metadata": {}
        }]

    return result


# ============================================================
# üîπ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥–µ–ª—É
# ============================================================

def get_file_text_stats(db: Session, case_id: str) -> Dict[str, Any]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Ñ–∞–π–ª–∞–º –∏ —á–∞–Ω–∫–∞–º –≤ –¥–µ–ª–µ."""

    try:
        files = db.query(File).filter(File.case_id == case_id).all()

        stats = {
            "case_id": case_id,
            "total_files": len(files),
            "files_with_chunks": 0,
            "total_chunks": 0,
            "total_chars": 0,
            "files": [],
        }

        for f in files:
            file_id_str = str(f.file_id)

            chunks = db.query(Chunk).filter(
                Chunk.file_id == UUID(file_id_str)
            ).all()

            text_length = sum(
                len(getattr(c, "text", "") or "")
                for c in chunks
            )

            stats["total_chunks"] += len(chunks)
            stats["total_chars"] += text_length

            if chunks:
                stats["files_with_chunks"] += 1

            stats["files"].append({
                "file_id": file_id_str,
                "filename": getattr(f, "filename", None),
                "chunks": len(chunks),
                "text_length": text_length,
            })

        logger.info(
            f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {stats['total_files']} —Ñ–∞–π–ª–æ–≤, "
            f"{stats['total_chunks']} chunks, "
            f"{stats['total_chars']} —Å–∏–º–≤–æ–ª–æ–≤"
        )

        return stats

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ get_file_text_stats: {e}")
        return {"error": str(e)}
