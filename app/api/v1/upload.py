# app/api/v1/upload.py
import uuid
import os
import tempfile
import zipfile
import shutil
import logging
import re
from typing import List, Optional

from fastapi import APIRouter, Depends, UploadFile, File as FastAPIFile, HTTPException
from sqlalchemy.orm import Session

from app.db import get_db
from app.db.models import File
from app.services.chunker import (
    process_any_file,
    process_text_into_chunks
)
from app.services.parser import extract_text_from_file
from app.services.retrieval import get_file_docs_for_qualifier
from app.services.agents.ai_qualifier import qualify_documents
from app.services.validation.verifier import run_full_verification
from app.utils.config import settings

# ============================================================
# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã
# ============================================================
MAX_FILE_SIZE_MB = getattr(settings, 'MAX_FILE_SIZE_MB', 100)
MAX_FILE_SIZE_BYTES = MAX_FILE_SIZE_MB * 1024 * 1024

router = APIRouter(prefix="/upload", tags=["Upload"])
logger = logging.getLogger(__name__)

# ============================================================
# –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
# ============================================================

def _extract_case_id_from_name(name: str) -> Optional[str]:
    """
    –ü—ã—Ç–∞–µ—Ç—Å—è –∏–∑–≤–ª–µ—á—å –Ω–æ–º–µ—Ä –ï–†–î–† / –¥–µ–ª–∞ –∏–∑ –ò–ú–ï–ù–ò —Ñ–∞–π–ª–∞ / –∞—Ä—Ö–∏–≤–∞.
    –ò—â–µ–º 15 –ø–æ–¥—Ä—è–¥ –∏–¥—É—â–∏—Ö —Ü–∏—Ñ—Ä.
    """
    if not name:
        return None
    m = re.search(r"(\d{15})", name)
    return m.group(1) if m else None


def _extract_case_id_from_text(text: str) -> Optional[str]:
    """
    –ü—ã—Ç–∞–µ—Ç—Å—è –∏–∑–≤–ª–µ—á—å –Ω–æ–º–µ—Ä –ï–†–î–† / –¥–µ–ª–∞ –∏–∑ –¢–ï–ö–°–¢–ê –¥–æ–∫—É–º–µ–Ω—Ç–∞.
    –†–∞–±–æ—Ç–∞–µ—Ç –∏ –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö PDF, –∏ –¥–ª—è DOCX/TXT, –∏ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ OCR.
    """
    if not text:
        return None
    # –ò—â–µ–º –ª—é–±—É—é –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏–∑ 15 —Ü–∏—Ñ—Ä
    m = re.search(r"(\d{15})", text)
    return m.group(1) if m else None


def _detect_case_id_for_file(
    file_path: str,
    filename: str,
    outer_case_id: Optional[str] = None,
) -> Optional[str]:
    """
    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –¥–µ—Ç–µ–∫—Ç–æ—Ä –Ω–æ–º–µ—Ä–∞ –¥–µ–ª–∞ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞.

    –ü–æ—Ä—è–¥–æ–∫:
    1) –∏—â–µ–º –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏ —Ñ–∞–π–ª–∞;
    2) –µ—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ ‚Äî –ø—ã—Ç–∞–µ–º—Å—è –≤—ã—Ç–∞—â–∏—Ç—å —Ç–µ–∫—Å—Ç (PDF/DOCX/TXT) –∏ –Ω–∞–π—Ç–∏ —Ç–∞–º;
    3) –µ—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º outer_case_id (–¥–ª—è —Ñ–∞–π–ª–æ–≤ –≤–Ω—É—Ç—Ä–∏ ZIP).
    """
    # 1) –ü–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
    case_id = _extract_case_id_from_name(filename)
    if case_id:
        logger.info(f"üîé case_id={case_id} –Ω–∞–π–¥–µ–Ω –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏ —Ñ–∞–π–ª–∞: {filename}")
        return case_id

    # 2) –ü–æ —Ç–µ–∫—Å—Ç—É —Ñ–∞–π–ª–∞
    try:
        text = extract_text_from_file(file_path) or ""
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞ {filename} –¥–ª—è –ø–æ–∏—Å–∫–∞ case_id: {e}")
        text = ""

    if text.strip():
        case_id_from_text = _extract_case_id_from_text(text)
        if case_id_from_text:
            logger.info(f"üîé case_id={case_id_from_text} –Ω–∞–π–¥–µ–Ω –≤ —Ç–µ–∫—Å—Ç–µ —Ñ–∞–π–ª–∞: {filename}")
            return case_id_from_text

    # 3) Fallback ‚Äî –±–µ—Ä–µ–º case_id —Å–Ω–∞—Ä—É–∂–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∏–∑ –∏–º–µ–Ω–∏ ZIP)
    if outer_case_id:
        logger.info(
            f"‚ÑπÔ∏è –î–ª—è —Ñ–∞–π–ª–∞ {filename} –∏—Å–ø–æ–ª—å–∑—É–µ–º outer_case_id={outer_case_id} "
            f"(–ø–æ –∏–º–µ–Ω–∏/—Ç–µ–∫—Å—Ç—É –Ω–µ –Ω–∞–π–¥–µ–Ω–æ)"
        )
        return outer_case_id

    logger.info(f"‚ö†Ô∏è case_id –Ω–µ –Ω–∞–π–¥–µ–Ω –Ω–∏ –≤ –∏–º–µ–Ω–∏, –Ω–∏ –≤ —Ç–µ–∫—Å—Ç–µ —Ñ–∞–π–ª–∞: {filename}")
    return None


def _validate_file_size(file: UploadFile) -> None:
    if hasattr(file, 'size') and file.size:
        if file.size > MAX_FILE_SIZE_BYTES:
            raise HTTPException(
                status_code=413,
                detail=(
                    f"–§–∞–π–ª {file.filename} —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π ({file.size / 1024 / 1024:.1f} –ú–ë). "
                    f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {MAX_FILE_SIZE_MB} –ú–ë"
                )
            )


# ============================================================
# –û—Å–Ω–æ–≤–Ω–æ–π endpoint
# ============================================================

@router.post("/")
async def upload_files(
    files: List[UploadFile] = FastAPIFile(...),
    db: Session = Depends(get_db),
):
    results = []
    case_ids_map = {}

    logger.info(f"üì§ –ó–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è —Ñ–∞–π–ª–æ–≤: {len(files)}")

    for file in files:
        temp_path = None

        try:
            # 1) –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞
            try:
                _validate_file_size(file)
            except HTTPException as e:
                results.append({
                    "file_id": None,
                    "filename": file.filename,
                    "chunks_created": 0,
                    "error": e.detail,
                    "status": "failed",
                })
                continue

            # 2) –í—Ä–µ–º–µ–Ω–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
            with tempfile.NamedTemporaryFile(delete=False, suffix=f"_{file.filename}") as tmp:
                temp_path = tmp.name
                content = await file.read()
                if len(content) > MAX_FILE_SIZE_BYTES:
                    raise HTTPException(
                        status_code=413,
                        detail=f"–§–∞–π–ª {file.filename} —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π. –ú–∞–∫—Å–∏–º—É–º: {MAX_FILE_SIZE_MB} –ú–ë"
                    )
                tmp.write(content)

            ext = os.path.splitext(file.filename)[1].lower()
            logger.info(f"üì• –ó–∞–≥—Ä—É–∂–µ–Ω {file.filename}, —Ä–∞–∑–º–µ—Ä {len(content)} –±–∞–π—Ç")

            # ============================================================
            # 3) ZIP
            # ============================================================
            if ext == ".zip":
                extract_dir = tempfile.mkdtemp(prefix="unzipped_")
                try:
                    with zipfile.ZipFile(temp_path, "r") as zip_ref:
                        zip_ref.extractall(extract_dir)
                except zipfile.BadZipFile:
                    raise HTTPException(status_code=400, detail="ZIP —Ñ–∞–π–ª –ø–æ–≤—Ä–µ–∂–¥—ë–Ω")

                # case_id, –∫–æ—Ç–æ—Ä—ã–π —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –≤ –ò–ú–ï–ù–ò —Å–∞–º–æ–≥–æ ZIP
                outer_case_id = _extract_case_id_from_name(file.filename)
                if outer_case_id:
                    logger.info(f"üîé outer_case_id={outer_case_id} –Ω–∞–π–¥–µ–Ω –≤ –∏–º–µ–Ω–∏ ZIP {file.filename}")
                else:
                    logger.info(f"‚ÑπÔ∏è –í –∏–º–µ–Ω–∏ ZIP {file.filename} –Ω–æ–º–µ—Ä –¥–µ–ª–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω")

                zip_inner_ids = []

                for root, _, inner_files in os.walk(extract_dir):
                    for inner_name in inner_files:
                        inner_path = os.path.join(root, inner_name)
                        inner_ext = os.path.splitext(inner_name)[1].lower()
                        if inner_ext not in [".pdf", ".docx", ".txt"]:
                            continue

                        inner_file_id = uuid.uuid4()
                        with db.begin_nested():
                            try:
                                # üî• –ù–æ–≤—ã–π —É–º–Ω—ã–π –ø–æ–∏—Å–∫ case_id:
                                # 1) –∏–º—è –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–≥–æ —Ñ–∞–π–ª–∞
                                # 2) —Ç–µ–∫—Å—Ç/–ûCR –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–≥–æ —Ñ–∞–π–ª–∞
                                # 3) outer_case_id (–∏–∑ –∏–º–µ–Ω–∏ ZIP)
                                case_id_to_save = _detect_case_id_for_file(
                                    file_path=inner_path,
                                    filename=inner_name,
                                    outer_case_id=outer_case_id,
                                )

                                new_file = File(
                                    file_id=inner_file_id,
                                    filename=inner_name,
                                    case_id=case_id_to_save,
                                    s3_key=f"s3://afm-originals/{inner_name}",
                                    ocr_confidence=0.9,
                                )
                                db.add(new_file)
                                db.flush()

                                chunks_created = 0
                                if inner_ext == ".pdf":
                                    # üîÅ –õ–æ–≥–∏–∫–∞ —á–∞–Ω–∫–∏–Ω–≥–∞ –Ω–µ –º–µ–Ω—è–µ—Ç—Å—è
                                    chunks_created = process_any_file(inner_path, inner_file_id, db)
                                else:
                                    text = extract_text_from_file(inner_path) or ""
                                    if text.strip():
                                        chunks_created = process_text_into_chunks(inner_file_id, text, db)

                                new_file.chunks_count = chunks_created
                                logger.info(f"üìÑ {inner_name}: —Å–æ–∑–¥–∞–Ω–æ —á–∞–Ω–∫–æ–≤ = {chunks_created}")

                                if case_id_to_save:
                                    case_ids_map.setdefault(case_id_to_save, []).append(str(inner_file_id))

                                results.append({
                                    "file_id": str(inner_file_id),
                                    "filename": inner_name,
                                    "chunks_created": chunks_created,
                                    "case_id": case_id_to_save,
                                    "s3_key": f"s3://afm-originals/{inner_name}",
                                    "status": "success",
                                })

                                zip_inner_ids.append(str(inner_file_id))

                            except Exception as e:
                                logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ñ–∞–π–ª–∞ –≤ ZIP {inner_name}: {e}")
                                results.append({
                                    "file_id": str(inner_file_id),
                                    "filename": inner_name,
                                    "chunks_created": 0,
                                    "error": str(e),
                                    "status": "failed"
                                })

                # –ò—Ç–æ–≥ –ø–æ ZIP
                total_chunks = sum(
                    r.get("chunks_created", 0)
                    for r in results
                    if r.get("file_id") in zip_inner_ids
                )
                results.append({
                    "file_id": None,
                    "filename": file.filename,
                    "type": "zip_summary",
                    "files_processed": len(zip_inner_ids),
                    "chunks_created": total_chunks,
                    "case_id": outer_case_id,
                    "status": "success"
                })

                shutil.rmtree(extract_dir, ignore_errors=True)
                continue

            # ============================================================
            # 4) PDF
            # ============================================================
            if ext == ".pdf":
                file_id = uuid.uuid4()
                with db.begin_nested():
                    try:
                        # üî• –ó–¥–µ—Å—å —Ç–µ–ø–µ—Ä—å —É–º–Ω—ã–π –ø–æ–∏—Å–∫ case_id:
                        case_id_extracted = _detect_case_id_for_file(
                            file_path=temp_path,
                            filename=file.filename,
                            outer_case_id=None,
                        )

                        new_file = File(
                            file_id=file_id,
                            filename=file.filename,
                            case_id=case_id_extracted,
                            s3_key=f"s3://afm-originals/{file.filename}",
                            ocr_confidence=0.9,
                        )
                        db.add(new_file)
                        db.flush()

                        # –õ–æ–≥–∏–∫–∞ —á–∞–Ω–∫–∏–Ω–≥–∞ –Ω–µ –º–µ–Ω—è–µ—Ç—Å—è
                        chunks_created = process_any_file(temp_path, file_id, db)
                        new_file.chunks_count = chunks_created
                        logger.info(f"üìÑ PDF {file.filename}: —á–∞–Ω–∫–æ–≤ = {chunks_created}")

                        if case_id_extracted:
                            case_ids_map.setdefault(case_id_extracted, []).append(str(file_id))

                        results.append({
                            "file_id": str(file_id),
                            "filename": file.filename,
                            "chunks_created": chunks_created,
                            "case_id": case_id_extracted,
                            "s3_key": f"s3://afm-originals/{file.filename}",
                            "status": "success",
                        })

                    except Exception as e:
                        logger.error(f"‚ùå –û—à–∏–±–∫–∞ PDF {file.filename}: {e}")
                        results.append({
                            "file_id": str(file_id),
                            "filename": file.filename,
                            "chunks_created": 0,
                            "error": str(e),
                            "status": "failed",
                        })
                continue

            # ============================================================
            # 5) DOCX / TXT
            # ============================================================
            if ext in [".docx", ".txt"]:
                file_id = uuid.uuid4()
                with db.begin_nested():
                    try:
                        # üî• –ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ –∏—â–µ–º case_id –∏ –ø–æ –∏–º–µ–Ω–∏, –∏ –ø–æ —Ç–µ–∫—Å—Ç—É
                        case_id_extracted = _detect_case_id_for_file(
                            file_path=temp_path,
                            filename=file.filename,
                            outer_case_id=None,
                        )

                        new_file = File(
                            file_id=file_id,
                            filename=file.filename,
                            case_id=case_id_extracted,
                            s3_key=f"s3://afm-originals/{file.filename}",
                            ocr_confidence=0.95,
                        )
                        db.add(new_file)
                        db.flush()

                        text = extract_text_from_file(temp_path) or ""
                        if not text.strip():
                            raise ValueError("–ü—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç")

                        chunks_created = process_text_into_chunks(file_id, text, db)
                        new_file.chunks_count = chunks_created

                        if case_id_extracted:
                            case_ids_map.setdefault(case_id_extracted, []).append(str(file_id))

                        results.append({
                            "file_id": str(file_id),
                            "filename": file.filename,
                            "chunks_created": chunks_created,
                            "case_id": case_id_extracted,
                            "status": "success",
                        })

                    except Exception as e:
                        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {file.filename}: {e}")
                        results.append({
                            "file_id": str(file_id),
                            "filename": file.filename,
                            "chunks_created": 0,
                            "error": str(e),
                            "status": "failed",
                        })
                continue

            # ============================================================
            # 6) –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç
            # ============================================================
            results.append({
                "file_id": None,
                "filename": file.filename,
                "chunks_created": 0,
                "error": f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç: {ext}",
                "status": "failed",
            })

        except Exception as e:
            logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}", exc_info=True)
            results.append({
                "file_id": None,
                "filename": file.filename,
                "error": str(e),
                "chunks_created": 0,
                "status": "failed",
            })

        finally:
            if temp_path and os.path.exists(temp_path):
                try:
                    os.remove(temp_path)
                except Exception:
                    pass

    # ============================================================
    # –ì–ª–æ–±–∞–ª—å–Ω—ã–π –∫–æ–º–º–∏—Ç
    # ============================================================
    try:
        db.commit()
    except Exception as e:
        db.rollback()
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—â–µ–≥–æ –∫–æ–º–º–∏—Ç–∞: {e}")

    # ============================================================
    # 7) –ö–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏—è (–ª–æ–≥–∏–∫–∞ –Ω–µ –º–µ–Ω—è–µ—Ç—Å—è)
    # ============================================================
    qualification_results = []

    if case_ids_map:
        for case_id, file_ids in case_ids_map.items():
            try:
                docs = get_file_docs_for_qualifier(db, file_ids=file_ids, case_id=case_id)
                if not docs:
                    continue

                qualifier = qualify_documents(
                    case_id=case_id,
                    docs=docs,
                    city="–≥. –ü–∞–≤–ª–æ–¥–∞—Ä",
                    investigator_line="–°–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å –°–≠–† –î–≠–† –ø–æ –ü–∞–≤–ª–æ–¥–∞—Ä—Å–∫–æ–π –æ–±–ª–∞—Å—Ç–∏",
                )

                verification = run_full_verification(qualifier)

                qualification_results.append({
                    "case_id": case_id,
                    "files_analyzed": len(file_ids),
                    "qualifier": qualifier,
                    "verification": verification,
                    "draft_postanovlenie": qualifier.get("final_postanovlenie"),
                    "status": "success",
                })

            except Exception as e:
                qualification_results.append({
                    "case_id": case_id,
                    "files_analyzed": len(file_ids),
                    "error": str(e),
                    "status": "failed",
                })

    # ============================================================
    # 8) –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç
    # ============================================================
    successful_files = sum(1 for r in results if r["status"] == "success")
    failed_files = sum(1 for r in results if r["status"] == "failed")

    return {
        "uploaded_files": len(results),
        "successful": successful_files,
        "failed": failed_files,
        "results": results,
        "qualifications": qualification_results or None,
    }
